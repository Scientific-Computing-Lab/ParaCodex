- Summary: Cached each material’s row pointers (`mat_offset`, `mat_mats`, `mat_concs`) in `calculate_macro_xs` so the 5-element macro cross-section loop no longer recomputes `mat * max_num_nucs` on every iteration, keeping the change confined to `Simulation.c` (see `data/src/XSBench-omp/Simulation.c`:293-332).  
- Documentation: Captured the before/after metrics, hypotheses, and micro-optimization narrative in `data/src/XSBench-omp/optimization_plan.md`, including the new final performance summary and checklist entries that reflect the mostly fixed data-transfer bottleneck.  
- Tests: `make -f Makefile.nvc clean` + `timeout 300 env OMP_TARGET_OFFLOAD=MANDATORY make -f Makefile.nvc run` (runtime dropped to 0.363s, lookups/s ~275k, same verification checksum); `diff baseline_output.txt current_output.txt | grep -E "Verification|SUCCESSFUL|FAILED"` (no differences reported).

Suggestions:
1. Investigate persisting the large datasets on the device between runs (e.g., keep the buffers allocated/mapped with `omp_target_alloc`/`is_device_ptr`) to attack the 300+ms host→device cost that still dominates runtime.
2. If the OpenMP runtime supports it, try streaming the verification buffer back only when needed rather than always, so the small device→host cost stays negligible and any future compute gains aren’t overshadowed by transfer noise.
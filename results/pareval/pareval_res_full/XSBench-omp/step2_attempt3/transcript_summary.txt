**Summary**
- `pick_mat` now compares `roll` against a fixed chain of cumulative thresholds instead of recalculating the prefix sum every iteration, trimming the per-thread instruction count and bringing `xs_lookup_kernel_baseline` from ~162 ms down to ~111 ms while keeping the checksum unchanged (`data/src/XSBench-omp/Simulation.cpp:224`).
- The performance plan now reports the updated runtime/transfer metrics and documents both the micro-optimization and the before/after summaries so the CUDA→OMP comparison and remaining work are recorded (`data/src/XSBench-omp/optimization_plan.md:3` and `data/src/XSBench-omp/optimization_plan.md:20`).
- The latest run output was copied into `profile.log` so the log and `current_output.txt` both reflect the optimized 0.371 s runtime, 134 ms host→device copy, and valid checksum (`data/src/XSBench-omp/profile.log:1`).

**Testing**
- `make -f Makefile.nvc clean`
- `timeout 300 env OMP_TARGET_OFFLOAD=MANDATORY make -f Makefile.nvc run NVCC="nvc++ -cuda -std=c++14 -gpu=cc89 -O3"`

**Next Steps**
1. Evaluate overlapping or reusing the 241 MB host→device copy (still ~134 ms) without breaking the current data strategy, as noted in the plan’s action list.
2. Consider more structural changes (e.g., splitting RNG from lookup or per-material sorting) if chasing the remaining ~2.5× slowdown vs. CUDA becomes the priority.
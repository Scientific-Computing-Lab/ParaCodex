Aligned the nano-XOR workspace by copying the CUDA driver/kernels into the data tree, adding the nvc++ build baseline, and documenting the kernel/loop analysis needed for subsequent OMP migration.

- Retained the CUDA logic in the new workspace by mirroring `nanoXOR.cu` as `data/src/nano-XOR-omp/nanoXOR.cpp#L1`, which still includes `gate.h` and the single `main`/kernel pair that were present in the golden source.
- Added a dedicated `data/src/nano-XOR-omp/Makefile.nvc#L1` that compiles `nanoXOR.cpp` with `nvc++ -cuda -std=c++17`, links `-lcudart`, and exposes `run`/`clean` targets so the environment can be rebuilt without touching the golden Makefile.
- Captured the golden baseline by rerunning `make -f golden_labels/src/nano-XOR-cuda/Makefile.nvc run` and copying its output into `data/src/nano-XOR-omp/baseline_output.txt#L1` for reference during OpenMP porting.
- Recorded the kernel and loop classification, kernel-launch details, CUDA dataflow, and OMP risks in `data/src/nano-XOR-omp/analysis.md#L1` to guide the upcoming migration.

Testing: `make -f golden_labels/src/nano-XOR-cuda/Makefile.nvc run` (see `baseline_output.txt#L1` for the captured output).

Next steps:
1. Replace the CUDA kernel launch with `#pragma omp parallel for collapse(2)` over `i`/`j`, keep the neighbor-check logic intact, and swap device buffers for host arrays as noted in the analysis.
2. Rework the host RNG fill and validation loops to be thread-safe (per-thread RNG state plus serialized diagnostics/early-exit) before building and testing the new OMP target with the nvc++ Makefile.
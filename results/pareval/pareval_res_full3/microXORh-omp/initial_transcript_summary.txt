Copied the CUDA driver into the `microXORh-omp` workspace, preserved the golden baseline run, added an nvc++ `Makefile.nvc`, and documented the kernel/loop classification for the planned OMP migration.

- Copied `main.cu` verbatim to `data/src/microXORh-omp/main.cpp:1` so the workspace holds the same CUDA logic under the required `.cpp` suffix for future translations.
- Added an `nvc++` build script (`data/src/microXORh-omp/Makefile.nvc:1`) that compiles `main.cpp` with `-cuda`/`-arch=sm_89` to mirror the golden build configuration.
- Saved the golden run log to `data/src/microXORh-omp/baseline_output.txt:1`, capturing the `make -f Makefile.nvc run` output used as the reference.
- Produced `data/src/microXORh-omp/analysis.md:1` with the required mapping, kernel/loop nesting, classification table, CUDA-specific notes, and migration guidance.

Tests: `make -f golden_labels/src/microXORh-cuda/Makefile.nvc run` (see the copied baseline log).

Next steps:
1. Use `nvc++ -cuda` via the new Makefile in `data/src/microXORh-omp` to verify the copied driver builds cleanly under the workspace environment.
2. Begin translating `cellsXOR` to OpenMP-aware loops guided by the analysis table (e.g., a `#pragma omp parallel for collapse(2)` over `i`/`j`) and replace the CUDA allocation/copy sequence with host memory management.
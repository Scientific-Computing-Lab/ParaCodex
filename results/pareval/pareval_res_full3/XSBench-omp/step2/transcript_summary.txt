Swapped in the OpenMP-targeted `Simulation.cpp` (with the missing `gate.h` link resolved) and tightened the macro‑XS helpers so the per-lookup kernel can rely on explicit constness and cached offsets, trimming the OpenMP kernel time by ~15ms.

- **Code:** Added the `gate.h` symlink so `Main.cpp` finds the gate SDK header, then updated the helpers to use `const`/`inline` signatures, cache per-material slices, and keep grid/search data read-only (`Simulation.cpp:9`, `Simulation.cpp:122`, `Simulation.cpp:191`), and mirrored those signatures in `XSbench_header.cuh:82-90` for the compiler.
- **Plan/docs:** Captured the runtime/transfer numbers and hypotheses in `optimization_plan.md:1` and refreshed `profile.log` with the latest run (still no `cuda_gpu_kern_sum` entries because the OpenMP target path is in use; see `profile.log:1`).
- **Tests:** `make -f Makefile.nvc clean` followed by `timeout 300 env OMP_TARGET_OFFLOAD=MANDATORY make -f Makefile.nvc run` (runtime 0.361s, host→device 137.4ms, kernel 106.3ms, device→host 0.63ms) produced the same verification output as the baseline (diff/grep yielded no `Verification` mismatches). The run now sits ~1.96× slower than the CUDA baseline but kernel time is down from ~125ms to ~106ms.

Next steps:
1. Capture an `nsys`/`nvprof` profile of the OpenMP target run to get concrete GPU kernel metrics and confirm the `#pragma omp target` launch shape.
2. Experiment with further micro-ops inside `calculate_macro_xs` (e.g., reduce branch overhead around the `grid_search` cases or hoist more readonly data) if the ~2× slow-down relative to CUDA remains unacceptable.
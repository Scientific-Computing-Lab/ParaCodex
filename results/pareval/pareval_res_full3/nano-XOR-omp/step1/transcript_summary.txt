**Summary**
- Converted `cellsXOR` into a pure host function that offloads the collapsed `N x N` stencil via `#pragma omp target teams loop collapse(2)` with `is_device_ptr` so the GPU still does the heavy work (`nanoXOR.cpp:22`).
- Wrapped the `input`/`output` buffers in a single `#pragma omp target data map(to:… ) map(from: …)` region so the host allocations keep the original lifetime and cleanup behavior while still syncing to the device (`nanoXOR.cpp:67`).
- Captured the CUDA memory/transfer workflow and Strategy A mapping in `data_plan.md` before touching runtime logic (`data_plan.md:1`).
- Saved a snapshot of the original CUDA source as `nanoXOR.cpp.bak` in case you need to compare back to the CUDA variant.

**Testing**
- `make -f Makefile.nvc clean`
- `make -f Makefile.nvc`
- `OMP_TARGET_OFFLOAD=MANDATORY timeout 300 make -f Makefile.nvc run` (output logged to `gpu_output.txt`; the run still reports `Validation passed.` and `GATE:SUM … value=8d6b0d7bb0cbdba2` from `gpu_output.txt:3`).
- `diff baseline_output.txt gpu_output.txt` (baseline’s `GATE:SUM… value=21692d804c3ad603` is at `baseline_output.txt:5`; the checksum differs because the RNG still seeds from `std::random_device`, so each run produces a different random grid even on CUDA, which is why the sum doesn’t match the stored baseline).

Next steps
1. Seed the generator deterministically if reproducible checksum regression tracking is required, then update the baseline output accordingly so the offload path can match expected markers.
2. Consider rerunning the suite under a profiler (e.g., as described in the workflow) with `OMP_TARGET_OFFLOAD=MANDATORY` to confirm that the target region executes on the RTX 4060.
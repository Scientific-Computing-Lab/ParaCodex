**Changes**
- `nanoXOR.cpp:22-46` now tags the input/output pointers with `__restrict__`, caches row offsets/boundary flags, and reuses a single `idx` for neighbor accesses, so each OpenMP target thread mirrors the CUDA 2D stencil indexing with fewer repeated multiplications.
- `optimization_plan.md:3-21` captures the new 0.02 s runtime, the micro-optimization hypothesis/actions, and the observation that Nsight still reports no CUDA kernel/memory stats for the OpenMP target loop.

**Testing**
- `make -f Makefile.nvc clean`
- `timeout 300 env OMP_TARGET_OFFLOAD=MANDATORY make -f Makefile.nvc run` (builds the binary, runs with `1024 32`, and validation passed)
- `env OMP_TARGET_OFFLOAD=MANDATORY /usr/bin/time -p ./nanoXOR.exe 1024 32` (validation passed; runtime ≈0.02 s)
- `env OMP_TARGET_OFFLOAD=MANDATORY nsys profile --force-overwrite true --stats true -o manual_profile ./nanoXOR.exe 1024 32` (Nsight still emitted zero CUDA kernel/memory data for the OpenMP target; noted in the plan)

Next steps:
1. Try OMPT- or NVTX-aware tracing (or a more recent Nsight profile configuration) to expose the OpenMP target kernel so the GPU-side metrics can be correlated with the code.
2. If further gains are needed, experiment with `target teams distribute parallel for collapse(2)` or other loop-scheduling clauses to fine-tune team/thread occupancy given the cached indexing.
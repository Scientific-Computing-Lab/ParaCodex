**OpenMP Translation**
- Converted the CUDA kernel into the host function `cellsXOR` and wrapped its computation in `#pragma omp target teams loop collapse(2) map(to: input[0:N*N]) map(from: output[0:N*N])`, eliminated all `cudaMalloc/cudaMemcpy`/`cudaFree` usage, added a host-only `cleanup` helper, and kept the validation path intact (`nanoXOR.cpp:21`, `nanoXOR.cpp:35`, `nanoXOR.cpp:71`). The original source was backed up as `nanoXOR.cpp.bak`.
- Documented the mapping strategy, data transfers, and kernel translation choices in `data_plan.md:1` so the migration rationale is captured before implementation.
- Tests: `make -f Makefile.nvc clean`, `env OMP_TARGET_OFFLOAD=MANDATORY make -f Makefile.nvc`, `timeout 300 env OMP_TARGET_OFFLOAD=MANDATORY make -f Makefile.nvc run > gpu_output.txt 2>&1`, and `diff baseline_output.txt gpu_output.txt`. The diff only shows the `GATE:SUM` checksum changing (`baseline_output.txt:5` vs. `gpu_output.txt:3`), which is expected because the input grid is seeded from `std::random_device`, so each run computes a different checksum.

**Next Steps**
- 1. Consider injecting a deterministic RNG seed (instead of `std::random_device`) when comparing against the recorded baseline output so future diffs reflect semantic regressions rather than stochastic variance.
- Documented the memory/kernels + Strategy A offload plan at `data/src/microXORh-omp/data_plan.md:29`, covering transfers, kernel mapping, and the rationale for a single `target data` region so future work knows how the CUDA flow maps to OpenMP.  
- Replaced the CUDA flow in `data/src/microXORh-omp/main.cpp#L3` with a host function `cellsXOR` that launches a `#pragma omp target teams loop collapse(2) is_device_ptr(d_input, d_output)` offload and wrapped the call in `#pragma omp target data map(to: input[0:totalCells]) map(from: output[0:totalCells])`—the rest of `main` still enforces `blockEdge`/size validation, initializes the RNG host buffer, and reuses the existing verification logic so behavior stays identical without CUDA APIs.  
- Preserved a backup of the original CUDA entry point at `data/src/microXORh-omp/main.cpp.bak` and captured the latest run output in `data/src/microXORh-omp/gpu_output.txt:1`, which shows the expected `./microXORh` launch and “Validation passed.”

- Tests: `make -f Makefile.nvc clean`, `make -f Makefile.nvc`, `env OMP_TARGET_OFFLOAD=MANDATORY make -f Makefile.nvc run > gpu_output.txt 2>&1` (validation output recorded in `gpu_output.txt`), `diff baseline_output.txt gpu_output.txt` shows only the prior `nvcc …` compile lines because the current build logs use `nvc++`, while the runtime lines (`./microXORh.exe…` and `Validation passed.`) match exactly.

- Next steps:  
  1. Profile the offloaded stencil on the RTX 4060 (Ada Lovelace) using the provided `nsys` command to benchmark the new OpenMP target launch.  
  2. If you need to compare full logs with the CUDA baseline, rerun the build/run sequence inside a single redirected session (so the compile commands appear in `gpu_output.txt`) or adjust the baseline capture to match the current `nvc++` output.
- Replaced the CUDA kernel/driver plumbing with `cellsXOR` executing via an `#pragma omp target teams loop collapse(2)` so the NxN neighbor logic now runs through OpenMP offload while validation and cleanup remain unchanged, and backed up the original source to `data/src/nano-XOR-omp/nanoXOR.cpp.bak`.
- Added `data/src/nano-XOR-omp/data_plan.md:1` to capture the CUDAâ†’OpenMP data movement strategy (Strategy A) and ensured `nvc++` passes `-mp=gpu` in `data/src/nano-XOR-omp/Makefile.nvc:4` so the target directives actually reach the GPU.
- Tests: `make -f Makefile.nvc clean`; `make -f Makefile.nvc`; `timeout 300 env OMP_TARGET_OFFLOAD=MANDATORY make -f Makefile.nvc run > gpu_output.txt 2>&1` (output captured in `gpu_output.txt`); `diff baseline_output.txt gpu_output.txt` (compiler invocation lines differ and the `GATE:SUM` checksum varies run-to-run because the input grid is reseeded via `std::random_device`).
- Next steps: 1) seed the RNG deterministically if you need bit-for-bit regression with the baseline; 2) profile the offloaded loop with `nsys`/`FORCE_OMP_GPU=1` once the command stream is stable.
Converted `nanoXOR.cpp` to run the XOR kernel via an `#pragma omp target teams loop` and removed every CUDA allocation/copy, while documenting the planned data flow in `data_plan.md`.

- `nanoXOR.cpp:11-23` now computes the XOR kernel inside a collapse-2 target teams loop with `map(to:/from:)` clauses so the host buffers drive the offload directly and no CUDA syntax remains.
- `nanoXOR.cpp:31-91` keeps the host argument checks, allocates `input`/`output`, feeds them with the original random fill, invokes the kernel, and validates before cleaning up; `cleanup()` now only frees the host vectors.
- Created `data_plan.md` to capture the CUDA → OpenMP mapping strategy (Strategy A) and document when/how each array is mapped.
- Saved a backup of the existing CUDA source as `nanoXOR.cpp.bak` (no `main.cu` was present in this workspace, so no additional backup was possible).

**Testing**
- `make -f Makefile.nvc clean && make -f Makefile.nvc` (passes; compiles the OpenMP offload binary).
- `OMP_TARGET_OFFLOAD=MANDATORY timeout 300 make -f Makefile.nvc run > gpu_output.txt 2>&1` (binary runs, prints “Validation passed.”, and logs `GATE:SUM … value=cbc8cafdf09d4103`).
- `diff baseline_output.txt gpu_output.txt` (fails because the `GATE:SUM` value differs from the recorded baseline `9f8e25fc79a1fa12`; this program still passes validation, but the random seed makes per-run checksums unpredictable).

Next steps: if you need deterministic diffs, consider seeding the RNG with a fixed value so the checksum matches the baseline every run.
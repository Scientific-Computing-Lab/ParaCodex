Cached the collapsed target loop’s neighbor logic so each team now stores its row offsets once before iterating over `j`, then reuses `idx`, `row_up`, and `row_down` instead of recomputing `i * N`/`j` at every branch (main.cpp:50). The build continues to override the Makefile’s invalid `-arch=sm_89` flag by passing `CFLAGS="-std=c++17 -cuda -O3"` so `nvc++` can target the local RTX 4060 without editing the Makefile.

Documented the updated metrics, bottleneck hypothesis, and the new final-performance summary (including the micro-optimization outcome and current lack of CUDA timing data) inside `optimization_plan.md:1`.

- Tests: `timeout 300 env OMP_TARGET_OFFLOAD=MANDATORY make -f Makefile.nvc CFLAGS="-std=c++17 -cuda -O3" run` (build + validation) and `env OMP_TARGET_OFFLOAD=MANDATORY /usr/bin/time -f "%e" ./microXORh.exe 1024 32` (end-to-end timing ~0.02s).

Next steps:
1. Capture NVIDIA profiling/`nsys` data for this OpenMP offload so the plan can note actual kernel runtimes and kernel transfer breakdowns rather than placeholder logs.
2. Re-run the kernel with larger grids (or repeated iterations) to see if the micro-optimizations become measurable and whether additional loop or transfer tuning is warranted.
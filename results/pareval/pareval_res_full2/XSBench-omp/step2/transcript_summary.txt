- Reworked the hot helper math in `data/src/XSBench-omp/Simulation.cpp`: `grid_search`/`grid_search_nuclide` are now inline with `const`/`restrict` pointers and `calculate_micro_xs`/`calculate_macro_xs` cache material offsets plus a `#pragma omp simd` accumulation to expose vectorization (`Simulation.cpp:10`, `Simulation.cpp:54`, `Simulation.cpp:126`).
- Updated the shared header so `grid_search_nuclide`’s signature matches the const-qualified helper and keeps every use from breaking (`XSbench_header.cuh:105`).
- Created `data/src/XSBench-omp/optimization_plan.md` that records the new baseline metrics, hypotheses, micro-optimization actions, and final performance summary for this CUDA→OpenMP migration (`optimization_plan.md:1`).
- Testing: `make -f Makefile.nvc clean` followed by `timeout 300 env OMP_TARGET_OFFLOAD=MANDATORY make -f Makefile.nvc run > current_output.txt 2>&1` (final runtime 0.315 s with host kernel_ms ≈162.3 ms as shown in `current_output.txt:57,62`); `diff baseline_output.txt current_output.txt | grep -E "Verification|SUCCESSFUL|FAILED"` returned no matches (exit 1).
- Observations: the OpenMP runtime still reports “No OpenMP target devices found; running on host” (`profile.log:17` and `current_output.txt:24`), even though `nvidia-smi --query-gpu=name,compute_cap --format=csv` exposes an RTX 4060 (compute capability 8.9), so every offload runs on CPU cores and the CUDA baseline remains faster.
- Next steps: 1) Enable or rebuild the libomptarget/NVPTX plugin stack so the `#pragma omp target` regions can actually reach the GPU (check that the runtime sees the same device reported by `nvidia-smi`); 2) After the device is available, rerun the profile and confirm the const/restrict/simd hints yield measurable gains and adjust further fusion/collapse strategies if needed.
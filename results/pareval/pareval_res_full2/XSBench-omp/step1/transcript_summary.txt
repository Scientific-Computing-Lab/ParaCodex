**Migration Summary**
- Documented the entire CUDA→OpenMP strategy in `data/src/XSBench-omp/data_plan.md:1`, covering device allocations, kernel inventory, and the decision to use a Strategy A target-data map that mirrors the original launch flow while keeping verification reductions on the host.
- Swapped the CUDA-only plumbing for OpenMP sanity: `data/src/XSBench-omp/GridInit.cpp:3` now simply acknowledges the host data (no `cudaMalloc`/`cudaMemcpy`), `data/src/XSBench-omp/XSbench_header.cuh:1` pulls in `<string.h>`/`<sys/time.h>` and re-exposes utility prototypes, and `data/src/XSBench-omp/io.cpp:1` now includes `<omp.h>` and reports “OpenMP offload” along with the absence of a target device.
- Reimplemented every kernel as a host helper that offloads via `#pragma omp target teams loop` with `is_device_ptr`, plus helper sorts/partitions and a `mark_used` utility to keep the compiler happy; see `data/src/XSBench-omp/Simulation.cpp:1-250` for the RNG/XS helpers and `data/src/XSBench-omp/Simulation.cpp:640-1045` for the baseline/optimized run functions (sampling, sorting, and lookups now run entirely within OpenMP target-data regions, complete with host-side sorts and `std::accumulate` reductions). A backup copy of the original CUDA file is preserved at `data/src/XSBench-omp/Simulation.cpp.bak:1`.
- Saved the smoke-test log in `data/src/XSBench-omp/gpu_output.txt:1`, showing the OpenMP run completing (no device found, runtime ~0.286 s, check-sum 299541) and the diff from `baseline_output.txt:1` highlights the switch from nvcc to nvc++, the host-only messaging, and the new timing breakdown (host-to-device and device-to-host times are now zero).

**Tests**
- `make -f Makefile.nvc clean`
- `OMP_TARGET_OFFLOAD=MANDATORY make -f Makefile.nvc`
- `timeout 300 env OMP_TARGET_OFFLOAD=MANDATORY make -f Makefile.nvc run > gpu_output.txt 2>&1`
- `diff baseline_output.txt gpu_output.txt` (shows the new OpenMP usage, runtime/lookups change, and host-only log vs the CUDA baseline)

**Next steps**
1. Repeat the run on a machine with an actual OpenMP offload device (so `omp_get_num_devices()` > 0) to confirm the target data mapping actually hits the GPU.
2. Consider profiling the host-side sorts/partitions to ensure they don’t dominate the new pipeline—if needed, replace the `std::stable_sort`/partition helpers with a parallel/OpenMP version.
3. Once the OpenMP version is stable, clean up the diagnostic pragmas or `mark_used` helpers if a different compiler is used so the code stays warning-free across toolchains.
- Implemented `cellsXOR` as an OpenMP target teams loop in `data/src/microXOR-omp/microXOR.cpp#L3-L16`, preserving the CUDA stencil logic inside the offload region and relying on the existing `target data` maps so the host pointers are passed implicitly rather than as device-only addresses.
- Authored a migration data plan (`data/src/microXOR-omp/data_plan.md#L1-L85`) that inventories the CUDA allocations/transfers, declares Strategy A, maps kernel launch expectations to the OpenMP offload pattern, and documents the lack of synchronization/atomics plus expected performance.

Tests (all run with `OMP_TARGET_OFFLOAD=MANDATORY`):
- `env OMP_TARGET_OFFLOAD=MANDATORY make -f Makefile.nvc clean`
- `env OMP_TARGET_OFFLOAD=MANDATORY make -f Makefile.nvc`
- `timeout 300 env OMP_TARGET_OFFLOAD=MANDATORY make -f Makefile.nvc run > gpu_output.txt 2>&1` (generated `data/src/microXOR-omp/gpu_output.txt`, showing `Validation passed.`)
- `diff baseline_output.txt gpu_output.txt` (only the compiler-driver lines differ; the validation output stays the same)

Suggestions:
1. Run `env OMP_TARGET_OFFLOAD=MANDATORY make -f Makefile.nvc check-correctness` to exercise the gate harness/validation against the CUDA binary.
2. Profile with `nsys` as outlined in the workflow if you need GPU performance data for the new OpenMP kernel.
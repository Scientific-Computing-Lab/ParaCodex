**Changes**
- Rebuilt `Simulation.c` into a pure OpenMP offload flow: device arrays now come from `omp_target_alloc`/`omp_target_memcpy`, the baseline and optimization kernels are `#pragma omp target teams loop` versions, and helper routines (verification reduction, sample sorting/partitioning) run on the host before copying back to the GPU (`data/src/XSBench-omp/Simulation.c:85`, `...:212`, `...:248`, `...:551`). All CUDA APIs and `thrust` utilities were removed, and a backup of the original source sits in `data/src/XSBench-omp/Simulation.c.bak:1`.
- Captured the required data-management plan before implementation so the mapping strategy is documented (`data/src/XSBench-omp/data_plan.md:1`).

**Tests**
- `make -f Makefile.nvc clean`
- `make -f Makefile.nvc`
- `timeout 300 env OMP_TARGET_OFFLOAD=MANDATORY make -f Makefile.nvc run > gpu_output.txt 2>&1` (captures the OpenMP-target run starting with `./XSBench …` at `data/src/XSBench-omp/gpu_output.txt:1`).
- `diff baseline_output.txt gpu_output.txt` (shows that the CUDA baseline declares `Programming Model: CUDA` at `baseline_output.txt:105`, while the new run reports `Programming Model: OpenMP Target Offloading` at `gpu_output.txt:16`, along with the extra `GATE:SUM` line at `gpu_output.txt:45` and the expected throughput/runtime differences).

**Next Steps**
- If you want to certify the OpenMP version, compare the reported `GATE:SUM name=verification_buffer …` value (`data/src/XSBench-omp/gpu_output.txt:45`) against the expected hash or rerun the reference harness to ensure the new output is considered correct despite the different runtime characteristics.
Micro-cached the lookup path because the run was already within ~3% of the measured transfer+kernel time, so only micro-optimizations were warranted; also captured the new metrics, early-exit reasoning, and next steps in `optimization_plan.md`.

- `Simulation.c:451` caches a per-nuclide base pointer (`nuc_grid`) and reuses it across the binary search/interpolation so the kernel keeps pointer math in registers instead of recomputing `nuclide_grids + nuc * n_gridpoints` everywhere.
- `Simulation.c:517` caches `num_nucs[mat]` plus the per-material `mats`/`concs` slices before the inner loop, eliminating repeated `mat * max_num_nucs` arithmetic and letting the macro lookup loop work on contiguous data.
- `optimization_plan.md:1` now records the 0.242 s runtime, host-to-device transfer dominance, the micro-optimization actions, and the final performance summary tailored to the RTX 4060 (CC 8.9) target.

- Tests: `make -f Makefile.nvc clean`; `timeout 300 env OMP_TARGET_OFFLOAD=MANDATORY make -f Makefile.nvc run > current_output.txt 2>&1` (passes, runtime drops from 0.267 s to 0.242 s); `diff baseline_output.txt current_output.txt | grep -E "Verification|SUCCESSFUL|FAILED"` (no differences).

1. Investigate keeping the big datasets resident via `omp_target_alloc`/`is_device_ptr` reuse or other persistent allocation patterns to attack the remaining host-to-device transfer wall (this is the only remaining large headroom).
- Tightened each GPU kernel so the inner loop now computes `idx = i + Nr * j`, keeps neighbor samples (`north`, `south`, `west`, `east`) in locals, and uses temporary scalars for `G2`, `L`, divergence, and diffusion coefficient updates; the three existing `#pragma omp target teams loop collapse(2)` sections still launch per stage but now incur far less redundant indexing (`data/src/srad-omp/src/main.c:351-419`).
- Captured the rationale, revised strategy, and final numbers in `optimization_plan.md`, including the updated `Final Performance Summary` so we can compare baseline vs. optimized metrics later (`optimization_plan.md:49-74`).

Tests:
- `make -f Makefile.nvc CC=nvc++ CLASS=C run` (pass; see GPU runtime 0.386919s and total runtime 8.7681s in `data/src/srad-omp/current_output.txt:1-111`).

Next steps:
1. Run a fresh GPU profile (nsys or similar) on the optimized build to confirm the ROI reduction kernel still dominates and to spot further micro-optimizations.
2. If additional speedup is required, revisit fusion/loop fusion ideas for the derivative and divergence stagesâ€”any further reorganization should be verified against both correctness and the profiling data before adoption.
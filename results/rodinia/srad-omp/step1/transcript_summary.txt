GPU iteration now executes entirely inside a Strategy A `#pragma omp target data` region so the image, index tables, and scratch buffers stay resident on the GPU while the ROI reduction, derivative stencil, and divergence/update loops launch as `#pragma omp target teams loop collapse(2)` kernels that reference the same device allocations (see `src/main.c:343-440`). The same section also clears the unused `threads` input to silence warnings and keeps the original CPU path for validation.

Documented the array usages, per-stage kernels, and transfer expectations in `data/src/srad-omp/data_plan.md:1-54` and archived the untouched starting point as `src/main.c.codex_backup`.

- Tests:
  - `OMP_TARGET_OFFLOAD=MANDATORY make -f Makefile.nvc CC=nvc++ CLASS=C` (build after cleaning)
  - `OMP_TARGET_OFFLOAD=MANDATORY timeout 300 make -f Makefile.nvc CC=nvc++ CLASS=C run > gpu_output.txt 2>&1`
  - `diff baseline_output.txt gpu_output.txt` (differences stem from compile log timing lines and the expected runtime metrics—`Non-Matching CPU-GPU Outputs Beyond Error Threshold of 0.05 Percent: 0` remained identical)

Next steps:
1. Run the prescribed Class B profiling (nsys with `OMP_TARGET_OFFLOAD=MANDATORY`) to inspect kernel occupancy, memory transfers, and potential bottlenecks across the new `target teams` kernels.
2. Use the profiling data to guide further tuning (grid/block sizes, shared-memory staging, or loop fusion) so the GPU kernels can saturate the RTX 4060 Ti’s SMs while keeping data local to the accelerator.
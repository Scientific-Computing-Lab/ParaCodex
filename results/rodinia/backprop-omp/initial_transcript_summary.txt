Converted the dense feed-forward and weight-update loops to OpenMP target teams loops that flatten the weight matrices, map them explicitly, and keep the CPU reference runs intact so the comparison checks still pass.

- Added `#include <omp.h>` to support the new offload pragmas and keep the rest of the legacy code unchanged (`data/src/backprop-omp/backprop.c:10-18`).
- `bpnn_layerforward` now flattens the connection matrix, runs `#pragma omp target teams loop` over the output neurons, and uses an inner `#pragma omp loop reduction` to accumulate the dot product before copying the results back for the CPU run and comparison (`data/src/backprop-omp/backprop.c:278-334`).
- `bpnn_adjust_weights` now flattens the weight/momentum matrices and executes a collapsed `teams loop` to update both the weight and momentum buffers on the device before leaving the CPU version untouched for correctness checks (`data/src/backprop-omp/backprop.c:381-457`).
- Tests: `make -f Makefile.nvc clean`, `make -f Makefile.nvc CLASS=B`, `./main 65536` (all succeed; GPU/CPU mismatch reports stay at 0 and training completes with the usual GATE_STATS output).
- Build still reports the existing legacy warnings about implicit declarations and old-style prototypes in the Rodinia helper files (`backprop.c`, `facetrain.c`, `imagenet.c`); no new warnings were introduced beyond those.

Next step: capture an `nsys` profile of the new kernels to see if further tuning (team/thread limits, data reuse) can improve GPU utilization.
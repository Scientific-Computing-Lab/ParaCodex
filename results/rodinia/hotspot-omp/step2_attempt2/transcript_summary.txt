Reworked `single_iteration_gpu` so each thread caches its linear index, the current `temp`/`power` values, and the precomputed `step/Cap` plus inverse resistances, eliminating redundant `r*col` and division math and dropping the GPU phase to `0.146269s`.

- **Hot kernel tuning** `src/hotspot_openmp.cpp:37-110`: introduced `step_div_Cap`/`inv_R*`, added a comment describing the caching, and rewrote the loop to reuse `center_temp`/`power_center` via `row_offset`/`idx` before the boundary `if` chain so each branch reuses the cached values instead of re-executing heavy arithmetic.
- **Plan update** `optimization_plan.md:1-188`: refreshed the analysis to cite the measured `0.146s` runtime, highlighted the per-cell caching optimization, and recorded the final speedup plus unchanged data-transfer behavior.
- **Validation** `data/src/hotspot-omp/current_output.txt`: `timeout 300 make -f Makefile.nvc CC=nvc++ CLASS=C run` (see the file for the full build/run transcript; GPU runtime printed as `0.146269s` with matching correctness output).
- **Profile note** `data/src/hotspot-omp/profile.log`: still contains the pre-change 0.341s run; rerun the CLASS‑B profiling command when you want updated kernel/memory summaries.

Suggestions:
1. Re-run the CLASS‑B `nsys` profiling command to regenerate `profile.log`, capturing the new runtime breakdown and verifying the kernel’s occupancy improvements.
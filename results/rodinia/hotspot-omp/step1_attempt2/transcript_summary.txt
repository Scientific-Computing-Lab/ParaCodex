Reworked the hotspot GPU path to follow our Strategy A data plan, reduced per-thread index math, and retraced the mandated baseline/GPU runs.

- **Summary** Expanded `data/src/hotspot-omp/data_plan.md:1` with the array inventory, function table, device allocations, transfer volumes, and checklist so every buffer and offload step is documented before coding.
- **Summary** Reworked `single_iteration_gpu` to precompute `row_offset/idx`, cache the center/power values, and reuse those offsets inside each `target teams loop` (see `data/src/hotspot-omp/src/hotspot_openmp.cpp:37`), plus explained the Strategy A `target data` region that now keeps all temp/power/result buffers resident (`data/src/hotspot-omp/src/hotspot_openmp.cpp:246`).
- **Summary** Saved the previous CPU-oriented GPU source as `data/src/hotspot-omp/src/hotspot_openmp.cpp.bak2` before edits for easy rollback.

- **Testing** `OMP_TARGET_OFFLOAD=MANDATORY timeout 300 make -f Makefile.nvc CC=nvc++ CLASS=C run > baseline_output.txt 2>&1` (captures the baseline compile/run log and runtimes at `data/src/hotspot-omp/baseline_output.txt:91-92`), `OMP_TARGET_OFFLOAD=MANDATORY timeout 300 make -f Makefile.nvc CC=nvc++ CLASS=C run > gpu_output.txt 2>&1` (new runtime at `data/src/hotspot-omp/gpu_output.txt:3-4`), and `diff baseline_output.txt gpu_output.txt` (shows the compile log mismatch plus the slight runtime delta: CPU 0.001366s → 0.001454s, GPU 0.146735s → 0.153951s).

- **Next steps** 1. Profile the CLASS B build via `nsys` to validate occupancy and verify the row_offset tweaks improve throughput; 2. Run the `check-correctness` target once profiling is clean to ensure the GPU result still matches the golden reference under `OMP_TARGET_OFFLOAD=MANDATORY`.
Fused the U/L sweeps so each pivot launches a single `target teams` kernel, kept the pivot row/diag pointers live inside that kernel, and rewrote the optimization plan/final summary to capture the new launch counts and runtime expectations.

- `lud_omp.c:33` now contains one `target data`/`target teams` construct per pivot, and the loops at `lud_omp.c:44`/`lud_omp.c:54` compute both the U-row and L-column updates using cached `row_i`, `diag_col`, and incremental `col_ptr` arithmetic so the inner reductions reuse computed offsets.
- `optimization_plan.md:3` has refreshed metrics (new CLASS B runtime, 1,024 launches, Strategy A transfers) plus a strategy section, and `optimization_plan.md:54` documents the baseline vs. final summary along with the two optimizations we applied.
- The key-insight block at `optimization_plan.md:71` reminds us that `profile.log` still reflects the unfused build, so running `nsys` on this version is the next profiling step.

- Tests: `make clean` (without `-f`) reports “No rule to make target 'clean'”, so I used `make -f Makefile.nvc clean` followed by `make -f Makefile.nvc CC=nvc++ CLASS=B run` (build succeeds with existing implicit-function/missing-return warnings in `src/lud.c` and `src/common/common.c`).

Next steps:
1. Rerun the prescribed `nsys` profiling pipeline (CLASS B) against the fused build so the GPU metrics/kernels reflect the current code.
2. If further speedup is needed, explore additional inner-loop `collapse`/`simd` hints or tiling strategies within the fused kernel while watching register pressure.
Kept the matrix resident for each stage and reshaped `lud_omp_gpu` so the two triangular sweeps now execute inside `#pragma omp target teams loop thread_limit(128)` with an inner `#pragma omp loop reduction(+:accum)` over `k`, letting the GPU do the heavy triangular reductions per `i` while still following the serial stage order (`data/src/lud-omp/lud_omp.c:33-60`).

- `lud_omp.c:33-60` now uses device-local reductions: the U-row loop reads the current value, performs a reduction of `a[i*size+k]*a[k*size+j]`, and writes the updated element, while the L-column loop similarly reduces before dividing by the pivot, keeping the pivot on-device for the entire stage.
- `data/src/lud-omp/data_plan.md:12-53` documents Strategy A’s device residency, the use of `thread_limit(128)` teams loops, and the `omp loop reduction` pattern so the triangular workload stays compute-bound on the GPU without mid-iteration transfers.
- Baseline + validation per instructions: `OMP_TARGET_OFFLOAD=MANDATORY timeout 300 make -f Makefile.nvc CC=nvc++ CLASS=C run > baseline_output.txt 2>&1` captures the pre-change behavior; after the edits I built and ran `OMP_TARGET_OFFLOAD=MANDATORY make -f Makefile.nvc CC=nvc++ CLASS=C` plus `OMP_TARGET_OFFLOAD=MANDATORY timeout 300 make -f Makefile.nvc CC=nvc++ CLASS=C run > gpu_output.txt 2>&1` (the runtime log `data/src/lud-omp/gpu_output.txt:1-8` shows CPU ≈0.325s and GPU ≈0.332s with verification). `diff baseline_output.txt gpu_output.txt` only highlights the earlier build-time logging and the tiny runtime drift, so functional correctness remains intact.

Next steps:
1. Profile the updated kernel under CLASS B with the recommended `nsys`/`nvprof` flow to confirm warp occupancy and shared-memory behavior now that reductions are inside `omp loop`.
2. If needed, experiment with different `thread_limit`/team sizes (guided by profiling) to balance register use versus parallelism for the triangular sweeps.
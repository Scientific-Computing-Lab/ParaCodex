**Changes**
- Introduced a small `RESTRICT` helper at the top of `data/src/bfs-omp/src/bfs.c:7` and applied it to the `init_device_state`/`run_gpu_bfs` prototypes at `data/src/bfs-omp/src/bfs.c:35` so the compiler knows the CSR buffers do not alias and can keep more metadata in registers.
- Tuned both target kernels (see `data/src/bfs-omp/src/bfs.c:268`) with `thread_limit(128)` plus `#pragma omp loop simd` inside the adjacency sweep to align team size with the Ada Lovelace warp/block structure while keeping the mask-update reduction on a consistent thread count.
- Recorded the new vectorization/thread-limit hints directly in the plan so future profiling knows why the micro-opts now mention these tweaks (`data/src/bfs-omp/optimization_plan.md:52` and `data/src/bfs-omp/optimization_plan.md:77`).

**Testing**
- `make -f Makefile.nvc clean` + `timeout 300 make -f Makefile.nvc CC=nvc++ DEVICE=gpu SM=cc89 CLASS=C run` (GPU runtime 0.012549s, CPU runtime 0.048137s, no mismatches).

Next steps:
1. Profile with Nsight/`nsys` to confirm that the new `thread_limit(128)` teams and `loop simd` hint actually improve occupancy/vectorization on the RTX 4060 Ti.
2. Follow the existing data-management plan to persist the six target allocations across runs so the dominant `cuMemAllocManaged` startup cost vanishes.
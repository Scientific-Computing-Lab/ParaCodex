- Documented the Strategy C plan (arrays, per-iteration function, transfer budget, and checks) ahead of implementation so the CUDA-style workflow is explicit before touching the code (`data_plan.md:3`, `data_plan.md:26`).
- Added `<omp.h>`, persistent device pointers, helper prototypes, and a device-managed `f1` that runs every loop through `#pragma omp target teams loop` to keep CSR/vectors on the GPU; `omp_target_alloc`/`omp_target_memcpy`/`omp_target_free` helpers now own the lifecycle of the working arrays (`cg.c:15`, `cg.c:26`, `cg.c:102`, `cg.c:559`, `cg.c:661`).
- Warmup and benchmark phases now call `f1` with device pointers, compute dot-products as device reductions, and scale `v8` on the GPU so only scalars touch the host; this keeps all vector math resident on the accelerator without extra transfers (`cg.c:197`, `cg.c:218`, `cg.c:250`).

**Testing**
- `make clean`
- `timeout 300 env OMP_TARGET_OFFLOAD=MANDATORY make CC=nvc++ CLASS=S run > gpu_output.txt 2>&1`
- `grep -E "Verification|SUCCESSFUL|FAILED" gpu_output.txt` → `VERIFICATION SUCCESSFUL`
- `diff baseline_output.txt gpu_output.txt` → only warning line-number shifts plus longer init/benchmark time and Mop/s changes, no incorrect results

**Next Steps**
1. Run the heavier Class B/C builds/runs (with the same `OMP_TARGET_OFFLOAD=MANDATORY` guard) and capture an `nsys` profile to understand GPU kernel performance now that the data lives on-device.

OpenAI Codex v0.66.0 (research preview)
--------
workdir: /root/codex_baseline/serial_omp_nas_workdir
model: gpt-5.1-codex-mini
provider: openai
approval: never
sandbox: danger-full-access
reasoning effort: medium
reasoning summaries: auto
session id: 019b0dd5-63f5-7e52-b5ad-edcc43650857
--------
user
Directory: /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp

# GPU Offload with OpenMP

**Directory:** `/root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/`  
**Files:** - cg.c  
**Reference:** `/root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/analysis.md`

**Required:** 
- Use `OMP_TARGET_OFFLOAD=MANDATORY` for all runs
- DO NOT use `distribute parallel for`

## Workflow

### 0. Backup
Save backup of - cg.c.

### 1. Get Baseline (CLASS A/S)
```bash
cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp
make clean
timeout 300 env OMP_TARGET_OFFLOAD=MANDATORY make CC=nvc++ CLASS=S run > baseline_output.txt 2>&1
# Fallback: timeout 60 env OMP_TARGET_OFFLOAD=MANDATORY make CC=nvc++ CLASS=S run > baseline_output.txt 2>&1
grep -E "Verification|SUCCESSFUL|FAILED" baseline_output.txt

DO NOT SKIP THIS STEP.
```

### 2. Choose Data Strategy
Walk through IN ORDER, stop at first match:

```
RULE 1: Type B (Sparse/CSR)?              → STRATEGY A/C
RULE 2: Type C1 (Iterative Solvers/Butterfly)?→ STRATEGY C
RULE 3: Type C2 (Multigrid)?              → STRATEGY A
RULE 4: Outer A + inner E (per-thread RNG)?→ STRATEGY A
RULE 5: Multiple independent kernels?     → STRATEGY B
RULE 6: Otherwise                         → STRATEGY A
```

### 2.5. Create Data Management Plan
MANDATORY: Create data_plan.md in /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp before implementation

**FIRST: Check if original algorithm can be simplified for GPU:**
- Large scratch arrays for intermediate results → Can per-thread locals replace them?
- Block-based iteration (for cache) → REMOVE blocking, use single parallel loop over ALL work items
- Multi-stage with host sync → Can everything run in one kernel?

**Rule:** If scratch arrays exist ONLY to avoid atomics on small data (<1KB), 
DELETE them and use per-thread locals + atomic merge instead.

**Block elimination:** If code has `for (blk = 0; blk < numblks; blk++)` with scratch arrays,
this is a CPU cache optimization. For GPU: remove blocking, parallelize over all N items directly.

Analyze ALL arrays and functions in timed region:

```markdown

# Data Management Plan

## Arrays Inventory
List ALL arrays used in timed region:

| Array Name | Size | Type | Init | Access |
|------------|------|------|------|--------|
| [name] | [bytes] | working/scratch/const/index | host/device | R/W/RO |

**Types:** working (main data), scratch (temp), const (read-only), index (maps)

## Functions in Timed Region
| Function | Arrays Accessed | Frequency | Must Run On |
|----------|----------------|-----------|-------------|
| [name] | [list] | per-iteration/once | device/host |

## Data Movement Strategy

**Chosen Strategy:** [A/B/C]

**Device Allocations (once):**
```
Strategy C: d_[array]: [size] via omp_target_alloc
Strategy A: [arrays] in target data region
```

**Host→Device Transfers:**
- When: [before iterations/once at start]
- Arrays: [array1]→d_[array1] ([size] MB)
- Total H→D: ~[X] MB

**Device→Host Transfers:**
- When: [after iterations/once at end]
- Arrays: d_[array1]→[array1] ([size] MB)
- Total D→H: ~[Y] MB

**Transfers During Iterations:** [YES/NO]
- If YES: [which arrays and why]
- If NO: All data stays on device

## Critical Checks (for chosen strategy)

**Strategy A:**
- [ ] Functions inside target data use `present,alloc` wrapper?
- [ ] Scratch arrays use enter/exit data OR omp_target_alloc?

**Strategy C:**
- [ ] ALL functions in iteration loop use is_device_ptr?
- [ ] Scratch arrays allocated on device (not host)?
- [ ] No map() clauses (only is_device_ptr)?

**Common Mistakes:**
-  Some functions on device, others on host (causes copying)
-  Scratch as host arrays in Strategy C
-  Forgetting to offload ALL functions in loop

## Expected Transfer Volume
- Total: ~[X+Y] MB for entire execution
- **Red flag:** If actual >2x expected → data management wrong

## Additional Parallelization Notes
- **RNG Replicable?** [YES/NO] - If YES, use `#pragma omp declare target` on RNG function
- **Outer Saturation?** [outer iters]
- **Sparse Matrix NONZER?** [value]
- **Histogram Strategy?** For small bin (≤ 100) counts: use per-thread local array + atomic merge (NO scratch arrays needed!)

**Summary:** [num] arrays ([num] scratch, [num] working), [num] functions, Strategy [A/B/C]. Expected: ~[X] MB H→D, ~[Y] MB D→H.
```

### 2.6. Implement Data Plan

**Use data_plan.md as implementation guide**

### Step 1: Setup Data Structures
From "Arrays Inventory" and "Data Movement Strategy":
- Declare device arrays/pointers as needed for chosen strategy
- Create allocation/initialization functions based on strategy:
  - **Strategy A:** Setup target data regions with map clauses from plan
  - **Strategy B:** Prepare depend clauses for async operations
  - **Strategy C:** Create omp_target_alloc calls using sizes from plan

### Step 2: Implement Transfers
From "H→D Transfers" and "D→H Transfers" sections:
- Implement each transfer listed with timing specified in plan
- Use method appropriate for strategy (map clauses, omp_target_memcpy, update, etc.)

### Step 3: Offload Functions
Use "Functions in Timed Region" table:
- For each function where "Must Run On" = device:
  - Add appropriate pragma for strategy
  - Include arrays from "Arrays Accessed" column
  - Follow strategy-specific patterns from Step 2

### Step 4: Main Program Flow
Follow "Data Movement Strategy" timing:
```
[setup from plan]
[H→D transfers at specified time]
[timed computation - call functions]
[D→H transfers at specified time]
[cleanup]
```

### Step 5: Verify Implementation
Check ALL items in "Critical Checks" section for YOUR strategy:
- [ ] Verify each checkpoint matches implementation
- [ ] Cross-reference "Functions in Timed Region" table
- [ ] Confirm transfer timing matches plan

**Common errors:** Mismatched array names, missing functions from table, wrong transfer timing

**Ready when:** All strategy-specific checks ✓ and compiles
---

## Strategy Details

### STRATEGY A: target data Region

**Map Clause Selection:**
| Scenario | Map Clause | Why |
|----------|------------|-----|
| Device-init arrays (zero(), fill()) | `alloc` | Avoid copying garbage |
| Host RNG init then sync | `alloc` + `update to` | Explicit sync after host init |
| Read + modify + write | `tofrom` | Bidirectional |
| Read-only | `to` | One-way |

**Functions Called Inside target data:**
Wrap with `present,alloc`/'to,tofrom', then use bare `target teams loop`:
```c
void compute(double *u, double *v, int n) {
  #pragma omp target data map(present,alloc:u[0:n],v[0:n])
  {
    #pragma omp target teams loop
    for (int i = 0; i < n; i++) { ... }
  }
}
```

**RNG replicable:**
```c
#pragma omp target teams loop reduction(+:sum1, sum2) firstprivate(seed_base, params)
for (int sample = 0; sample < N; ++sample) {
  double rng_state = compute_seed_for_sample(sample);  // Per-thread seed
  double local_hist[BINS] = {0};  // Per-thread histogram
  
  // Type E (RNG) is sequential WITHIN this thread
  for (int i = 0; i < work_per_sample; ++i) {
    double r = my_rng(&rng_state, A);
    int bin = compute_bin(r);
    local_hist[bin] += 1.0;
    sum1 += ...; sum2 += ...;  // Reduction handles these
  }
  
  // Atomic merge histogram at end
  for (int b = 0; b < BINS; ++b) {
    if (local_hist[b] != 0.0) {
      #pragma omp atomic update
      global_hist[b] += local_hist[b];
    }
  }
}
```

**Scratch Arrays (two options):**

- **Option 1: enter/exit data**
```c
double scratch[N];
#pragma omp target enter data map(alloc:scratch[0:n])
#pragma omp target data map(present,alloc:in[0:n])
{
  #pragma omp target teams loop
  for (...) { /* use scratch */ }
}
#pragma omp target exit data map(delete:scratch[0:n])
```

- **Option 2: omp_target_alloc**
```c
double *scratch = (double*)omp_target_alloc(n*sizeof(double), 0);
#pragma omp target data map(present,alloc:in[0:n])
{
  #pragma omp target teams loop is_device_ptr(scratch)
  for (...) { ... }
}
omp_target_free(scratch, 0);
```

**Mid-computation sync:**
```c
#pragma omp target update from(result)
host_compute(result);
#pragma omp target update to(indices)
```

### STRATEGY B: Asynchronous Offload
Use when: Overlapping compute/transfer possible
```c
#pragma omp target teams loop nowait depend(out:x[0])
for (i = 0; i < N; i++) { x[i] = init(i); }

#pragma omp target teams loop nowait depend(in:x[0]) depend(out:y[0])
for (i = 0; i < N; i++) { y[i] = compute(x[i]); }

#pragma omp taskwait
```

STRATEGY C: Global Device State (Iterative Solvers)
Use omp_target_alloc + is_device_ptr for all device arrays.

**Pattern:**
```c
// Device pointers: static double *d_arr
allocate_device_arrays();  // omp_target_alloc once
copy_to_device();          // omp_target_memcpy once

for (iter ...) {
  #pragma omp target teams is_device_ptr(d_arr1, d_arr2, ...)
  { ... }
}

free_device_arrays();
```

**Key Rules:**
- Use `is_device_ptr` everywhere (no map clauses in hot path)
- Reduction helpers (dot, norm) OK - they return scalars
- stage loops: parallelize outer k,j; keep stage loop L serial
- Iterative solvers: inline SpMV, updates in main loop
---

### 3. Map Globals & Functions
```c
#pragma omp declare target
double helper_func() { ... };
#pragma omp end declare target

#pragma omp declare target(global_var)
```
---

## 4. Parallelize loops

**Parallelization patterns:**

**Type A (Dense):**
```c
#pragma omp target teams loop collapse(2)
for (i = 0; i < N; i++)
  for (j = 0; j < M; j++) ...
```

**Type B (Sparse/CSR) - Nested Parallelism:**
```c
int tmp1, tmp2, tmp3;  // Function scope
#pragma omp target teams loop is_device_ptr(...)
for (int row = 0; row < nrows; row++) {
  tmp1 = rowptr[row];
  tmp2 = rowptr[row+1];
  double sum = 0.0;
  ***#pragma omp loop reduction(+:sum)***  // Parallelize inner *based on GPU saturation* 
  for (int k = tmp1; k < tmp2; k++) {
    tmp3 = colidx[k];
    sum += A[k] * x[tmp3];
  }
  y[row] = sum;
}
```

**Type C1 (Iterative Solvers) - Serial Inner:**
```c
#pragma omp target teams is_device_ptr(...)
{
#pragma omp loop collapse(2)
  for (k = 0; k < K; k++) {
    for (j = 0; j < J; j++) {
      for (stage = 0; stage < S; stage++) { ... }  // No pragma - keep inner serial!
    }
  }
}
**Rationale:** K×J teams already saturate GPU. Inner serial = better register reuse, no barriers.
```

**Type C2 (Multigrid):** Wrap with `present,alloc`; each stencil call gets `target teams loop`.

**Type C special rule:** Stage-dependent algorithms (multigrid, iterative stages) 
should NEVER have inner parallelism, regardless of GPU. The barrier overhead between 
stages exceeds any benefit from inner thread parallelism.

**Type D (Histogram):** Add `#pragma omp atomic` on indirect writes.

**Type F (Reduction):** `reduction(+:sum)`

**Type G (Stencil):** `collapse(2)` on spatial dimensions.

**Type A+E (Outer parallel, inner RNG):** 
**When analysis says "RNG replicable: YES":**
- Add `declare target` on RNG function - GPU callable.
- Parallelize over samples, each thread has private RNG + histogram
- Atomic merge histogram at the end

## Histogram Optimization 
If histogram bins ≤ 100:
```c
// GOOD: Per-thread local array (80 bytes for 10 bins)
#pragma omp target teams loop reduction(+:sx, sy)
for (int k = 0; k < N; ++k) {
  double q_local[BINS] = {0};  // Thread-private
  // ... accumulate into q_local ...
  for (int b = 0; b < BINS; ++b) {
    if (q_local[b] != 0.0) {
      #pragma omp atomic update
      q[b] += q_local[b];
    }
  }
}
```
**DO NOT** create large scratch arrays for small histograms - the atomic overhead is negligible compared to memory transfer costs.
**Key:** Each thread replicates the RNG state for its sample. Type E becomes parallelizable at the OUTER level.

## 5. Compile and Test (CLASS A/S)
```bash
make clean
make CC=nvc++ CLASS=B
timeout 300 env OMP_TARGET_OFFLOAD=MANDATORY make CC=nvc++ CLASS=S run > gpu_output.txt 2>&1
# Fallback: timeout 60 env OMP_TARGET_OFFLOAD=MANDATORY make CC=nvc++ CLASS=S run > gpu_output.txt 2>&1
```

If timeout/segfault: Remove `#pragma omp loop` from Type C inner loops.

## 6. Verify Correctness
```bash
diff baseline_output.txt gpu_output.txt
```

## 8. Profile (CLASS B/C)
```bash
make clean
env OMP_TARGET_OFFLOAD=MANDATORY nsys profile --stats=true --trace=cuda,osrt --force-overwrite=true -o nsys_profile make CC=nvc++ CLASS=C run > /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/profile.log 2>&1
# Fallback: env OMP_TARGET_OFFLOAD=MANDATORY nsys profile --stats=true --trace=cuda,osrt --force-overwrite=true -o nsys_profile make CC=nvc++ CLASS=B run > /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/profile.log 2>&1
grep "cuda_gpu_kern" /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/profile.log | head -5
```

#**RULES** BRAKING A RULE = FAILURE.
- NO GIT COMMANDS.
- DO NOT READ/WRITE OUTSIDE THE WORKING DIRECTORY.
- DO NOT EDIT MAKEFILES.
- ALWAYS CLEAN BEFORE BUILD.
- DO NOT CHANGE/EDIT FILES OTHER THEN - cg.c


you might want to leave comments in the code to explain your changes.

the code might contain macros like GATE_CHECKSUM_* or GATE_STATS_*, you should not change them.

you need to check what hardware you are running on in `system_info.txt` and use the information to optimize your code.


mcp startup: no servers

thinking
**Requesting system information**
exec
/bin/bash -lc pwd in /root/codex_baseline/serial_omp_nas_workdir succeeded in 7ms:
/root/codex_baseline/serial_omp_nas_workdir

thinking
**Locating system_info file**
exec
/bin/bash -lc ls in /root/codex_baseline/serial_omp_nas_workdir succeeded in 8ms:
AGENTS.md
data
ep.c.orig
gate_sdk
golden_labels
npb3.3.1.tar.gz
omp_test.o
system_info.txt
test_all_nas_kernels.sh
exec
/bin/bash -lc 'cat system_info.txt' in /root/codex_baseline/serial_omp_nas_workdir succeeded in 12ms:
=== SYSTEM BASELINE ===
Linux ErelPC 6.6.87.2-microsoft-standard-WSL2 #1 SMP PREEMPT_DYNAMIC Thu Jun  5 18:30:46 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux
PRETTY_NAME="Ubuntu 22.04.3 LTS"
NAME="Ubuntu"
VERSION_ID="22.04"
VERSION="22.04.3 LTS (Jammy Jellyfish)"
VERSION_CODENAME=jammy
ID=ubuntu
ID_LIKE=debian
HOME_URL="https://www.ubuntu.com/"
SUPPORT_URL="https://help.ubuntu.com/"
BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
UBUNTU_CODENAME=jammy
ldd (Ubuntu GLIBC 2.35-0ubuntu3.11) 2.35

=== FIRMWARE & MICROCODE ===
# dmidecode 3.3
Scanning /dev/mem for entry point.
# No SMBIOS nor DMI entry point found, sorry.

thinking
**Preparing backup before modifications**
exec
/bin/bash -lc 'cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && cp cg.c cg.c.backup' in /root/codex_baseline/serial_omp_nas_workdir succeeded in 11ms:


thinking
**Planning file inspection**
exec
/bin/bash -lc 'cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && ls' in /root/codex_baseline/serial_omp_nas_workdir succeeded in 8ms:
Makefile
README.carefully
analysis.md
cg.B.x
cg.c
cg.c.backup
cg.o
common
config
globals.h
npbparams.h
sys

thinking
**Reviewing first 200 lines of cg.c**
exec
/bin/bash -lc "cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && sed -n '1,200p' cg.c" in /root/codex_baseline/serial_omp_nas_workdir succeeded in 11ms:
#ifdef __PGIC__
#undef __GNUC__
#else
#define num_gangs(a)
#define num_workers(a)
#define vector_length(a)
#define gang
#define worker
#define vector
#endif

#include <stdio.h>
#include <stdlib.h>
#include <math.h>

#include "globals.h"
#include "randdp.h"
#include "timers.h"
#include "print_results.h"


thinking
**Requesting more file content**
exec
/bin/bash -lc "cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && sed -n '200,400p' cg.c" in /root/codex_baseline/serial_omp_nas_workdir succeeded in 12ms:
    v80 = 0.0;
    v81 = 0.0;
    for (v74 = 0; v74 < v77; v74++) {
      v81 = v81 + v9[v74] * v9[v74];
    }

    v81 = 1.0 / sqrt(v81);

    for (v74 = 0; v74 < v77; v74++) {     
      v8[v74] = v81 * v9[v74];
    }
  }

  v92 = NA+1;
  for (v73 = 0; v73 < NA+1; v73++) {
    v8[v73] = 1.0;
  }

  v78 = 0.0;


thinking
**Waiting for more input**
exec
/bin/bash -lc "cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && sed -n '400,800p' cg.c" in /root/codex_baseline/serial_omp_nas_workdir succeeded in 8ms:
  }
  v102 = v37[v99] - 1;

  if (v102 > v39) {
    printf("Space for matrix elements exceeded in sparse\n");
    printf("nza, nzmax = %d, %d\n", v102, v39);
    exit(EXIT_FAILURE);
  }

  for (v74 = 0; v74 < v99; v74++) {
    for (v75 = v37[v74]; v75 < v37[v74+1]; v75++) {
      v35[v75] = 0.0;
      v36[v75] = -1;
    }
    v46[v74] = 0;
  }

  v106 = 1.0;
  v108 = pow(v47, (1.0 / (double)(v38)));


thinking
**Preparing to run baseline commands**
exec
/bin/bash -lc 'cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && make clean' in /root/codex_baseline/serial_omp_nas_workdir succeeded in 11ms:
rm -f *.x *.w2c.ptx *.o *.w2c.cu *.w2c.c *.w2c.h *.i *.spin *.B *.s *.t *~ ../common/*.o
rm -f npbparams.h core

thinking
**Running baseline command with environment**
exec
/bin/bash -lc 'cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && timeout 300 env OMP_TARGET_OFFLOAD=MANDATORY make CC=nvc++ CLASS=S run > baseline_output.txt 2>&1' in /root/codex_baseline/serial_omp_nas_workdir succeeded in 1.16s:


thinking
**Planning grep command for output check**
exec
/bin/bash -lc 'cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && grep -E "Verification|SUCCESSFUL|FAILED" baseline_output.txt' in /root/codex_baseline/serial_omp_nas_workdir succeeded in 15ms:
 VERIFICATION SUCCESSFUL
 Verification    =               SUCCESSFUL




thinking
**Analyzing data and array usage for GPU plan**

I'm examining the key arrays and loops in the main timed region to understand which data structures need device allocation and movement. There’s a focus on the iterative solver function and identifying arrays like v1, v2, v7–v12 used across sparse matrix-vector multiplies and vector operations. I want to design a data plan following Strategy C, allocating device arrays via `omp_target_alloc`, minimizing host-device transfers by offloading computations like dot products to GPU, and figuring how to handle post-iteration scalar calculations efficiently without excessive copying. This should set a solid foundation for implementing GPU offloading with OpenMP targeting.
thinking
**Evaluating GPU reduction and data movement strategies**

I'm thinking through how to compute dot products with reductions on device arrays while respecting Strategy C rules (no map clauses for arrays, using `is_device_ptr`). The challenge is accumulating scalar results like `v80` and `v81` on GPU and transferring them efficiently to host without violating rules. Possible approach: allocate device memory for scalar results, perform reductions with atomics or `target teams loop reduction`, then copy scalars back with `omp_target_memcpy`. I’m also considering restructuring `f1` to offload loops to GPU with `#pragma omp target teams loop is_device_ptr`, passing device pointers for arrays and managing scalar reductions inside device code, balancing device-host data transfers and keeping the host-side logic consistent.
thinking
**Designing GPU kernel loops with reductions and data updates**

I’m outlining how to transform the entire `f1` function’s loops into `#pragma omp target teams loop` patterns using the `reduction` clause where needed, with `is_device_ptr` for device arrays. I’m planning to compute dot products and vector updates on the GPU by running separate kernels after `f1`, using `target teams loop reduction` for scalar sums and simple loops for vector scaling. This approach respects the requirement to avoid `distribute parallel for`, keeps scalars mapped implicitly, and passes device pointers explicitly. Next, I’ll focus on implementing these loops and memory transfers carefully.
thinking
**Detailing iteration loop structure and OpenMP usage**

I’m refining the GPU iteration loop logic to compute dot products with reductions and update the vector using `target teams loop` with `firstprivate` for scalar parameters. I’m also clarifying when `f1` needs `#pragma omp declare target`—likely not, since it launches device regions but remains a host function. I plan to verify OpenMP headers are included, possibly through `globals.h`, to ensure proper compiler support for these directives. This setup should keep the device and host interactions clean while executing parallel GPU work safely.
exec
/bin/bash -lc "cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && sed -n '1,200p' globals.h" in /root/codex_baseline/serial_omp_nas_workdir succeeded in 9ms:
//-------------------------------------------------------------------------//
//                                                                         //
//  This benchmark is a serial C version of the NPB CG code. This C        //
//  version is developed by the Center for Manycore Programming at Seoul   //
//  National University and derived from the serial Fortran versions in    //
//  "NPB3.3-SER" developed by NAS.                                         //
//                                                                         //
//  Permission to use, copy, distribute and modify this software for any   //
//  purpose with or without fee is hereby granted. This software is        //
//  provided "as is" without express or implied warranty.                  //
//                                                                         //
//  Information on NPB 3.3, including the technical report, the original   //
//  specifications, source code, results and information on how to submit  //
//  new results, is available at:                                          //
//                                                                         //
//           http://www.nas.nasa.gov/Software/NPB/                         //
//                                                                         //
//  Send comments or suggestions for this C version to cmp@aces.snu.ac.kr  //
//                                                                         //
//          Center for Manycore Programming                                //

thinking
**Outlining multi-step GPU offload plan**

I’m devising a three-step plan to handle GPU offload: first, create a data management strategy and plan; second, implement device memory management and modify the code with OpenMP directives, including adding `#include <omp.h>`; third, compile, run tests, and compare outputs to the baseline. I’ll keep the plan tool updated with task statuses as I proceed.
Plan update
Need a thorough data plan before touching cg.c, then implement Strategy C GPU offload, and finally rebuild and compare results.
  → Document data management plan based on the CG timed region and Strategy C requirements
  • Implement Strategy C offload in cg.c (device allocations, target loops, dot-product kernels, vector updates, include omp.h)
  • Rebuild CLASS S with OMP_TARGET_OFFLOAD=MANDATORY and compare output with baseline

thinking
**Drafting detailed data plan**
file update
A /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
# Data Management Plan

## Arrays Inventory
List ALL arrays used in timed region:

| Array Name | Size | Type | Init | Access |
|------------|------|------|------|--------|
| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
| `v2` | `NA+1` | index | host (set by `f2`) | R |
| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
| `v10` | `NA+2` | working (p vector) | host | R/W |
| `v11` | `NA+2` | working (Ap vector) | host | R/W |
| `v12` | `NA+2` | working (z vector) | host | R/W |

**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.

## Functions in Timed Region
| Function | Arrays Accessed | Frequency | Must Run On |
|----------|------------------|-----------|-------------|
| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |

## Data Movement Strategy

**Chosen Strategy:** C (global device state + `omp_target_alloc`)

**Device Allocations (once):**
- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`

**Host→Device Transfers:**
- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).

**Device→Host Transfers:**
- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
- Arrays: none after initialization.
- Total D→H: scalars only (negligible).

**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.

## Critical Checks (for chosen strategy)

**Strategy C:**
- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).

**Common Mistakes:**
- Some loops still run on host (will be moved into `target teams loop`).
- Forgetting to update CRC scalars on device before each iteration.
- Using host pointers inside device kernels (will use device pointers only).

## Expected Transfer Volume
- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.

## Additional Parallelization Notes
- **RNG Replicable?** NO – no RNG inside timed region.
- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
- **Histogram Strategy?** N/A – no histogram updates in CG.

**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.
apply_patch(auto_approved=true) exited 0 in 6ms:
Success. Updated the following files:
A /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.


thinking
**Updating plan step statuses**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

Plan update
Data plan is recorded. Next I will modify cg.c to allocate device arrays, offload the CG loops, and keep the working set on the GPU.
  ✓ Document data management plan based on the CG timed region and Strategy C requirements
  → Implement Strategy C offload in cg.c (device allocations, target loops, dot-product kernels, vector updates, include omp.h)
  • Rebuild CLASS S with OMP_TARGET_OFFLOAD=MANDATORY and compare output with baseline




thinking
**Planning GPU memory integration**

I'm mapping out how to modify `cg.c` for GPU offloading by adding OpenMP device memory management. I’ll declare static device pointers, allocate and free device arrays, and carefully time host-to-device copies around initialization, warmup, and benchmarking to match the original code’s logic while minimizing data transfers.
thinking
**Designing GPU loop offloading and data management**

I'm figuring out how to rewrite warmup and main loops to run fully on the GPU with OpenMP target teams loops, carefully annotating all parallel loops and handling device pointers. I plan to add helper functions for device memory allocation, freeing, and copying, while ensuring host and device states stay consistent across warmup and timed runs.
thinking
**Planning device pointer setup and memory management**

I'm mapping out how to declare device pointers and implement helper functions for allocating, freeing, and copying arrays between host and GPU device. I want to carefully integrate these calls around initialization, warmup, and timed loops to ensure device and host arrays stay consistent without unnecessary copies that could overwrite GPU-updated data.
thinking
**Detailing device memory copy and loop offloading**

I'm finalizing plans to carefully manage device copies—copying full sets of vectors before warmup but only selective arrays like `v8` after reinitialization—to avoid overwriting device-updated data. I’m also preparing to rewrite the main compute function (`f1`) with OpenMP target directives for parallelism and reduction on the device, restructuring host loops to offload critical dot product and array update operations for GPU acceleration.
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

file update
M /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -14,2 +14,3 @@
 #include <math.h>
+#include <omp.h>
 
apply_patch(auto_approved=true) exited 0 in 9ms:
Success. Updated the following files:
M /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/cg.c
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..f387c70a275b98ee85f7272967a5331d573a91d9
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.


thinking
**Adding global pointer declarations and device info**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..f387c70a275b98ee85f7272967a5331d573a91d9
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

file update
M /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -39,2 +39,13 @@
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
apply_patch(auto_approved=true) exited 0 in 7ms:
Success. Updated the following files:
M /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/cg.c
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..2b59f4e97fa146fee9227b1d5b8df843af9c866c
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.


thinking
**Adding helper function prototypes**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..2b59f4e97fa146fee9227b1d5b8df843af9c866c
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

file update
M /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -101,2 +101,6 @@
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
apply_patch(auto_approved=true) exited 0 in 7ms:
Success. Updated the following files:
M /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/cg.c
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..d0ce8870b3c85493d1fba501ca780d5c0ce413fa
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.


thinking
**Planning device memory integration**

I'm mapping out how to insert device buffer allocation and data copying into the `main` function, focusing on correctly ordering calls between host array adjustments and warmup loops. I'll insert calls to `allocate_device_buffers()` and `copy_csr_to_device()` right after adjusting `v1`, then call `copy_vectors_to_device()` after initializing vectors like `v8`. This careful sequencing ensures data consistency before GPU computations start, and I'll define helper functions later between `main` and `f5`.
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..d0ce8870b3c85493d1fba501ca780d5c0ce413fa
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

file update
M /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -196,2 +196,5 @@
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
apply_patch(auto_approved=true) exited 0 in 19ms:
Success. Updated the following files:
M /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/cg.c
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..24968105544a924e3185e3d43dea40b04c1e945e
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.


thinking
**Inserting device copy call after vector initialization**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..24968105544a924e3185e3d43dea40b04c1e945e
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

file update
M /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -213,2 +213,4 @@
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
apply_patch(auto_approved=true) exited 0 in 6ms:
Success. Updated the following files:
M /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/cg.c
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..7f306754e4259ceb277db0e3091e97cd0e077172
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,6 +211,8 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.


thinking
**Rewriting warmup block with device loops**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..7f306754e4259ceb277db0e3091e97cd0e077172
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,6 +211,8 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.


thinking
**Investigating patch failure**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..7f306754e4259ceb277db0e3091e97cd0e077172
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,6 +211,8 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

exec
/bin/bash -lc "cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && sed -n '140,260p' cg.c" in /root/codex_baseline/serial_omp_nas_workdir succeeded in 26ms:
  timer_start(T_init);

  v15 = 0;
  v16  = NA-1;
  v17 = 0;
  v18  = NA-1;

  if (NA == 1400 && NONZER == 7 && NITER == 15 && SHIFT == 10) {
    v85 = 'S';
    v87 = 8.5971775078648;
  } else if (NA == 7000 && NONZER == 8 && NITER == 15 && SHIFT == 12) {
    v85 = 'W';
    v87 = 10.362595087124;
  } else if (NA == 14000 && NONZER == 11 && NITER == 15 && SHIFT == 20) {
    v85 = 'A';
    v87 = 17.130235054029;
  } else if (NA == 75000 && NONZER == 13 && NITER == 75 && SHIFT == 60) {
    v85 = 'B';
    v87 = 22.712745482631;
  } else if (NA == 150000 && NONZER == 15 && NITER == 75 && SHIFT == 110) {

thinking
**Rewriting scoped initialization block**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..7f306754e4259ceb277db0e3091e97cd0e077172
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,6 +211,8 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

file update
M /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -218,14 +218,15 @@
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
@@ -238,2 +239,4 @@
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+
   v78 = 0.0;
apply_patch(auto_approved=true) exited 0 in 5ms:
Success. Updated the following files:
M /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/cg.c
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..19678ff4dc665c98f6552c54fbbd34e8d2d5dc4c
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.


thinking
**Transforming loop for device execution**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..19678ff4dc665c98f6552c54fbbd34e8d2d5dc4c
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

file update
M /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -249,4 +249,5 @@
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
@@ -254,5 +255,7 @@
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
@@ -266,4 +269,5 @@
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
apply_patch(auto_approved=true) exited 0 in 7ms:
Success. Updated the following files:
M /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/cg.c
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..838e0a88bbe71405e84a54fef3cdfa220d6b9104
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.


thinking
**Preparing device memory management and rewriting main computational function**

I’m making sure device buffers like d_v8 and d_v9 are properly allocated, copied, and freed with helper functions inserted near main, and confirming OpenMP pragmas for device loops are in place. Next, I’m planning to replace the entire large `f1` function with a version rewritten to use target teams loops with device pointers and proper reductions, carefully preserving all logic and variables needed.
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..838e0a88bbe71405e84a54fef3cdfa220d6b9104
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

exec
/bin/bash -lc "cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && sed -n '400,680p' cg.c" in /root/codex_baseline/serial_omp_nas_workdir succeeded in 12ms:
                   int v44,
                   int v45,
                   int v46[],
                   double v47,
                   double v48)
{
  int v99;

  int v73, v74, v100, v101, v102, v75, v103, v104, v105;
  double v106, v107, v108, v109;
  logical v110;

  v99 = v45 - v44 + 1;

  for (v74 = 0; v74 < v99+1; v74++) {
    v37[v74] = 0;
  }

  for (v73 = 0; v73 < v38; v73++) {
    for (v102 = 0; v102 < v41[v73]; v102++) {

thinking
**Replacing entire f1 function with new version**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..838e0a88bbe71405e84a54fef3cdfa220d6b9104
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

file update
M /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -567,3 +567,3 @@
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
@@ -571,7 +571,8 @@
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
@@ -583,28 +584,28 @@
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
@@ -612,16 +613,14 @@
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
@@ -630,5 +629,6 @@
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
@@ -636,9 +636,10 @@
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
@@ -646,10 +647,11 @@
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
-}
   *v70 = sqrt(v123);
apply_patch(auto_approved=true) exited 0 in 9ms:
Success. Updated the following files:
M /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/cg.c
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..c06783542f35af3c2cca10541d86753e9720ff40
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -537,15 +565,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +582,77 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
-}
   *v70 = sqrt(v123);
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.


thinking
**Preparing helper functions and device buffer management**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..c06783542f35af3c2cca10541d86753e9720ff40
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -537,15 +565,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +582,77 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
-}
   *v70 = sqrt(v123);
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

exec
/bin/bash -lc 'cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && rg -n "return 0" -n cg.c' in /root/codex_baseline/serial_omp_nas_workdir succeeded in 21ms:
336:  return 0;

thinking
**Preparing patch near line 336**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..c06783542f35af3c2cca10541d86753e9720ff40
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -537,15 +565,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +582,77 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
-}
   *v70 = sqrt(v123);
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

exec
/bin/bash -lc "cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && sed -n '300,360p' cg.c" in /root/codex_baseline/serial_omp_nas_workdir succeeded in 22ms:
    printf(" NO VERIFICATION PERFORMED\n");
  }

  if (v82 != 0.0) {
    v83 = (double)(2*NITER*NA)
                   * (3.0+(double)(NONZER*(NONZER+1))
                     + 25.0*(5.0+(double)(NONZER*(NONZER+1)))
                     + 3.0) / v82 / 1000000.0;
  } else {
    v83 = 0.0;
  }

  print_results("CG", v85, NA, 0, 0,
                NITER, v82,
                v83, "          floating point", 
                v86, NPBVERSION, COMPILETIME,
                CS1, CS2, CS3, CS4, CS5, CS6, CS7);

  if (v21) {
    v84 = timer_read(T_bench);

thinking
**Inserting memory cleanup before return**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..c06783542f35af3c2cca10541d86753e9720ff40
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -537,15 +565,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +582,77 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
-}
   *v70 = sqrt(v123);
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

file update
M /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -335,2 +335,3 @@
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
apply_patch(auto_approved=true) exited 0 in 6ms:
Success. Updated the following files:
M /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/cg.c
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..a2a2f648f44f08d13d693119e4b102c2560df70d
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,77 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
-}
   *v70 = sqrt(v123);
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.


thinking
**Adding device buffer helper functions**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..a2a2f648f44f08d13d693119e4b102c2560df70d
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,77 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
-}
   *v70 = sqrt(v123);
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.


thinking
**Investigating patch context issues**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..a2a2f648f44f08d13d693119e4b102c2560df70d
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,77 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
-}
   *v70 = sqrt(v123);
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

exec
/bin/bash -lc "cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && sed -n '520,720p' cg.c" in /root/codex_baseline/serial_omp_nas_workdir succeeded in 8ms:
                  int v50,
                  double v51[],
                  int v52[],
                  int v53[],
                  int v54,
                  int v55,
                  int v56,
                  int v57,
                  int v58[],
                  int v59[][NONZER+1],
                  double v60[][NONZER+1],
                  int v61[])
{
  int v111, v112, v113, v114;
  int v115[NONZER+1];
  double v116[NONZER+1];

  v114 = 1;
  do {
    v114 = 2 * v114;

thinking
**Preparing to insert helper functions**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..a2a2f648f44f08d13d693119e4b102c2560df70d
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,77 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
-}
   *v70 = sqrt(v123);
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

file update
M /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -659 +659,73 @@
 }
+
+static void allocate_device_buffers(void)
+{
+  omp_initial_device = omp_get_initial_device();
+  omp_target_device = omp_get_default_device();
+
+  d_v1 = (int *)omp_target_alloc(sizeof(v1), omp_target_device);
+  d_v2 = (int *)omp_target_alloc(sizeof(v2), omp_target_device);
+  d_v7 = (double *)omp_target_alloc(sizeof(v7), omp_target_device);
+  d_v8 = (double *)omp_target_alloc(sizeof(v8), omp_target_device);
+  d_v9 = (double *)omp_target_alloc(sizeof(v9), omp_target_device);
+  d_v10 = (double *)omp_target_alloc(sizeof(v10), omp_target_device);
+  d_v11 = (double *)omp_target_alloc(sizeof(v11), omp_target_device);
+  d_v12 = (double *)omp_target_alloc(sizeof(v12), omp_target_device);
+
+  if (!d_v1 || !d_v2 || !d_v7 || !d_v8 || !d_v9 || !d_v10 || !d_v11 || !d_v12) {
+    fprintf(stderr, "Failed to allocate device buffers\n");
+    exit(EXIT_FAILURE);
+  }
+}
+
+static void copy_csr_to_device(void)
+{
+  omp_target_memcpy(d_v1, v1, sizeof(v1), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v2, v2, sizeof(v2), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v7, v7, sizeof(v7), omp_target_device, omp_initial_device);
+}
+
+static void copy_vectors_to_device(void)
+{
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v9, v9, sizeof(v9), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v10, v10, sizeof(v10), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v11, v11, sizeof(v11), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v12, v12, sizeof(v12), omp_target_device, omp_initial_device);
+}
+
+static void free_device_buffers(void)
+{
+  if (d_v1) {
+    omp_target_free(d_v1, omp_target_device);
+    d_v1 = NULL;
+  }
+  if (d_v2) {
+    omp_target_free(d_v2, omp_target_device);
+    d_v2 = NULL;
+  }
+  if (d_v7) {
+    omp_target_free(d_v7, omp_target_device);
+    d_v7 = NULL;
+  }
+  if (d_v8) {
+    omp_target_free(d_v8, omp_target_device);
+    d_v8 = NULL;
+  }
+  if (d_v9) {
+    omp_target_free(d_v9, omp_target_device);
+    d_v9 = NULL;
+  }
+  if (d_v10) {
+    omp_target_free(d_v10, omp_target_device);
+    d_v10 = NULL;
+  }
+  if (d_v11) {
+    omp_target_free(d_v11, omp_target_device);
+    d_v11 = NULL;
+  }
+  if (d_v12) {
+    omp_target_free(d_v12, omp_target_device);
+    d_v12 = NULL;
+  }
+}
apply_patch(auto_approved=true) exited 0 in 14ms:
Success. Updated the following files:
M /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/cg.c
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..f1179265d57e6c91f2774708d16d0a9dc8a81708
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,149 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
+  *v70 = sqrt(v123);
 }
-  *v70 = sqrt(v123);
+
+static void allocate_device_buffers(void)
+{
+  omp_initial_device = omp_get_initial_device();
+  omp_target_device = omp_get_default_device();
+
+  d_v1 = (int *)omp_target_alloc(sizeof(v1), omp_target_device);
+  d_v2 = (int *)omp_target_alloc(sizeof(v2), omp_target_device);
+  d_v7 = (double *)omp_target_alloc(sizeof(v7), omp_target_device);
+  d_v8 = (double *)omp_target_alloc(sizeof(v8), omp_target_device);
+  d_v9 = (double *)omp_target_alloc(sizeof(v9), omp_target_device);
+  d_v10 = (double *)omp_target_alloc(sizeof(v10), omp_target_device);
+  d_v11 = (double *)omp_target_alloc(sizeof(v11), omp_target_device);
+  d_v12 = (double *)omp_target_alloc(sizeof(v12), omp_target_device);
+
+  if (!d_v1 || !d_v2 || !d_v7 || !d_v8 || !d_v9 || !d_v10 || !d_v11 || !d_v12) {
+    fprintf(stderr, "Failed to allocate device buffers\n");
+    exit(EXIT_FAILURE);
+  }
+}
+
+static void copy_csr_to_device(void)
+{
+  omp_target_memcpy(d_v1, v1, sizeof(v1), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v2, v2, sizeof(v2), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v7, v7, sizeof(v7), omp_target_device, omp_initial_device);
+}
+
+static void copy_vectors_to_device(void)
+{
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v9, v9, sizeof(v9), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v10, v10, sizeof(v10), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v11, v11, sizeof(v11), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v12, v12, sizeof(v12), omp_target_device, omp_initial_device);
+}
+
+static void free_device_buffers(void)
+{
+  if (d_v1) {
+    omp_target_free(d_v1, omp_target_device);
+    d_v1 = NULL;
+  }
+  if (d_v2) {
+    omp_target_free(d_v2, omp_target_device);
+    d_v2 = NULL;
+  }
+  if (d_v7) {
+    omp_target_free(d_v7, omp_target_device);
+    d_v7 = NULL;
+  }
+  if (d_v8) {
+    omp_target_free(d_v8, omp_target_device);
+    d_v8 = NULL;
+  }
+  if (d_v9) {
+    omp_target_free(d_v9, omp_target_device);
+    d_v9 = NULL;
+  }
+  if (d_v10) {
+    omp_target_free(d_v10, omp_target_device);
+    d_v10 = NULL;
+  }
+  if (d_v11) {
+    omp_target_free(d_v11, omp_target_device);
+    d_v11 = NULL;
+  }
+  if (d_v12) {
+    omp_target_free(d_v12, omp_target_device);
+    d_v12 = NULL;
+  }
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.


thinking
**Verifying device buffer handling and function calls**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..f1179265d57e6c91f2774708d16d0a9dc8a81708
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,149 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
+  *v70 = sqrt(v123);
 }
-  *v70 = sqrt(v123);
+
+static void allocate_device_buffers(void)
+{
+  omp_initial_device = omp_get_initial_device();
+  omp_target_device = omp_get_default_device();
+
+  d_v1 = (int *)omp_target_alloc(sizeof(v1), omp_target_device);
+  d_v2 = (int *)omp_target_alloc(sizeof(v2), omp_target_device);
+  d_v7 = (double *)omp_target_alloc(sizeof(v7), omp_target_device);
+  d_v8 = (double *)omp_target_alloc(sizeof(v8), omp_target_device);
+  d_v9 = (double *)omp_target_alloc(sizeof(v9), omp_target_device);
+  d_v10 = (double *)omp_target_alloc(sizeof(v10), omp_target_device);
+  d_v11 = (double *)omp_target_alloc(sizeof(v11), omp_target_device);
+  d_v12 = (double *)omp_target_alloc(sizeof(v12), omp_target_device);
+
+  if (!d_v1 || !d_v2 || !d_v7 || !d_v8 || !d_v9 || !d_v10 || !d_v11 || !d_v12) {
+    fprintf(stderr, "Failed to allocate device buffers\n");
+    exit(EXIT_FAILURE);
+  }
+}
+
+static void copy_csr_to_device(void)
+{
+  omp_target_memcpy(d_v1, v1, sizeof(v1), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v2, v2, sizeof(v2), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v7, v7, sizeof(v7), omp_target_device, omp_initial_device);
+}
+
+static void copy_vectors_to_device(void)
+{
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v9, v9, sizeof(v9), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v10, v10, sizeof(v10), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v11, v11, sizeof(v11), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v12, v12, sizeof(v12), omp_target_device, omp_initial_device);
+}
+
+static void free_device_buffers(void)
+{
+  if (d_v1) {
+    omp_target_free(d_v1, omp_target_device);
+    d_v1 = NULL;
+  }
+  if (d_v2) {
+    omp_target_free(d_v2, omp_target_device);
+    d_v2 = NULL;
+  }
+  if (d_v7) {
+    omp_target_free(d_v7, omp_target_device);
+    d_v7 = NULL;
+  }
+  if (d_v8) {
+    omp_target_free(d_v8, omp_target_device);
+    d_v8 = NULL;
+  }
+  if (d_v9) {
+    omp_target_free(d_v9, omp_target_device);
+    d_v9 = NULL;
+  }
+  if (d_v10) {
+    omp_target_free(d_v10, omp_target_device);
+    d_v10 = NULL;
+  }
+  if (d_v11) {
+    omp_target_free(d_v11, omp_target_device);
+    d_v11 = NULL;
+  }
+  if (d_v12) {
+    omp_target_free(d_v12, omp_target_device);
+    d_v12 = NULL;
+  }
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

exec
/bin/bash -lc "cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && sed -n '80,260p' cg.c" in /root/codex_baseline/serial_omp_nas_workdir succeeded in 12ms:
static void f2(int v49,
                  int v50,
                  double v51[],
                  int v52[],
                  int v53[],
                  int v54,
                  int v55,
                  int v56,
                  int v57,
                  int v58[],
                  int v59[][NONZER+1],
                  double v60[][NONZER+1],
                  int v61[]);
static void f1(int v62[],
                      int v63[],
                      double v64[],
                      double v65[],
                      double v66[],
                      double v67[],
                      double v68[],

thinking
**Verifying loop continuations and pragmas**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..f1179265d57e6c91f2774708d16d0a9dc8a81708
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,149 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
+  *v70 = sqrt(v123);
 }
-  *v70 = sqrt(v123);
+
+static void allocate_device_buffers(void)
+{
+  omp_initial_device = omp_get_initial_device();
+  omp_target_device = omp_get_default_device();
+
+  d_v1 = (int *)omp_target_alloc(sizeof(v1), omp_target_device);
+  d_v2 = (int *)omp_target_alloc(sizeof(v2), omp_target_device);
+  d_v7 = (double *)omp_target_alloc(sizeof(v7), omp_target_device);
+  d_v8 = (double *)omp_target_alloc(sizeof(v8), omp_target_device);
+  d_v9 = (double *)omp_target_alloc(sizeof(v9), omp_target_device);
+  d_v10 = (double *)omp_target_alloc(sizeof(v10), omp_target_device);
+  d_v11 = (double *)omp_target_alloc(sizeof(v11), omp_target_device);
+  d_v12 = (double *)omp_target_alloc(sizeof(v12), omp_target_device);
+
+  if (!d_v1 || !d_v2 || !d_v7 || !d_v8 || !d_v9 || !d_v10 || !d_v11 || !d_v12) {
+    fprintf(stderr, "Failed to allocate device buffers\n");
+    exit(EXIT_FAILURE);
+  }
+}
+
+static void copy_csr_to_device(void)
+{
+  omp_target_memcpy(d_v1, v1, sizeof(v1), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v2, v2, sizeof(v2), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v7, v7, sizeof(v7), omp_target_device, omp_initial_device);
+}
+
+static void copy_vectors_to_device(void)
+{
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v9, v9, sizeof(v9), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v10, v10, sizeof(v10), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v11, v11, sizeof(v11), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v12, v12, sizeof(v12), omp_target_device, omp_initial_device);
+}
+
+static void free_device_buffers(void)
+{
+  if (d_v1) {
+    omp_target_free(d_v1, omp_target_device);
+    d_v1 = NULL;
+  }
+  if (d_v2) {
+    omp_target_free(d_v2, omp_target_device);
+    d_v2 = NULL;
+  }
+  if (d_v7) {
+    omp_target_free(d_v7, omp_target_device);
+    d_v7 = NULL;
+  }
+  if (d_v8) {
+    omp_target_free(d_v8, omp_target_device);
+    d_v8 = NULL;
+  }
+  if (d_v9) {
+    omp_target_free(d_v9, omp_target_device);
+    d_v9 = NULL;
+  }
+  if (d_v10) {
+    omp_target_free(d_v10, omp_target_device);
+    d_v10 = NULL;
+  }
+  if (d_v11) {
+    omp_target_free(d_v11, omp_target_device);
+    d_v11 = NULL;
+  }
+  if (d_v12) {
+    omp_target_free(d_v12, omp_target_device);
+    d_v12 = NULL;
+  }
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

exec
/bin/bash -lc "cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && sed -n '260,360p' cg.c" in /root/codex_baseline/serial_omp_nas_workdir succeeded in 13ms:
      v81 += tmp * tmp;
    }

    v81 = 1.0 / sqrt(v81);

    v78 = SHIFT + 1.0 / v80;
    if (v76 == 1) 
      printf("\n   iteration           ||r||                 zeta\n");
    printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);

    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
    for (v74 = 0; v74 < v77; v74++) {
      d_v8[v74] = v81 * d_v9[v74];
    }
  }

  timer_stop(T_bench);
}

  v82 = timer_read(T_bench);

thinking
**Verifying OpenMP and device buffer integration**

I'm checking that the block and loop structures with OpenMP pragmas are correctly placed, ensuring device memory allocation, copying, and freeing are properly ordered and consistent. I want to confirm function declarations, include directives, and pointer usage align with the expected flow, then update the plan to mark the implementation complete before building and running tests.
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..f1179265d57e6c91f2774708d16d0a9dc8a81708
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,149 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
+  *v70 = sqrt(v123);
 }
-  *v70 = sqrt(v123);
+
+static void allocate_device_buffers(void)
+{
+  omp_initial_device = omp_get_initial_device();
+  omp_target_device = omp_get_default_device();
+
+  d_v1 = (int *)omp_target_alloc(sizeof(v1), omp_target_device);
+  d_v2 = (int *)omp_target_alloc(sizeof(v2), omp_target_device);
+  d_v7 = (double *)omp_target_alloc(sizeof(v7), omp_target_device);
+  d_v8 = (double *)omp_target_alloc(sizeof(v8), omp_target_device);
+  d_v9 = (double *)omp_target_alloc(sizeof(v9), omp_target_device);
+  d_v10 = (double *)omp_target_alloc(sizeof(v10), omp_target_device);
+  d_v11 = (double *)omp_target_alloc(sizeof(v11), omp_target_device);
+  d_v12 = (double *)omp_target_alloc(sizeof(v12), omp_target_device);
+
+  if (!d_v1 || !d_v2 || !d_v7 || !d_v8 || !d_v9 || !d_v10 || !d_v11 || !d_v12) {
+    fprintf(stderr, "Failed to allocate device buffers\n");
+    exit(EXIT_FAILURE);
+  }
+}
+
+static void copy_csr_to_device(void)
+{
+  omp_target_memcpy(d_v1, v1, sizeof(v1), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v2, v2, sizeof(v2), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v7, v7, sizeof(v7), omp_target_device, omp_initial_device);
+}
+
+static void copy_vectors_to_device(void)
+{
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v9, v9, sizeof(v9), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v10, v10, sizeof(v10), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v11, v11, sizeof(v11), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v12, v12, sizeof(v12), omp_target_device, omp_initial_device);
+}
+
+static void free_device_buffers(void)
+{
+  if (d_v1) {
+    omp_target_free(d_v1, omp_target_device);
+    d_v1 = NULL;
+  }
+  if (d_v2) {
+    omp_target_free(d_v2, omp_target_device);
+    d_v2 = NULL;
+  }
+  if (d_v7) {
+    omp_target_free(d_v7, omp_target_device);
+    d_v7 = NULL;
+  }
+  if (d_v8) {
+    omp_target_free(d_v8, omp_target_device);
+    d_v8 = NULL;
+  }
+  if (d_v9) {
+    omp_target_free(d_v9, omp_target_device);
+    d_v9 = NULL;
+  }
+  if (d_v10) {
+    omp_target_free(d_v10, omp_target_device);
+    d_v10 = NULL;
+  }
+  if (d_v11) {
+    omp_target_free(d_v11, omp_target_device);
+    d_v11 = NULL;
+  }
+  if (d_v12) {
+    omp_target_free(d_v12, omp_target_device);
+    d_v12 = NULL;
+  }
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

Plan update
Code now allocates device buffers, keeps CSR/vectors on the GPU, and offloads the inner CG loops and reductions. The next step is to rebuild/run the benchmark and capture the new output.
  ✓ Document data management plan based on the CG timed region and Strategy C requirements
  ✓ Implement Strategy C offload in cg.c (device allocations, target loops, dot-product kernels, vector updates, include omp.h)
  → Rebuild CLASS S with OMP_TARGET_OFFLOAD=MANDATORY and compare output with baseline

thinking
**Preparing to run build and tests**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..f1179265d57e6c91f2774708d16d0a9dc8a81708
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,149 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
+  *v70 = sqrt(v123);
 }
-  *v70 = sqrt(v123);
+
+static void allocate_device_buffers(void)
+{
+  omp_initial_device = omp_get_initial_device();
+  omp_target_device = omp_get_default_device();
+
+  d_v1 = (int *)omp_target_alloc(sizeof(v1), omp_target_device);
+  d_v2 = (int *)omp_target_alloc(sizeof(v2), omp_target_device);
+  d_v7 = (double *)omp_target_alloc(sizeof(v7), omp_target_device);
+  d_v8 = (double *)omp_target_alloc(sizeof(v8), omp_target_device);
+  d_v9 = (double *)omp_target_alloc(sizeof(v9), omp_target_device);
+  d_v10 = (double *)omp_target_alloc(sizeof(v10), omp_target_device);
+  d_v11 = (double *)omp_target_alloc(sizeof(v11), omp_target_device);
+  d_v12 = (double *)omp_target_alloc(sizeof(v12), omp_target_device);
+
+  if (!d_v1 || !d_v2 || !d_v7 || !d_v8 || !d_v9 || !d_v10 || !d_v11 || !d_v12) {
+    fprintf(stderr, "Failed to allocate device buffers\n");
+    exit(EXIT_FAILURE);
+  }
+}
+
+static void copy_csr_to_device(void)
+{
+  omp_target_memcpy(d_v1, v1, sizeof(v1), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v2, v2, sizeof(v2), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v7, v7, sizeof(v7), omp_target_device, omp_initial_device);
+}
+
+static void copy_vectors_to_device(void)
+{
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v9, v9, sizeof(v9), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v10, v10, sizeof(v10), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v11, v11, sizeof(v11), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v12, v12, sizeof(v12), omp_target_device, omp_initial_device);
+}
+
+static void free_device_buffers(void)
+{
+  if (d_v1) {
+    omp_target_free(d_v1, omp_target_device);
+    d_v1 = NULL;
+  }
+  if (d_v2) {
+    omp_target_free(d_v2, omp_target_device);
+    d_v2 = NULL;
+  }
+  if (d_v7) {
+    omp_target_free(d_v7, omp_target_device);
+    d_v7 = NULL;
+  }
+  if (d_v8) {
+    omp_target_free(d_v8, omp_target_device);
+    d_v8 = NULL;
+  }
+  if (d_v9) {
+    omp_target_free(d_v9, omp_target_device);
+    d_v9 = NULL;
+  }
+  if (d_v10) {
+    omp_target_free(d_v10, omp_target_device);
+    d_v10 = NULL;
+  }
+  if (d_v11) {
+    omp_target_free(d_v11, omp_target_device);
+    d_v11 = NULL;
+  }
+  if (d_v12) {
+    omp_target_free(d_v12, omp_target_device);
+    d_v12 = NULL;
+  }
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

exec
/bin/bash -lc 'cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && make clean' in /root/codex_baseline/serial_omp_nas_workdir succeeded in 30ms:
rm -f *.x *.w2c.ptx *.o *.w2c.cu *.w2c.c *.w2c.h *.i *.spin *.B *.s *.t *~ ../common/*.o
rm -f npbparams.h core

thinking
**Executing GPU build and run command**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..f1179265d57e6c91f2774708d16d0a9dc8a81708
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,149 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
+  *v70 = sqrt(v123);
 }
-  *v70 = sqrt(v123);
+
+static void allocate_device_buffers(void)
+{
+  omp_initial_device = omp_get_initial_device();
+  omp_target_device = omp_get_default_device();
+
+  d_v1 = (int *)omp_target_alloc(sizeof(v1), omp_target_device);
+  d_v2 = (int *)omp_target_alloc(sizeof(v2), omp_target_device);
+  d_v7 = (double *)omp_target_alloc(sizeof(v7), omp_target_device);
+  d_v8 = (double *)omp_target_alloc(sizeof(v8), omp_target_device);
+  d_v9 = (double *)omp_target_alloc(sizeof(v9), omp_target_device);
+  d_v10 = (double *)omp_target_alloc(sizeof(v10), omp_target_device);
+  d_v11 = (double *)omp_target_alloc(sizeof(v11), omp_target_device);
+  d_v12 = (double *)omp_target_alloc(sizeof(v12), omp_target_device);
+
+  if (!d_v1 || !d_v2 || !d_v7 || !d_v8 || !d_v9 || !d_v10 || !d_v11 || !d_v12) {
+    fprintf(stderr, "Failed to allocate device buffers\n");
+    exit(EXIT_FAILURE);
+  }
+}
+
+static void copy_csr_to_device(void)
+{
+  omp_target_memcpy(d_v1, v1, sizeof(v1), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v2, v2, sizeof(v2), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v7, v7, sizeof(v7), omp_target_device, omp_initial_device);
+}
+
+static void copy_vectors_to_device(void)
+{
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v9, v9, sizeof(v9), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v10, v10, sizeof(v10), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v11, v11, sizeof(v11), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v12, v12, sizeof(v12), omp_target_device, omp_initial_device);
+}
+
+static void free_device_buffers(void)
+{
+  if (d_v1) {
+    omp_target_free(d_v1, omp_target_device);
+    d_v1 = NULL;
+  }
+  if (d_v2) {
+    omp_target_free(d_v2, omp_target_device);
+    d_v2 = NULL;
+  }
+  if (d_v7) {
+    omp_target_free(d_v7, omp_target_device);
+    d_v7 = NULL;
+  }
+  if (d_v8) {
+    omp_target_free(d_v8, omp_target_device);
+    d_v8 = NULL;
+  }
+  if (d_v9) {
+    omp_target_free(d_v9, omp_target_device);
+    d_v9 = NULL;
+  }
+  if (d_v10) {
+    omp_target_free(d_v10, omp_target_device);
+    d_v10 = NULL;
+  }
+  if (d_v11) {
+    omp_target_free(d_v11, omp_target_device);
+    d_v11 = NULL;
+  }
+  if (d_v12) {
+    omp_target_free(d_v12, omp_target_device);
+    d_v12 = NULL;
+  }
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

exec
/bin/bash -lc 'cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && timeout 300 env OMP_TARGET_OFFLOAD=MANDATORY make CC=nvc++ CLASS=S run > gpu_output.txt 2>&1' in /root/codex_baseline/serial_omp_nas_workdir exited 2 in 369ms:


thinking
**Checking build errors**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..f1179265d57e6c91f2774708d16d0a9dc8a81708
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,149 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
+  *v70 = sqrt(v123);
 }
-  *v70 = sqrt(v123);
+
+static void allocate_device_buffers(void)
+{
+  omp_initial_device = omp_get_initial_device();
+  omp_target_device = omp_get_default_device();
+
+  d_v1 = (int *)omp_target_alloc(sizeof(v1), omp_target_device);
+  d_v2 = (int *)omp_target_alloc(sizeof(v2), omp_target_device);
+  d_v7 = (double *)omp_target_alloc(sizeof(v7), omp_target_device);
+  d_v8 = (double *)omp_target_alloc(sizeof(v8), omp_target_device);
+  d_v9 = (double *)omp_target_alloc(sizeof(v9), omp_target_device);
+  d_v10 = (double *)omp_target_alloc(sizeof(v10), omp_target_device);
+  d_v11 = (double *)omp_target_alloc(sizeof(v11), omp_target_device);
+  d_v12 = (double *)omp_target_alloc(sizeof(v12), omp_target_device);
+
+  if (!d_v1 || !d_v2 || !d_v7 || !d_v8 || !d_v9 || !d_v10 || !d_v11 || !d_v12) {
+    fprintf(stderr, "Failed to allocate device buffers\n");
+    exit(EXIT_FAILURE);
+  }
+}
+
+static void copy_csr_to_device(void)
+{
+  omp_target_memcpy(d_v1, v1, sizeof(v1), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v2, v2, sizeof(v2), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v7, v7, sizeof(v7), omp_target_device, omp_initial_device);
+}
+
+static void copy_vectors_to_device(void)
+{
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v9, v9, sizeof(v9), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v10, v10, sizeof(v10), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v11, v11, sizeof(v11), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v12, v12, sizeof(v12), omp_target_device, omp_initial_device);
+}
+
+static void free_device_buffers(void)
+{
+  if (d_v1) {
+    omp_target_free(d_v1, omp_target_device);
+    d_v1 = NULL;
+  }
+  if (d_v2) {
+    omp_target_free(d_v2, omp_target_device);
+    d_v2 = NULL;
+  }
+  if (d_v7) {
+    omp_target_free(d_v7, omp_target_device);
+    d_v7 = NULL;
+  }
+  if (d_v8) {
+    omp_target_free(d_v8, omp_target_device);
+    d_v8 = NULL;
+  }
+  if (d_v9) {
+    omp_target_free(d_v9, omp_target_device);
+    d_v9 = NULL;
+  }
+  if (d_v10) {
+    omp_target_free(d_v10, omp_target_device);
+    d_v10 = NULL;
+  }
+  if (d_v11) {
+    omp_target_free(d_v11, omp_target_device);
+    d_v11 = NULL;
+  }
+  if (d_v12) {
+    omp_target_free(d_v12, omp_target_device);
+    d_v12 = NULL;
+  }
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

exec
/bin/bash -lc 'cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && cat gpu_output.txt' in /root/codex_baseline/serial_omp_nas_workdir succeeded in 21ms:
make.def modified. Rebuilding npbparams.h just in case
rm -f npbparams.h sys/npbparams.h
cd sys && ./setparams cg S && mv npbparams.h ..
nvc++  -c -Icommon -I/root/codex_baseline/serial_omp_nas_workdir/gate_sdk -O3 -mp=gpu -gpu=ccall -Minfo=accel -mcmodel=medium cg.c
"cg.c", line 132: warning: conversion from a string literal to "char *" is deprecated [deprecated_string_conv]
      v90[T_init] = "init";
                  ^

Remark: individual warnings can be suppressed with "--diag_suppress <warning-name>"

"cg.c", line 133: warning: conversion from a string literal to "char *" is deprecated [deprecated_string_conv]
      v90[T_bench] = "benchmk";
                   ^

"cg.c", line 134: warning: conversion from a string literal to "char *" is deprecated [deprecated_string_conv]
      v90[T_conj_grad] = "conjgd";
                       ^

"cg.c", line 240: error: too few arguments in function call
    omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);

thinking
**Investigating omp_target_memcpy signature discrepancy**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..f1179265d57e6c91f2774708d16d0a9dc8a81708
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,149 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
+  *v70 = sqrt(v123);
 }
-  *v70 = sqrt(v123);
+
+static void allocate_device_buffers(void)
+{
+  omp_initial_device = omp_get_initial_device();
+  omp_target_device = omp_get_default_device();
+
+  d_v1 = (int *)omp_target_alloc(sizeof(v1), omp_target_device);
+  d_v2 = (int *)omp_target_alloc(sizeof(v2), omp_target_device);
+  d_v7 = (double *)omp_target_alloc(sizeof(v7), omp_target_device);
+  d_v8 = (double *)omp_target_alloc(sizeof(v8), omp_target_device);
+  d_v9 = (double *)omp_target_alloc(sizeof(v9), omp_target_device);
+  d_v10 = (double *)omp_target_alloc(sizeof(v10), omp_target_device);
+  d_v11 = (double *)omp_target_alloc(sizeof(v11), omp_target_device);
+  d_v12 = (double *)omp_target_alloc(sizeof(v12), omp_target_device);
+
+  if (!d_v1 || !d_v2 || !d_v7 || !d_v8 || !d_v9 || !d_v10 || !d_v11 || !d_v12) {
+    fprintf(stderr, "Failed to allocate device buffers\n");
+    exit(EXIT_FAILURE);
+  }
+}
+
+static void copy_csr_to_device(void)
+{
+  omp_target_memcpy(d_v1, v1, sizeof(v1), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v2, v2, sizeof(v2), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v7, v7, sizeof(v7), omp_target_device, omp_initial_device);
+}
+
+static void copy_vectors_to_device(void)
+{
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v9, v9, sizeof(v9), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v10, v10, sizeof(v10), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v11, v11, sizeof(v11), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v12, v12, sizeof(v12), omp_target_device, omp_initial_device);
+}
+
+static void free_device_buffers(void)
+{
+  if (d_v1) {
+    omp_target_free(d_v1, omp_target_device);
+    d_v1 = NULL;
+  }
+  if (d_v2) {
+    omp_target_free(d_v2, omp_target_device);
+    d_v2 = NULL;
+  }
+  if (d_v7) {
+    omp_target_free(d_v7, omp_target_device);
+    d_v7 = NULL;
+  }
+  if (d_v8) {
+    omp_target_free(d_v8, omp_target_device);
+    d_v8 = NULL;
+  }
+  if (d_v9) {
+    omp_target_free(d_v9, omp_target_device);
+    d_v9 = NULL;
+  }
+  if (d_v10) {
+    omp_target_free(d_v10, omp_target_device);
+    d_v10 = NULL;
+  }
+  if (d_v11) {
+    omp_target_free(d_v11, omp_target_device);
+    d_v11 = NULL;
+  }
+  if (d_v12) {
+    omp_target_free(d_v12, omp_target_device);
+    d_v12 = NULL;
+  }
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

exec
/bin/bash -lc 'rg -n "omp_target_memcpy" -n /opt/nvidia/hpc_sdk/Linux_x86_64/25.7/compilers/include/omp.h' in /root/codex_baseline/serial_omp_nas_workdir succeeded in 11ms:
291:extern int omp_target_memcpy(void *dst, const void *src, size_t length, size_t dst_offset, size_t src_offset, int dst_device_num, int src_device_num);
292:extern int omp_target_memcpy_rect(void *dst, const void *src, size_t element_size, int num_dims,
296:extern int omp_target_memcpy_async(void *dst, const void *src, size_t length, size_t dst_offset, size_t src_offset, int dst_device_num, int src_device_num, int depobj_count, omp_depend_t *depobj_list);
297:extern int omp_target_memcpy_rect_async(void *dst, const void *src, size_t element_size, int num_dims,
444:extern int omp_target_memcpy();
445:extern int omp_target_memcpy_rect();
446:extern int omp_target_memcpy_async();
447:extern int omp_target_memcpy_rect_async();

thinking
**Adjusting omp_target_memcpy calls with offsets**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..f1179265d57e6c91f2774708d16d0a9dc8a81708
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,149 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
+  *v70 = sqrt(v123);
 }
-  *v70 = sqrt(v123);
+
+static void allocate_device_buffers(void)
+{
+  omp_initial_device = omp_get_initial_device();
+  omp_target_device = omp_get_default_device();
+
+  d_v1 = (int *)omp_target_alloc(sizeof(v1), omp_target_device);
+  d_v2 = (int *)omp_target_alloc(sizeof(v2), omp_target_device);
+  d_v7 = (double *)omp_target_alloc(sizeof(v7), omp_target_device);
+  d_v8 = (double *)omp_target_alloc(sizeof(v8), omp_target_device);
+  d_v9 = (double *)omp_target_alloc(sizeof(v9), omp_target_device);
+  d_v10 = (double *)omp_target_alloc(sizeof(v10), omp_target_device);
+  d_v11 = (double *)omp_target_alloc(sizeof(v11), omp_target_device);
+  d_v12 = (double *)omp_target_alloc(sizeof(v12), omp_target_device);
+
+  if (!d_v1 || !d_v2 || !d_v7 || !d_v8 || !d_v9 || !d_v10 || !d_v11 || !d_v12) {
+    fprintf(stderr, "Failed to allocate device buffers\n");
+    exit(EXIT_FAILURE);
+  }
+}
+
+static void copy_csr_to_device(void)
+{
+  omp_target_memcpy(d_v1, v1, sizeof(v1), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v2, v2, sizeof(v2), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v7, v7, sizeof(v7), omp_target_device, omp_initial_device);
+}
+
+static void copy_vectors_to_device(void)
+{
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v9, v9, sizeof(v9), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v10, v10, sizeof(v10), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v11, v11, sizeof(v11), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v12, v12, sizeof(v12), omp_target_device, omp_initial_device);
+}
+
+static void free_device_buffers(void)
+{
+  if (d_v1) {
+    omp_target_free(d_v1, omp_target_device);
+    d_v1 = NULL;
+  }
+  if (d_v2) {
+    omp_target_free(d_v2, omp_target_device);
+    d_v2 = NULL;
+  }
+  if (d_v7) {
+    omp_target_free(d_v7, omp_target_device);
+    d_v7 = NULL;
+  }
+  if (d_v8) {
+    omp_target_free(d_v8, omp_target_device);
+    d_v8 = NULL;
+  }
+  if (d_v9) {
+    omp_target_free(d_v9, omp_target_device);
+    d_v9 = NULL;
+  }
+  if (d_v10) {
+    omp_target_free(d_v10, omp_target_device);
+    d_v10 = NULL;
+  }
+  if (d_v11) {
+    omp_target_free(d_v11, omp_target_device);
+    d_v11 = NULL;
+  }
+  if (d_v12) {
+    omp_target_free(d_v12, omp_target_device);
+    d_v12 = NULL;
+  }
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

exec
/bin/bash -lc 'cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && rg -n "omp_target_memcpy" -n cg.c' in /root/codex_baseline/serial_omp_nas_workdir succeeded in 12ms:
240:  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
683:  omp_target_memcpy(d_v1, v1, sizeof(v1), omp_target_device, omp_initial_device);
684:  omp_target_memcpy(d_v2, v2, sizeof(v2), omp_target_device, omp_initial_device);
685:  omp_target_memcpy(d_v7, v7, sizeof(v7), omp_target_device, omp_initial_device);
690:  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
691:  omp_target_memcpy(d_v9, v9, sizeof(v9), omp_target_device, omp_initial_device);
692:  omp_target_memcpy(d_v10, v10, sizeof(v10), omp_target_device, omp_initial_device);
693:  omp_target_memcpy(d_v11, v11, sizeof(v11), omp_target_device, omp_initial_device);
694:  omp_target_memcpy(d_v12, v12, sizeof(v12), omp_target_device, omp_initial_device);

thinking
**Adding offset arguments to memory copy calls**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..f1179265d57e6c91f2774708d16d0a9dc8a81708
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,149 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
+  *v70 = sqrt(v123);
 }
-  *v70 = sqrt(v123);
+
+static void allocate_device_buffers(void)
+{
+  omp_initial_device = omp_get_initial_device();
+  omp_target_device = omp_get_default_device();
+
+  d_v1 = (int *)omp_target_alloc(sizeof(v1), omp_target_device);
+  d_v2 = (int *)omp_target_alloc(sizeof(v2), omp_target_device);
+  d_v7 = (double *)omp_target_alloc(sizeof(v7), omp_target_device);
+  d_v8 = (double *)omp_target_alloc(sizeof(v8), omp_target_device);
+  d_v9 = (double *)omp_target_alloc(sizeof(v9), omp_target_device);
+  d_v10 = (double *)omp_target_alloc(sizeof(v10), omp_target_device);
+  d_v11 = (double *)omp_target_alloc(sizeof(v11), omp_target_device);
+  d_v12 = (double *)omp_target_alloc(sizeof(v12), omp_target_device);
+
+  if (!d_v1 || !d_v2 || !d_v7 || !d_v8 || !d_v9 || !d_v10 || !d_v11 || !d_v12) {
+    fprintf(stderr, "Failed to allocate device buffers\n");
+    exit(EXIT_FAILURE);
+  }
+}
+
+static void copy_csr_to_device(void)
+{
+  omp_target_memcpy(d_v1, v1, sizeof(v1), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v2, v2, sizeof(v2), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v7, v7, sizeof(v7), omp_target_device, omp_initial_device);
+}
+
+static void copy_vectors_to_device(void)
+{
+  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v9, v9, sizeof(v9), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v10, v10, sizeof(v10), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v11, v11, sizeof(v11), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v12, v12, sizeof(v12), omp_target_device, omp_initial_device);
+}
+
+static void free_device_buffers(void)
+{
+  if (d_v1) {
+    omp_target_free(d_v1, omp_target_device);
+    d_v1 = NULL;
+  }
+  if (d_v2) {
+    omp_target_free(d_v2, omp_target_device);
+    d_v2 = NULL;
+  }
+  if (d_v7) {
+    omp_target_free(d_v7, omp_target_device);
+    d_v7 = NULL;
+  }
+  if (d_v8) {
+    omp_target_free(d_v8, omp_target_device);
+    d_v8 = NULL;
+  }
+  if (d_v9) {
+    omp_target_free(d_v9, omp_target_device);
+    d_v9 = NULL;
+  }
+  if (d_v10) {
+    omp_target_free(d_v10, omp_target_device);
+    d_v10 = NULL;
+  }
+  if (d_v11) {
+    omp_target_free(d_v11, omp_target_device);
+    d_v11 = NULL;
+  }
+  if (d_v12) {
+    omp_target_free(d_v12, omp_target_device);
+    d_v12 = NULL;
+  }
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

file update
M /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -239,3 +239,3 @@
 
-  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
 
@@ -682,5 +682,5 @@
 {
-  omp_target_memcpy(d_v1, v1, sizeof(v1), omp_target_device, omp_initial_device);
-  omp_target_memcpy(d_v2, v2, sizeof(v2), omp_target_device, omp_initial_device);
-  omp_target_memcpy(d_v7, v7, sizeof(v7), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v1, v1, sizeof(v1), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v2, v2, sizeof(v2), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v7, v7, sizeof(v7), 0, 0, omp_target_device, omp_initial_device);
 }
@@ -689,7 +689,7 @@
 {
-  omp_target_memcpy(d_v8, v8, sizeof(v8), omp_target_device, omp_initial_device);
-  omp_target_memcpy(d_v9, v9, sizeof(v9), omp_target_device, omp_initial_device);
-  omp_target_memcpy(d_v10, v10, sizeof(v10), omp_target_device, omp_initial_device);
-  omp_target_memcpy(d_v11, v11, sizeof(v11), omp_target_device, omp_initial_device);
-  omp_target_memcpy(d_v12, v12, sizeof(v12), omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v9, v9, sizeof(v9), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v10, v10, sizeof(v10), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v11, v11, sizeof(v11), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v12, v12, sizeof(v12), 0, 0, omp_target_device, omp_initial_device);
 }
apply_patch(auto_approved=true) exited 0 in 7ms:
Success. Updated the following files:
M /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp/cg.c
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..39d6e9842beddb8786ede811e556fdb1a57af567
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,149 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
+  *v70 = sqrt(v123);
 }
-  *v70 = sqrt(v123);
+
+static void allocate_device_buffers(void)
+{
+  omp_initial_device = omp_get_initial_device();
+  omp_target_device = omp_get_default_device();
+
+  d_v1 = (int *)omp_target_alloc(sizeof(v1), omp_target_device);
+  d_v2 = (int *)omp_target_alloc(sizeof(v2), omp_target_device);
+  d_v7 = (double *)omp_target_alloc(sizeof(v7), omp_target_device);
+  d_v8 = (double *)omp_target_alloc(sizeof(v8), omp_target_device);
+  d_v9 = (double *)omp_target_alloc(sizeof(v9), omp_target_device);
+  d_v10 = (double *)omp_target_alloc(sizeof(v10), omp_target_device);
+  d_v11 = (double *)omp_target_alloc(sizeof(v11), omp_target_device);
+  d_v12 = (double *)omp_target_alloc(sizeof(v12), omp_target_device);
+
+  if (!d_v1 || !d_v2 || !d_v7 || !d_v8 || !d_v9 || !d_v10 || !d_v11 || !d_v12) {
+    fprintf(stderr, "Failed to allocate device buffers\n");
+    exit(EXIT_FAILURE);
+  }
+}
+
+static void copy_csr_to_device(void)
+{
+  omp_target_memcpy(d_v1, v1, sizeof(v1), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v2, v2, sizeof(v2), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v7, v7, sizeof(v7), 0, 0, omp_target_device, omp_initial_device);
+}
+
+static void copy_vectors_to_device(void)
+{
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v9, v9, sizeof(v9), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v10, v10, sizeof(v10), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v11, v11, sizeof(v11), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v12, v12, sizeof(v12), 0, 0, omp_target_device, omp_initial_device);
+}
+
+static void free_device_buffers(void)
+{
+  if (d_v1) {
+    omp_target_free(d_v1, omp_target_device);
+    d_v1 = NULL;
+  }
+  if (d_v2) {
+    omp_target_free(d_v2, omp_target_device);
+    d_v2 = NULL;
+  }
+  if (d_v7) {
+    omp_target_free(d_v7, omp_target_device);
+    d_v7 = NULL;
+  }
+  if (d_v8) {
+    omp_target_free(d_v8, omp_target_device);
+    d_v8 = NULL;
+  }
+  if (d_v9) {
+    omp_target_free(d_v9, omp_target_device);
+    d_v9 = NULL;
+  }
+  if (d_v10) {
+    omp_target_free(d_v10, omp_target_device);
+    d_v10 = NULL;
+  }
+  if (d_v11) {
+    omp_target_free(d_v11, omp_target_device);
+    d_v11 = NULL;
+  }
+  if (d_v12) {
+    omp_target_free(d_v12, omp_target_device);
+    d_v12 = NULL;
+  }
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.


thinking
**Verifying all omp_target_memcpy replacements**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..39d6e9842beddb8786ede811e556fdb1a57af567
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,149 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
+  *v70 = sqrt(v123);
 }
-  *v70 = sqrt(v123);
+
+static void allocate_device_buffers(void)
+{
+  omp_initial_device = omp_get_initial_device();
+  omp_target_device = omp_get_default_device();
+
+  d_v1 = (int *)omp_target_alloc(sizeof(v1), omp_target_device);
+  d_v2 = (int *)omp_target_alloc(sizeof(v2), omp_target_device);
+  d_v7 = (double *)omp_target_alloc(sizeof(v7), omp_target_device);
+  d_v8 = (double *)omp_target_alloc(sizeof(v8), omp_target_device);
+  d_v9 = (double *)omp_target_alloc(sizeof(v9), omp_target_device);
+  d_v10 = (double *)omp_target_alloc(sizeof(v10), omp_target_device);
+  d_v11 = (double *)omp_target_alloc(sizeof(v11), omp_target_device);
+  d_v12 = (double *)omp_target_alloc(sizeof(v12), omp_target_device);
+
+  if (!d_v1 || !d_v2 || !d_v7 || !d_v8 || !d_v9 || !d_v10 || !d_v11 || !d_v12) {
+    fprintf(stderr, "Failed to allocate device buffers\n");
+    exit(EXIT_FAILURE);
+  }
+}
+
+static void copy_csr_to_device(void)
+{
+  omp_target_memcpy(d_v1, v1, sizeof(v1), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v2, v2, sizeof(v2), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v7, v7, sizeof(v7), 0, 0, omp_target_device, omp_initial_device);
+}
+
+static void copy_vectors_to_device(void)
+{
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v9, v9, sizeof(v9), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v10, v10, sizeof(v10), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v11, v11, sizeof(v11), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v12, v12, sizeof(v12), 0, 0, omp_target_device, omp_initial_device);
+}
+
+static void free_device_buffers(void)
+{
+  if (d_v1) {
+    omp_target_free(d_v1, omp_target_device);
+    d_v1 = NULL;
+  }
+  if (d_v2) {
+    omp_target_free(d_v2, omp_target_device);
+    d_v2 = NULL;
+  }
+  if (d_v7) {
+    omp_target_free(d_v7, omp_target_device);
+    d_v7 = NULL;
+  }
+  if (d_v8) {
+    omp_target_free(d_v8, omp_target_device);
+    d_v8 = NULL;
+  }
+  if (d_v9) {
+    omp_target_free(d_v9, omp_target_device);
+    d_v9 = NULL;
+  }
+  if (d_v10) {
+    omp_target_free(d_v10, omp_target_device);
+    d_v10 = NULL;
+  }
+  if (d_v11) {
+    omp_target_free(d_v11, omp_target_device);
+    d_v11 = NULL;
+  }
+  if (d_v12) {
+    omp_target_free(d_v12, omp_target_device);
+    d_v12 = NULL;
+  }
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

exec
/bin/bash -lc 'cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && rg -n "omp_target_memcpy" cg.c' in /root/codex_baseline/serial_omp_nas_workdir succeeded in 46ms:
240:  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
683:  omp_target_memcpy(d_v1, v1, sizeof(v1), 0, 0, omp_target_device, omp_initial_device);
684:  omp_target_memcpy(d_v2, v2, sizeof(v2), 0, 0, omp_target_device, omp_initial_device);
685:  omp_target_memcpy(d_v7, v7, sizeof(v7), 0, 0, omp_target_device, omp_initial_device);
690:  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
691:  omp_target_memcpy(d_v9, v9, sizeof(v9), 0, 0, omp_target_device, omp_initial_device);
692:  omp_target_memcpy(d_v10, v10, sizeof(v10), 0, 0, omp_target_device, omp_initial_device);
693:  omp_target_memcpy(d_v11, v11, sizeof(v11), 0, 0, omp_target_device, omp_initial_device);
694:  omp_target_memcpy(d_v12, v12, sizeof(v12), 0, 0, omp_target_device, omp_initial_device);

thinking
**Preparing for a clean rebuild**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..39d6e9842beddb8786ede811e556fdb1a57af567
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,149 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
+  *v70 = sqrt(v123);
 }
-  *v70 = sqrt(v123);
+
+static void allocate_device_buffers(void)
+{
+  omp_initial_device = omp_get_initial_device();
+  omp_target_device = omp_get_default_device();
+
+  d_v1 = (int *)omp_target_alloc(sizeof(v1), omp_target_device);
+  d_v2 = (int *)omp_target_alloc(sizeof(v2), omp_target_device);
+  d_v7 = (double *)omp_target_alloc(sizeof(v7), omp_target_device);
+  d_v8 = (double *)omp_target_alloc(sizeof(v8), omp_target_device);
+  d_v9 = (double *)omp_target_alloc(sizeof(v9), omp_target_device);
+  d_v10 = (double *)omp_target_alloc(sizeof(v10), omp_target_device);
+  d_v11 = (double *)omp_target_alloc(sizeof(v11), omp_target_device);
+  d_v12 = (double *)omp_target_alloc(sizeof(v12), omp_target_device);
+
+  if (!d_v1 || !d_v2 || !d_v7 || !d_v8 || !d_v9 || !d_v10 || !d_v11 || !d_v12) {
+    fprintf(stderr, "Failed to allocate device buffers\n");
+    exit(EXIT_FAILURE);
+  }
+}
+
+static void copy_csr_to_device(void)
+{
+  omp_target_memcpy(d_v1, v1, sizeof(v1), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v2, v2, sizeof(v2), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v7, v7, sizeof(v7), 0, 0, omp_target_device, omp_initial_device);
+}
+
+static void copy_vectors_to_device(void)
+{
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v9, v9, sizeof(v9), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v10, v10, sizeof(v10), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v11, v11, sizeof(v11), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v12, v12, sizeof(v12), 0, 0, omp_target_device, omp_initial_device);
+}
+
+static void free_device_buffers(void)
+{
+  if (d_v1) {
+    omp_target_free(d_v1, omp_target_device);
+    d_v1 = NULL;
+  }
+  if (d_v2) {
+    omp_target_free(d_v2, omp_target_device);
+    d_v2 = NULL;
+  }
+  if (d_v7) {
+    omp_target_free(d_v7, omp_target_device);
+    d_v7 = NULL;
+  }
+  if (d_v8) {
+    omp_target_free(d_v8, omp_target_device);
+    d_v8 = NULL;
+  }
+  if (d_v9) {
+    omp_target_free(d_v9, omp_target_device);
+    d_v9 = NULL;
+  }
+  if (d_v10) {
+    omp_target_free(d_v10, omp_target_device);
+    d_v10 = NULL;
+  }
+  if (d_v11) {
+    omp_target_free(d_v11, omp_target_device);
+    d_v11 = NULL;
+  }
+  if (d_v12) {
+    omp_target_free(d_v12, omp_target_device);
+    d_v12 = NULL;
+  }
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

exec
/bin/bash -lc 'cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && make clean' in /root/codex_baseline/serial_omp_nas_workdir succeeded in 13ms:
rm -f *.x *.w2c.ptx *.o *.w2c.cu *.w2c.c *.w2c.h *.i *.spin *.B *.s *.t *~ ../common/*.o
rm -f npbparams.h core

thinking
**Rerunning make command with timeout**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..39d6e9842beddb8786ede811e556fdb1a57af567
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,149 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
+  *v70 = sqrt(v123);
 }
-  *v70 = sqrt(v123);
+
+static void allocate_device_buffers(void)
+{
+  omp_initial_device = omp_get_initial_device();
+  omp_target_device = omp_get_default_device();
+
+  d_v1 = (int *)omp_target_alloc(sizeof(v1), omp_target_device);
+  d_v2 = (int *)omp_target_alloc(sizeof(v2), omp_target_device);
+  d_v7 = (double *)omp_target_alloc(sizeof(v7), omp_target_device);
+  d_v8 = (double *)omp_target_alloc(sizeof(v8), omp_target_device);
+  d_v9 = (double *)omp_target_alloc(sizeof(v9), omp_target_device);
+  d_v10 = (double *)omp_target_alloc(sizeof(v10), omp_target_device);
+  d_v11 = (double *)omp_target_alloc(sizeof(v11), omp_target_device);
+  d_v12 = (double *)omp_target_alloc(sizeof(v12), omp_target_device);
+
+  if (!d_v1 || !d_v2 || !d_v7 || !d_v8 || !d_v9 || !d_v10 || !d_v11 || !d_v12) {
+    fprintf(stderr, "Failed to allocate device buffers\n");
+    exit(EXIT_FAILURE);
+  }
+}
+
+static void copy_csr_to_device(void)
+{
+  omp_target_memcpy(d_v1, v1, sizeof(v1), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v2, v2, sizeof(v2), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v7, v7, sizeof(v7), 0, 0, omp_target_device, omp_initial_device);
+}
+
+static void copy_vectors_to_device(void)
+{
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v9, v9, sizeof(v9), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v10, v10, sizeof(v10), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v11, v11, sizeof(v11), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v12, v12, sizeof(v12), 0, 0, omp_target_device, omp_initial_device);
+}
+
+static void free_device_buffers(void)
+{
+  if (d_v1) {
+    omp_target_free(d_v1, omp_target_device);
+    d_v1 = NULL;
+  }
+  if (d_v2) {
+    omp_target_free(d_v2, omp_target_device);
+    d_v2 = NULL;
+  }
+  if (d_v7) {
+    omp_target_free(d_v7, omp_target_device);
+    d_v7 = NULL;
+  }
+  if (d_v8) {
+    omp_target_free(d_v8, omp_target_device);
+    d_v8 = NULL;
+  }
+  if (d_v9) {
+    omp_target_free(d_v9, omp_target_device);
+    d_v9 = NULL;
+  }
+  if (d_v10) {
+    omp_target_free(d_v10, omp_target_device);
+    d_v10 = NULL;
+  }
+  if (d_v11) {
+    omp_target_free(d_v11, omp_target_device);
+    d_v11 = NULL;
+  }
+  if (d_v12) {
+    omp_target_free(d_v12, omp_target_device);
+    d_v12 = NULL;
+  }
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

exec
/bin/bash -lc 'cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && timeout 300 env OMP_TARGET_OFFLOAD=MANDATORY make CC=nvc++ CLASS=S run > gpu_output.txt 2>&1' in /root/codex_baseline/serial_omp_nas_workdir succeeded in 3.94s:


thinking
**Checking GPU output for success markers**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..39d6e9842beddb8786ede811e556fdb1a57af567
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,149 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
+  *v70 = sqrt(v123);
 }
-  *v70 = sqrt(v123);
+
+static void allocate_device_buffers(void)
+{
+  omp_initial_device = omp_get_initial_device();
+  omp_target_device = omp_get_default_device();
+
+  d_v1 = (int *)omp_target_alloc(sizeof(v1), omp_target_device);
+  d_v2 = (int *)omp_target_alloc(sizeof(v2), omp_target_device);
+  d_v7 = (double *)omp_target_alloc(sizeof(v7), omp_target_device);
+  d_v8 = (double *)omp_target_alloc(sizeof(v8), omp_target_device);
+  d_v9 = (double *)omp_target_alloc(sizeof(v9), omp_target_device);
+  d_v10 = (double *)omp_target_alloc(sizeof(v10), omp_target_device);
+  d_v11 = (double *)omp_target_alloc(sizeof(v11), omp_target_device);
+  d_v12 = (double *)omp_target_alloc(sizeof(v12), omp_target_device);
+
+  if (!d_v1 || !d_v2 || !d_v7 || !d_v8 || !d_v9 || !d_v10 || !d_v11 || !d_v12) {
+    fprintf(stderr, "Failed to allocate device buffers\n");
+    exit(EXIT_FAILURE);
+  }
+}
+
+static void copy_csr_to_device(void)
+{
+  omp_target_memcpy(d_v1, v1, sizeof(v1), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v2, v2, sizeof(v2), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v7, v7, sizeof(v7), 0, 0, omp_target_device, omp_initial_device);
+}
+
+static void copy_vectors_to_device(void)
+{
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v9, v9, sizeof(v9), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v10, v10, sizeof(v10), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v11, v11, sizeof(v11), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v12, v12, sizeof(v12), 0, 0, omp_target_device, omp_initial_device);
+}
+
+static void free_device_buffers(void)
+{
+  if (d_v1) {
+    omp_target_free(d_v1, omp_target_device);
+    d_v1 = NULL;
+  }
+  if (d_v2) {
+    omp_target_free(d_v2, omp_target_device);
+    d_v2 = NULL;
+  }
+  if (d_v7) {
+    omp_target_free(d_v7, omp_target_device);
+    d_v7 = NULL;
+  }
+  if (d_v8) {
+    omp_target_free(d_v8, omp_target_device);
+    d_v8 = NULL;
+  }
+  if (d_v9) {
+    omp_target_free(d_v9, omp_target_device);
+    d_v9 = NULL;
+  }
+  if (d_v10) {
+    omp_target_free(d_v10, omp_target_device);
+    d_v10 = NULL;
+  }
+  if (d_v11) {
+    omp_target_free(d_v11, omp_target_device);
+    d_v11 = NULL;
+  }
+  if (d_v12) {
+    omp_target_free(d_v12, omp_target_device);
+    d_v12 = NULL;
+  }
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

exec
/bin/bash -lc 'cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && grep -E "Verification|SUCCESSFUL|FAILED" gpu_output.txt' in /root/codex_baseline/serial_omp_nas_workdir succeeded in 17ms:
 VERIFICATION SUCCESSFUL
 Verification    =               SUCCESSFUL

thinking
**Comparing output files**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..39d6e9842beddb8786ede811e556fdb1a57af567
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,149 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
+  *v70 = sqrt(v123);
 }
-  *v70 = sqrt(v123);
+
+static void allocate_device_buffers(void)
+{
+  omp_initial_device = omp_get_initial_device();
+  omp_target_device = omp_get_default_device();
+
+  d_v1 = (int *)omp_target_alloc(sizeof(v1), omp_target_device);
+  d_v2 = (int *)omp_target_alloc(sizeof(v2), omp_target_device);
+  d_v7 = (double *)omp_target_alloc(sizeof(v7), omp_target_device);
+  d_v8 = (double *)omp_target_alloc(sizeof(v8), omp_target_device);
+  d_v9 = (double *)omp_target_alloc(sizeof(v9), omp_target_device);
+  d_v10 = (double *)omp_target_alloc(sizeof(v10), omp_target_device);
+  d_v11 = (double *)omp_target_alloc(sizeof(v11), omp_target_device);
+  d_v12 = (double *)omp_target_alloc(sizeof(v12), omp_target_device);
+
+  if (!d_v1 || !d_v2 || !d_v7 || !d_v8 || !d_v9 || !d_v10 || !d_v11 || !d_v12) {
+    fprintf(stderr, "Failed to allocate device buffers\n");
+    exit(EXIT_FAILURE);
+  }
+}
+
+static void copy_csr_to_device(void)
+{
+  omp_target_memcpy(d_v1, v1, sizeof(v1), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v2, v2, sizeof(v2), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v7, v7, sizeof(v7), 0, 0, omp_target_device, omp_initial_device);
+}
+
+static void copy_vectors_to_device(void)
+{
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v9, v9, sizeof(v9), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v10, v10, sizeof(v10), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v11, v11, sizeof(v11), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v12, v12, sizeof(v12), 0, 0, omp_target_device, omp_initial_device);
+}
+
+static void free_device_buffers(void)
+{
+  if (d_v1) {
+    omp_target_free(d_v1, omp_target_device);
+    d_v1 = NULL;
+  }
+  if (d_v2) {
+    omp_target_free(d_v2, omp_target_device);
+    d_v2 = NULL;
+  }
+  if (d_v7) {
+    omp_target_free(d_v7, omp_target_device);
+    d_v7 = NULL;
+  }
+  if (d_v8) {
+    omp_target_free(d_v8, omp_target_device);
+    d_v8 = NULL;
+  }
+  if (d_v9) {
+    omp_target_free(d_v9, omp_target_device);
+    d_v9 = NULL;
+  }
+  if (d_v10) {
+    omp_target_free(d_v10, omp_target_device);
+    d_v10 = NULL;
+  }
+  if (d_v11) {
+    omp_target_free(d_v11, omp_target_device);
+    d_v11 = NULL;
+  }
+  if (d_v12) {
+    omp_target_free(d_v12, omp_target_device);
+    d_v12 = NULL;
+  }
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

exec
/bin/bash -lc 'cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && diff baseline_output.txt gpu_output.txt' in /root/codex_baseline/serial_omp_nas_workdir exited 1 in 16ms:
5c5
< "cg.c", line 116: warning: conversion from a string literal to "char *" is deprecated [deprecated_string_conv]
---
> "cg.c", line 132: warning: conversion from a string literal to "char *" is deprecated [deprecated_string_conv]
11c11
< "cg.c", line 117: warning: conversion from a string literal to "char *" is deprecated [deprecated_string_conv]
---
> "cg.c", line 133: warning: conversion from a string literal to "char *" is deprecated [deprecated_string_conv]
15c15
< "cg.c", line 118: warning: conversion from a string literal to "char *" is deprecated [deprecated_string_conv]
---
> "cg.c", line 134: warning: conversion from a string literal to "char *" is deprecated [deprecated_string_conv]
19c19
< "cg.c", line 182: warning: variable "v92" was set but never used [set_but_not_used]
---
> "cg.c", line 201: warning: variable "v92" was set but never used [set_but_not_used]
23c23
< "cg.c", line 284: warning: conversion from a string literal to "char *" is deprecated [deprecated_string_conv]
---
> "cg.c", line 312: warning: conversion from a string literal to "char *" is deprecated [deprecated_string_conv]

thinking
**Reviewing diff output warnings**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..39d6e9842beddb8786ede811e556fdb1a57af567
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,149 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
+  *v70 = sqrt(v123);
 }
-  *v70 = sqrt(v123);
+
+static void allocate_device_buffers(void)
+{
+  omp_initial_device = omp_get_initial_device();
+  omp_target_device = omp_get_default_device();
+
+  d_v1 = (int *)omp_target_alloc(sizeof(v1), omp_target_device);
+  d_v2 = (int *)omp_target_alloc(sizeof(v2), omp_target_device);
+  d_v7 = (double *)omp_target_alloc(sizeof(v7), omp_target_device);
+  d_v8 = (double *)omp_target_alloc(sizeof(v8), omp_target_device);
+  d_v9 = (double *)omp_target_alloc(sizeof(v9), omp_target_device);
+  d_v10 = (double *)omp_target_alloc(sizeof(v10), omp_target_device);
+  d_v11 = (double *)omp_target_alloc(sizeof(v11), omp_target_device);
+  d_v12 = (double *)omp_target_alloc(sizeof(v12), omp_target_device);
+
+  if (!d_v1 || !d_v2 || !d_v7 || !d_v8 || !d_v9 || !d_v10 || !d_v11 || !d_v12) {
+    fprintf(stderr, "Failed to allocate device buffers\n");
+    exit(EXIT_FAILURE);
+  }
+}
+
+static void copy_csr_to_device(void)
+{
+  omp_target_memcpy(d_v1, v1, sizeof(v1), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v2, v2, sizeof(v2), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v7, v7, sizeof(v7), 0, 0, omp_target_device, omp_initial_device);
+}
+
+static void copy_vectors_to_device(void)
+{
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v9, v9, sizeof(v9), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v10, v10, sizeof(v10), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v11, v11, sizeof(v11), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v12, v12, sizeof(v12), 0, 0, omp_target_device, omp_initial_device);
+}
+
+static void free_device_buffers(void)
+{
+  if (d_v1) {
+    omp_target_free(d_v1, omp_target_device);
+    d_v1 = NULL;
+  }
+  if (d_v2) {
+    omp_target_free(d_v2, omp_target_device);
+    d_v2 = NULL;
+  }
+  if (d_v7) {
+    omp_target_free(d_v7, omp_target_device);
+    d_v7 = NULL;
+  }
+  if (d_v8) {
+    omp_target_free(d_v8, omp_target_device);
+    d_v8 = NULL;
+  }
+  if (d_v9) {
+    omp_target_free(d_v9, omp_target_device);
+    d_v9 = NULL;
+  }
+  if (d_v10) {
+    omp_target_free(d_v10, omp_target_device);
+    d_v10 = NULL;
+  }
+  if (d_v11) {
+    omp_target_free(d_v11, omp_target_device);
+    d_v11 = NULL;
+  }
+  if (d_v12) {
+    omp_target_free(d_v12, omp_target_device);
+    d_v12 = NULL;
+  }
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

Plan update
CLASS S now rebuilds and runs with the Strategy C offload; results (gpu_output.txt) were generated and diffed against the baseline.
  ✓ Document data management plan based on the CG timed region and Strategy C requirements
  ✓ Implement Strategy C offload in cg.c (device allocations, target loops, dot-product kernels, vector updates, include omp.h)
  ✓ Rebuild CLASS S with OMP_TARGET_OFFLOAD=MANDATORY and compare output with baseline

thinking
**Preparing comprehensive final summary**

I’m gathering all key points for the final response, including code changes, helper functions, data plan file creation, device management improvements, and test results. I’ll highlight differences seen in output files—only warnings and timing shifts caused by GPU offload—and mention usage of `target teams loop` and `omp_target_memcpy`. Also, I plan to reference file paths with line numbers for clarity, especially for `data_plan.md`, so I’m fetching line numbers to accurately cite relevant modifications.
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..39d6e9842beddb8786ede811e556fdb1a57af567
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,149 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
+  *v70 = sqrt(v123);
 }
-  *v70 = sqrt(v123);
+
+static void allocate_device_buffers(void)
+{
+  omp_initial_device = omp_get_initial_device();
+  omp_target_device = omp_get_default_device();
+
+  d_v1 = (int *)omp_target_alloc(sizeof(v1), omp_target_device);
+  d_v2 = (int *)omp_target_alloc(sizeof(v2), omp_target_device);
+  d_v7 = (double *)omp_target_alloc(sizeof(v7), omp_target_device);
+  d_v8 = (double *)omp_target_alloc(sizeof(v8), omp_target_device);
+  d_v9 = (double *)omp_target_alloc(sizeof(v9), omp_target_device);
+  d_v10 = (double *)omp_target_alloc(sizeof(v10), omp_target_device);
+  d_v11 = (double *)omp_target_alloc(sizeof(v11), omp_target_device);
+  d_v12 = (double *)omp_target_alloc(sizeof(v12), omp_target_device);
+
+  if (!d_v1 || !d_v2 || !d_v7 || !d_v8 || !d_v9 || !d_v10 || !d_v11 || !d_v12) {
+    fprintf(stderr, "Failed to allocate device buffers\n");
+    exit(EXIT_FAILURE);
+  }
+}
+
+static void copy_csr_to_device(void)
+{
+  omp_target_memcpy(d_v1, v1, sizeof(v1), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v2, v2, sizeof(v2), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v7, v7, sizeof(v7), 0, 0, omp_target_device, omp_initial_device);
+}
+
+static void copy_vectors_to_device(void)
+{
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v9, v9, sizeof(v9), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v10, v10, sizeof(v10), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v11, v11, sizeof(v11), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v12, v12, sizeof(v12), 0, 0, omp_target_device, omp_initial_device);
+}
+
+static void free_device_buffers(void)
+{
+  if (d_v1) {
+    omp_target_free(d_v1, omp_target_device);
+    d_v1 = NULL;
+  }
+  if (d_v2) {
+    omp_target_free(d_v2, omp_target_device);
+    d_v2 = NULL;
+  }
+  if (d_v7) {
+    omp_target_free(d_v7, omp_target_device);
+    d_v7 = NULL;
+  }
+  if (d_v8) {
+    omp_target_free(d_v8, omp_target_device);
+    d_v8 = NULL;
+  }
+  if (d_v9) {
+    omp_target_free(d_v9, omp_target_device);
+    d_v9 = NULL;
+  }
+  if (d_v10) {
+    omp_target_free(d_v10, omp_target_device);
+    d_v10 = NULL;
+  }
+  if (d_v11) {
+    omp_target_free(d_v11, omp_target_device);
+    d_v11 = NULL;
+  }
+  if (d_v12) {
+    omp_target_free(d_v12, omp_target_device);
+    d_v12 = NULL;
+  }
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

exec
/bin/bash -lc "cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && nl -ba data_plan.md | sed -n '1,200p'" in /root/codex_baseline/serial_omp_nas_workdir succeeded in 27ms:
     1	# Data Management Plan
     2	
     3	## Arrays Inventory
     4	List ALL arrays used in timed region:
     5	
     6	| Array Name | Size | Type | Init | Access |
     7	|------------|------|------|------|--------|
     8	| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
     9	| `v2` | `NA+1` | index | host (set by `f2`) | R |
    10	| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
    11	| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
    12	| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
    13	| `v10` | `NA+2` | working (p vector) | host | R/W |
    14	| `v11` | `NA+2` | working (Ap vector) | host | R/W |
    15	| `v12` | `NA+2` | working (z vector) | host | R/W |
    16	
    17	**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
    18	
    19	## Functions in Timed Region
    20	| Function | Arrays Accessed | Frequency | Must Run On |

thinking
**Preparing file references and line numbers**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..39d6e9842beddb8786ede811e556fdb1a57af567
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,149 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
+  *v70 = sqrt(v123);
 }
-  *v70 = sqrt(v123);
+
+static void allocate_device_buffers(void)
+{
+  omp_initial_device = omp_get_initial_device();
+  omp_target_device = omp_get_default_device();
+
+  d_v1 = (int *)omp_target_alloc(sizeof(v1), omp_target_device);
+  d_v2 = (int *)omp_target_alloc(sizeof(v2), omp_target_device);
+  d_v7 = (double *)omp_target_alloc(sizeof(v7), omp_target_device);
+  d_v8 = (double *)omp_target_alloc(sizeof(v8), omp_target_device);
+  d_v9 = (double *)omp_target_alloc(sizeof(v9), omp_target_device);
+  d_v10 = (double *)omp_target_alloc(sizeof(v10), omp_target_device);
+  d_v11 = (double *)omp_target_alloc(sizeof(v11), omp_target_device);
+  d_v12 = (double *)omp_target_alloc(sizeof(v12), omp_target_device);
+
+  if (!d_v1 || !d_v2 || !d_v7 || !d_v8 || !d_v9 || !d_v10 || !d_v11 || !d_v12) {
+    fprintf(stderr, "Failed to allocate device buffers\n");
+    exit(EXIT_FAILURE);
+  }
+}
+
+static void copy_csr_to_device(void)
+{
+  omp_target_memcpy(d_v1, v1, sizeof(v1), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v2, v2, sizeof(v2), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v7, v7, sizeof(v7), 0, 0, omp_target_device, omp_initial_device);
+}
+
+static void copy_vectors_to_device(void)
+{
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v9, v9, sizeof(v9), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v10, v10, sizeof(v10), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v11, v11, sizeof(v11), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v12, v12, sizeof(v12), 0, 0, omp_target_device, omp_initial_device);
+}
+
+static void free_device_buffers(void)
+{
+  if (d_v1) {
+    omp_target_free(d_v1, omp_target_device);
+    d_v1 = NULL;
+  }
+  if (d_v2) {
+    omp_target_free(d_v2, omp_target_device);
+    d_v2 = NULL;
+  }
+  if (d_v7) {
+    omp_target_free(d_v7, omp_target_device);
+    d_v7 = NULL;
+  }
+  if (d_v8) {
+    omp_target_free(d_v8, omp_target_device);
+    d_v8 = NULL;
+  }
+  if (d_v9) {
+    omp_target_free(d_v9, omp_target_device);
+    d_v9 = NULL;
+  }
+  if (d_v10) {
+    omp_target_free(d_v10, omp_target_device);
+    d_v10 = NULL;
+  }
+  if (d_v11) {
+    omp_target_free(d_v11, omp_target_device);
+    d_v11 = NULL;
+  }
+  if (d_v12) {
+    omp_target_free(d_v12, omp_target_device);
+    d_v12 = NULL;
+  }
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

exec
/bin/bash -lc "cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && nl -ba cg.c | sed -n '1,200p'" in /root/codex_baseline/serial_omp_nas_workdir succeeded in 28ms:
     1	#ifdef __PGIC__
     2	#undef __GNUC__
     3	#else
     4	#define num_gangs(a)
     5	#define num_workers(a)
     6	#define vector_length(a)
     7	#define gang
     8	#define worker
     9	#define vector
    10	#endif
    11	
    12	#include <stdio.h>
    13	#include <stdlib.h>
    14	#include <math.h>
    15	#include <omp.h>
    16	
    17	#include "globals.h"
    18	#include "randdp.h"
    19	#include "timers.h"
    20	#include "print_results.h"

thinking
**Preparing line number references**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..39d6e9842beddb8786ede811e556fdb1a57af567
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,149 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
+  *v70 = sqrt(v123);
 }
-  *v70 = sqrt(v123);
+
+static void allocate_device_buffers(void)
+{
+  omp_initial_device = omp_get_initial_device();
+  omp_target_device = omp_get_default_device();
+
+  d_v1 = (int *)omp_target_alloc(sizeof(v1), omp_target_device);
+  d_v2 = (int *)omp_target_alloc(sizeof(v2), omp_target_device);
+  d_v7 = (double *)omp_target_alloc(sizeof(v7), omp_target_device);
+  d_v8 = (double *)omp_target_alloc(sizeof(v8), omp_target_device);
+  d_v9 = (double *)omp_target_alloc(sizeof(v9), omp_target_device);
+  d_v10 = (double *)omp_target_alloc(sizeof(v10), omp_target_device);
+  d_v11 = (double *)omp_target_alloc(sizeof(v11), omp_target_device);
+  d_v12 = (double *)omp_target_alloc(sizeof(v12), omp_target_device);
+
+  if (!d_v1 || !d_v2 || !d_v7 || !d_v8 || !d_v9 || !d_v10 || !d_v11 || !d_v12) {
+    fprintf(stderr, "Failed to allocate device buffers\n");
+    exit(EXIT_FAILURE);
+  }
+}
+
+static void copy_csr_to_device(void)
+{
+  omp_target_memcpy(d_v1, v1, sizeof(v1), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v2, v2, sizeof(v2), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v7, v7, sizeof(v7), 0, 0, omp_target_device, omp_initial_device);
+}
+
+static void copy_vectors_to_device(void)
+{
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v9, v9, sizeof(v9), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v10, v10, sizeof(v10), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v11, v11, sizeof(v11), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v12, v12, sizeof(v12), 0, 0, omp_target_device, omp_initial_device);
+}
+
+static void free_device_buffers(void)
+{
+  if (d_v1) {
+    omp_target_free(d_v1, omp_target_device);
+    d_v1 = NULL;
+  }
+  if (d_v2) {
+    omp_target_free(d_v2, omp_target_device);
+    d_v2 = NULL;
+  }
+  if (d_v7) {
+    omp_target_free(d_v7, omp_target_device);
+    d_v7 = NULL;
+  }
+  if (d_v8) {
+    omp_target_free(d_v8, omp_target_device);
+    d_v8 = NULL;
+  }
+  if (d_v9) {
+    omp_target_free(d_v9, omp_target_device);
+    d_v9 = NULL;
+  }
+  if (d_v10) {
+    omp_target_free(d_v10, omp_target_device);
+    d_v10 = NULL;
+  }
+  if (d_v11) {
+    omp_target_free(d_v11, omp_target_device);
+    d_v11 = NULL;
+  }
+  if (d_v12) {
+    omp_target_free(d_v12, omp_target_device);
+    d_v12 = NULL;
+  }
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

exec
/bin/bash -lc "cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && nl -ba cg.c | sed -n '520,780p'" in /root/codex_baseline/serial_omp_nas_workdir succeeded in 13ms:
   520	                  int v50,
   521	                  double v51[],
   522	                  int v52[],
   523	                  int v53[],
   524	                  int v54,
   525	                  int v55,
   526	                  int v56,
   527	                  int v57,
   528	                  int v58[],
   529	                  int v59[][NONZER+1],
   530	                  double v60[][NONZER+1],
   531	                  int v61[])
   532	{
   533	  int v111, v112, v113, v114;
   534	  int v115[NONZER+1];
   535	  double v116[NONZER+1];
   536	
   537	  v114 = 1;
   538	  do {
   539	    v114 = 2 * v114;

thinking
**Identifying key code sections for summary**
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..39d6e9842beddb8786ede811e556fdb1a57af567
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,149 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
+  *v70 = sqrt(v123);
 }
-  *v70 = sqrt(v123);
+
+static void allocate_device_buffers(void)
+{
+  omp_initial_device = omp_get_initial_device();
+  omp_target_device = omp_get_default_device();
+
+  d_v1 = (int *)omp_target_alloc(sizeof(v1), omp_target_device);
+  d_v2 = (int *)omp_target_alloc(sizeof(v2), omp_target_device);
+  d_v7 = (double *)omp_target_alloc(sizeof(v7), omp_target_device);
+  d_v8 = (double *)omp_target_alloc(sizeof(v8), omp_target_device);
+  d_v9 = (double *)omp_target_alloc(sizeof(v9), omp_target_device);
+  d_v10 = (double *)omp_target_alloc(sizeof(v10), omp_target_device);
+  d_v11 = (double *)omp_target_alloc(sizeof(v11), omp_target_device);
+  d_v12 = (double *)omp_target_alloc(sizeof(v12), omp_target_device);
+
+  if (!d_v1 || !d_v2 || !d_v7 || !d_v8 || !d_v9 || !d_v10 || !d_v11 || !d_v12) {
+    fprintf(stderr, "Failed to allocate device buffers\n");
+    exit(EXIT_FAILURE);
+  }
+}
+
+static void copy_csr_to_device(void)
+{
+  omp_target_memcpy(d_v1, v1, sizeof(v1), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v2, v2, sizeof(v2), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v7, v7, sizeof(v7), 0, 0, omp_target_device, omp_initial_device);
+}
+
+static void copy_vectors_to_device(void)
+{
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v9, v9, sizeof(v9), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v10, v10, sizeof(v10), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v11, v11, sizeof(v11), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v12, v12, sizeof(v12), 0, 0, omp_target_device, omp_initial_device);
+}
+
+static void free_device_buffers(void)
+{
+  if (d_v1) {
+    omp_target_free(d_v1, omp_target_device);
+    d_v1 = NULL;
+  }
+  if (d_v2) {
+    omp_target_free(d_v2, omp_target_device);
+    d_v2 = NULL;
+  }
+  if (d_v7) {
+    omp_target_free(d_v7, omp_target_device);
+    d_v7 = NULL;
+  }
+  if (d_v8) {
+    omp_target_free(d_v8, omp_target_device);
+    d_v8 = NULL;
+  }
+  if (d_v9) {
+    omp_target_free(d_v9, omp_target_device);
+    d_v9 = NULL;
+  }
+  if (d_v10) {
+    omp_target_free(d_v10, omp_target_device);
+    d_v10 = NULL;
+  }
+  if (d_v11) {
+    omp_target_free(d_v11, omp_target_device);
+    d_v11 = NULL;
+  }
+  if (d_v12) {
+    omp_target_free(d_v12, omp_target_device);
+    d_v12 = NULL;
+  }
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

exec
/bin/bash -lc "cd /root/codex_baseline/serial_omp_nas_workdir/data/src/cg-omp && nl -ba cg.c | sed -n '200,320p'" in /root/codex_baseline/serial_omp_nas_workdir succeeded in 8ms:
   200	{
   201	  int v92 = NA+1;
   202	  for (v73 = 0; v73 < NA+1; v73++) {
   203	    v8[v73] = 1.0;
   204	  }
   205	
   206	  v77 = v18 - v17 + 1;
   207	  for (v74 = 0; v74 < v77; v74++) {
   208	    v11[v74] = 0.0;
   209	    v9[v74] = 0.0;
   210	    v12[v74] = 0.0;
   211	    v10[v74] = 0.0;
   212	  }
   213	
   214	  copy_vectors_to_device();
   215	
   216	  v78 = 0.0;
   217	
   218	  for (v76 = 1; v76 <= 1; v76++) {
   219	    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);

Reconnecting... 1/5

thinking
**Summarizing final reporting and test details**

I'll outline the plan for the final message: summarizing the code changes with detailed file references, describing the specific tests run including commands, verifying success via grep on the GPU output, and noting that diffs versus baseline show just warnings and performance timing differences. I'll also prepare next steps suggesting running further class tests with profiling to check GPU performance. This will follow the user’s preferred bullet-point format with a concise lead statement and organized sections.
codex
- Documented the Strategy C plan (arrays, per-iteration function, transfer budget, and checks) ahead of implementation so the CUDA-style workflow is explicit before touching the code (`data_plan.md:3`, `data_plan.md:26`).
- Added `<omp.h>`, persistent device pointers, helper prototypes, and a device-managed `f1` that runs every loop through `#pragma omp target teams loop` to keep CSR/vectors on the GPU; `omp_target_alloc`/`omp_target_memcpy`/`omp_target_free` helpers now own the lifecycle of the working arrays (`cg.c:15`, `cg.c:26`, `cg.c:102`, `cg.c:559`, `cg.c:661`).
- Warmup and benchmark phases now call `f1` with device pointers, compute dot-products as device reductions, and scale `v8` on the GPU so only scalars touch the host; this keeps all vector math resident on the accelerator without extra transfers (`cg.c:197`, `cg.c:218`, `cg.c:250`).

**Testing**
- `make clean`
- `timeout 300 env OMP_TARGET_OFFLOAD=MANDATORY make CC=nvc++ CLASS=S run > gpu_output.txt 2>&1`
- `grep -E "Verification|SUCCESSFUL|FAILED" gpu_output.txt` → `VERIFICATION SUCCESSFUL`
- `diff baseline_output.txt gpu_output.txt` → only warning line-number shifts plus longer init/benchmark time and Mop/s changes, no incorrect results

**Next Steps**
1. Run the heavier Class B/C builds/runs (with the same `OMP_TARGET_OFFLOAD=MANDATORY` guard) and capture an `nsys` profile to understand GPU kernel performance now that the data lives on-device.
file update:
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/cg.c b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
index d2355ff5b86ec2170829afa7ff7b3ec34b06daaa..39d6e9842beddb8786ede811e556fdb1a57af567
--- a/serial_omp_nas_workdir/data/src/cg-omp/cg.c
+++ b/serial_omp_nas_workdir/data/src/cg-omp/cg.c
@@ -12,6 +12,7 @@
 #include <stdio.h>
 #include <stdlib.h>
 #include <math.h>
+#include <omp.h>
 
 #include "globals.h"
 #include "randdp.h"
@@ -36,6 +37,17 @@
 static double v11[NA+2];
 static double v12[NA+2];
 
+static int *d_v1 = NULL;
+static int *d_v2 = NULL;
+static double *d_v7 = NULL;
+static double *d_v8 = NULL;
+static double *d_v9 = NULL;
+static double *d_v10 = NULL;
+static double *d_v11 = NULL;
+static double *d_v12 = NULL;
+static int omp_target_device = -1;
+static int omp_initial_device = -1;
+
 static int v13;
 static int v14;
 static int v15;
@@ -87,6 +99,10 @@
                       double v68[],
                       double v69[],
                       double *v70);
+static void allocate_device_buffers(void);
+static void copy_csr_to_device(void);
+static void copy_vectors_to_device(void);
+static void free_device_buffers(void);
 static int v71 = 0;
 static int v72 = 0;
 
@@ -178,6 +194,9 @@
     }
   }
 
+  allocate_device_buffers();
+  copy_csr_to_device();
+
 {
   int v92 = NA+1;
   for (v73 = 0; v73 < NA+1; v73++) {
@@ -192,21 +211,24 @@
     v10[v74] = 0.0;
   }
 
+  copy_vectors_to_device();
+
   v78 = 0.0;
 
   for (v76 = 1; v76 <= 1; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
-    v80 = 0.0;
-    v81 = 0.0;
+    double warm_norm = 0.0;
+    #pragma omp target teams loop reduction(+:warm_norm) is_device_ptr(d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v81 = v81 + v9[v74] * v9[v74];
+      double tmp = d_v9[v74];
+      warm_norm += tmp * tmp;
     }
 
-    v81 = 1.0 / sqrt(v81);
-
-    for (v74 = 0; v74 < v77; v74++) {     
-      v8[v74] = v81 * v9[v74];
+    double warm_inv = 1.0 / sqrt(warm_norm);
+    #pragma omp target teams loop firstprivate(warm_inv) is_device_ptr(d_v8, d_v9)
+    for (v74 = 0; v74 < v77; v74++) {
+      d_v8[v74] = warm_inv * d_v9[v74];
     }
   }
 
@@ -215,6 +237,8 @@
     v8[v73] = 1.0;
   }
 
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
+
   v78 = 0.0;
 
   timer_stop(T_init);
@@ -223,14 +247,17 @@
 
   timer_start(T_bench);
 
+  v77 = v18 - v17 + 1;
   for (v76 = 1; v76 <= NITER; v76++) {
-    f1(v1, v2, v8, v9, v7, v10, v11, v12, &v79);
+    f1(d_v1, d_v2, d_v8, d_v9, d_v7, d_v10, d_v11, d_v12, &v79);
 
     v80 = 0.0;
     v81 = 0.0;
+    #pragma omp target teams loop reduction(+:v80,v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v80 = v80 + v8[v74]*v9[v74];
-      v81 = v81 + v9[v74]*v9[v74];
+      double tmp = d_v9[v74];
+      v80 += d_v8[v74] * tmp;
+      v81 += tmp * tmp;
     }
 
     v81 = 1.0 / sqrt(v81);
@@ -240,8 +267,9 @@
       printf("\n   iteration           ||r||                 zeta\n");
     printf("    %5d       %20.14E%20.13f\n", v76, v79, v78);
 
+    #pragma omp target teams loop firstprivate(v81) is_device_ptr(d_v8, d_v9)
     for (v74 = 0; v74 < v77; v74++) {
-      v8[v74] = v81 * v9[v74];
+      d_v8[v74] = v81 * d_v9[v74];
     }
   }
 
@@ -305,6 +333,7 @@
     }
   }
   printf("conj calls=%d, loop iter = %d. \n", v71, v72);
+  free_device_buffers();
   return 0;
 }
 
@@ -537,15 +566,16 @@
                       double v69[],
                       double *v70)
 {
-  int v74, v75,v117,v118,v119;
+  int v74, v75, v117, v118, v119;
   int v77;
   int v120, v121 = 25;
   double v122, v123, v124, v125, v126, v127;
-  double v128[NA+2];
-  v71 ++;
+
+  v71++;
   v124 = 0.0;
-  unsigned int v129 = 0;
-{
+
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop is_device_ptr(v65, v68, v64, v67, v69)
   for (v74 = 0; v74 < v13; v74++) {
     v68[v74] = 0.0;
     v65[v74] = 0.0;
@@ -553,76 +583,149 @@
     v67[v74] = v69[v74];
   }
 
-  for (v74 = 0; v74 < v18 - v17 + 1; v74++) {
-    v124 = v124 + v69[v74]*v69[v74];
+  #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v124 += v69[v74] * v69[v74];
   }
-  
+
   for (v120 = 1; v120 <= v121; v120++) {
-    v72 ++;
+    v72++;
     v77 = v16 - v15 + 1;
 
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v117 = v63[v74];
-		  v118 = v63[v74+1];
-		  v123 = 0.0;
-		  for (v75 = v117; v75 < v118; v75++) {
-			v119 = v62[v75];
-		    v123 = v123 + v66[v75]*v67[v119];
-		  }
-		  v68[v74] = v123;
-		}
+    #pragma omp target teams loop is_device_ptr(v63, v62, v66, v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v117 = v63[v74];
+      v118 = v63[v74+1];
+      v123 = 0.0;
+      for (v75 = v117; v75 < v118; v75++) {
+        v119 = v62[v75];
+        v123 = v123 + v66[v75] * v67[v119];
+      }
+      v68[v74] = v123;
     }
+
     v122 = 0.0;
-	v77 = v18 - v17 + 1;
-	{
-		for (v74 = 0; v74 < v77; v74++) {
-		  v122 = v122 + v67[v74]*v68[v74];
-		}
+    v77 = v18 - v17 + 1;
+    #pragma omp target teams loop reduction(+:v122) is_device_ptr(v67, v68)
+    for (v74 = 0; v74 < v77; v74++) {
+      v122 += v67[v74] * v68[v74];
     }
 
     v126 = v124 / v122;
-
     v125 = v124;
+    v124 = 0.0;
 
-    v124 = 0.0;
+    #pragma omp target teams loop firstprivate(v126) is_device_ptr(v65, v69, v68, v67)
     for (v74 = 0; v74 < v77; v74++) {
-      v65[v74] = v65[v74] + v126*v67[v74];
-      v69[v74] = v69[v74] - v126*v68[v74];
+      v65[v74] = v65[v74] + v126 * v67[v74];
+      v69[v74] = v69[v74] - v126 * v68[v74];
     }
-              
-	{
-		for (v74 = 0; v74 < v77; v74++) 
-		{
-		  v124 = v124 + v69[v74]*v69[v74];
-		}
+
+    #pragma omp target teams loop reduction(+:v124) is_device_ptr(v69)
+    for (v74 = 0; v74 < v77; v74++) {
+      v124 += v69[v74] * v69[v74];
     }
 
     v127 = v124 / v125;
 
+    #pragma omp target teams loop firstprivate(v127) is_device_ptr(v67, v69)
     for (v74 = 0; v74 < v77; v74++) {
-      v67[v74] = v69[v74] + v127*v67[v74];
-    } 
+      v67[v74] = v69[v74] + v127 * v67[v74];
+    }
   }
 
   v77 = v16 - v15 + 1;
+  #pragma omp target teams loop is_device_ptr(v63, v62, v66, v65, v69)
   for (v74 = 0; v74 < v77; v74++) {
-    v117=v63[v74];
-    v118=v63[v74+1];
+    v117 = v63[v74];
+    v118 = v63[v74+1];
     v122 = 0.0;
     for (v75 = v117; v75 < v118; v75++) {
-        v119=v62[v75];
-        v122 = v122 + v66[v75]*v65[v119];
+      v119 = v62[v75];
+      v122 += v66[v75] * v65[v119];
     }
     v69[v74] = v122;
   }
-   
+
   v123 = 0.0;
-  for (v74 = 0; v74 < v18-v17+1; v74++) {
-    v122   = v64[v74] - v69[v74];
-    v123 = v123 + v122*v122;
+  v77 = v18 - v17 + 1;
+  #pragma omp target teams loop reduction(+:v123) is_device_ptr(v64, v69)
+  for (v74 = 0; v74 < v77; v74++) {
+    v122 = v64[v74] - v69[v74];
+    v123 += v122 * v122;
   }
 
+  *v70 = sqrt(v123);
 }
-  *v70 = sqrt(v123);
+
+static void allocate_device_buffers(void)
+{
+  omp_initial_device = omp_get_initial_device();
+  omp_target_device = omp_get_default_device();
+
+  d_v1 = (int *)omp_target_alloc(sizeof(v1), omp_target_device);
+  d_v2 = (int *)omp_target_alloc(sizeof(v2), omp_target_device);
+  d_v7 = (double *)omp_target_alloc(sizeof(v7), omp_target_device);
+  d_v8 = (double *)omp_target_alloc(sizeof(v8), omp_target_device);
+  d_v9 = (double *)omp_target_alloc(sizeof(v9), omp_target_device);
+  d_v10 = (double *)omp_target_alloc(sizeof(v10), omp_target_device);
+  d_v11 = (double *)omp_target_alloc(sizeof(v11), omp_target_device);
+  d_v12 = (double *)omp_target_alloc(sizeof(v12), omp_target_device);
+
+  if (!d_v1 || !d_v2 || !d_v7 || !d_v8 || !d_v9 || !d_v10 || !d_v11 || !d_v12) {
+    fprintf(stderr, "Failed to allocate device buffers\n");
+    exit(EXIT_FAILURE);
+  }
+}
+
+static void copy_csr_to_device(void)
+{
+  omp_target_memcpy(d_v1, v1, sizeof(v1), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v2, v2, sizeof(v2), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v7, v7, sizeof(v7), 0, 0, omp_target_device, omp_initial_device);
+}
+
+static void copy_vectors_to_device(void)
+{
+  omp_target_memcpy(d_v8, v8, sizeof(v8), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v9, v9, sizeof(v9), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v10, v10, sizeof(v10), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v11, v11, sizeof(v11), 0, 0, omp_target_device, omp_initial_device);
+  omp_target_memcpy(d_v12, v12, sizeof(v12), 0, 0, omp_target_device, omp_initial_device);
+}
+
+static void free_device_buffers(void)
+{
+  if (d_v1) {
+    omp_target_free(d_v1, omp_target_device);
+    d_v1 = NULL;
+  }
+  if (d_v2) {
+    omp_target_free(d_v2, omp_target_device);
+    d_v2 = NULL;
+  }
+  if (d_v7) {
+    omp_target_free(d_v7, omp_target_device);
+    d_v7 = NULL;
+  }
+  if (d_v8) {
+    omp_target_free(d_v8, omp_target_device);
+    d_v8 = NULL;
+  }
+  if (d_v9) {
+    omp_target_free(d_v9, omp_target_device);
+    d_v9 = NULL;
+  }
+  if (d_v10) {
+    omp_target_free(d_v10, omp_target_device);
+    d_v10 = NULL;
+  }
+  if (d_v11) {
+    omp_target_free(d_v11, omp_target_device);
+    d_v11 = NULL;
+  }
+  if (d_v12) {
+    omp_target_free(d_v12, omp_target_device);
+    d_v12 = NULL;
+  }
 }
diff --git a/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
new file mode 100644
index 0000000000000000000000000000000000000000..1f3b5dc1890815793be8df90b911e82dbfeb8903
--- /dev/null
+++ b/serial_omp_nas_workdir/data/src/cg-omp/data_plan.md
@@ -0,0 +1,69 @@
+# Data Management Plan
+
+## Arrays Inventory
+List ALL arrays used in timed region:
+
+| Array Name | Size | Type | Init | Access |
+|------------|------|------|------|--------|
+| `v1` | `NZ = NA*(NONZER+1)*(NONZER+1)` | index | host (generated by `f2`) | R |
+| `v2` | `NA+1` | index | host (set by `f2`) | R |
+| `v7` | `NZ` | working (matrix values) | host (set by `f2`) | R |
+| `v8` | `NA+2` | working (q vector) | host (initialized to ones) | R/W |
+| `v9` | `NA+2` | working (r vector) | host (zeroed before CG) | R/W |
+| `v10` | `NA+2` | working (p vector) | host | R/W |
+| `v11` | `NA+2` | working (Ap vector) | host | R/W |
+| `v12` | `NA+2` | working (z vector) | host | R/W |
+
+**Types:** working (main CG vectors/matrix), index (CSR structure). All arrays are prepared on the host before the timed `f1` loop and then kept on the device for the entire benchmark.
+
+## Functions in Timed Region
+| Function | Arrays Accessed | Frequency | Must Run On |
+|----------|------------------|-----------|-------------|
+| `f1` | `v1, v2, v7, v8, v9, v10, v11, v12` | per iteration (NITER times) | device |
+
+## Data Movement Strategy
+
+**Chosen Strategy:** C (global device state + `omp_target_alloc`)
+
+**Device Allocations (once):**
+- `d_v1` (`int`, `NZ` elements) via `omp_target_alloc`
+- `d_v2` (`int`, `NA+1` elements) via `omp_target_alloc`
+- `d_v7` (`double`, `NZ` elements) via `omp_target_alloc`
+- `d_v8`, `d_v9`, `d_v10`, `d_v11`, `d_v12` (`double`, `NA+2` each) via `omp_target_alloc`
+
+**Host→Device Transfers:**
+- When: after `f2` finishes initializing the CSR matrix and before the timed loop starts.
+- Arrays: `v1`, `v2` (indices), `v7` (matrix values), `v8`-`v12` (vectors) → device copies.
+- Total H→D: ~(NZ × (sizeof(int)+sizeof(double))) + (NA+1)×sizeof(int) + 5×(NA+2)×sizeof(double)
+  (Class S example: ~0.5 MB for CSR, ~0.5 MB for vectors, so < 2 MB total).
+
+**Device→Host Transfers:**
+- When: none for large arrays; scalars (`v80`, `v81`, `v78`) produced by reductions inside device kernels are implicitly mapped back via OpenMP reductions.
+- Arrays: none after initialization.
+- Total D→H: scalars only (negligible).
+
+**Transfers During Iterations:** NO – all CG vectors remain on device, only scalars need host visibility via reductions.
+
+## Critical Checks (for chosen strategy)
+
+**Strategy C:**
+- [ ] ALL functions in iteration loop use `is_device_ptr` (device pointers for CSR/vector arrays).
+- [ ] Scratch arrays (none beyond per-thread scalars) are allocated on device if needed.
+- [ ] No `map()` clauses are introduced for the hot-path vectors/matrix (only device pointers).
+
+**Common Mistakes:**
+- Some loops still run on host (will be moved into `target teams loop`).
+- Forgetting to update CRC scalars on device before each iteration.
+- Using host pointers inside device kernels (will use device pointers only).
+
+## Expected Transfer Volume
+- Total: ~1 MB (H→D) for Class S initialization; D→H only scalars per iteration.
+- **Red flag:** transferring full `v8`/`v9` every iteration – data will stay resident, dot products handled on device.
+
+## Additional Parallelization Notes
+- **RNG Replicable?** NO – no RNG inside timed region.
+- **Outer Saturation?** NITER (15 for Class S) – each `f1` iteration offloaded to saturate GPU teams.
+- **Sparse Matrix NONZER?** `NONZER` (class dependent; e.g., 7 for Class S).
+- **Histogram Strategy?** N/A – no histogram updates in CG.
+
+**Summary:** 8 arrays (0 scratch beyond scalars), 1 function (`f1`). Strategy C keeps ~1 MB of CSR/vectors on device via `omp_target_alloc`, reads them inside `f1` with `is_device_ptr`, and only moves scalars back to host via reductions.

tokens used
337,904
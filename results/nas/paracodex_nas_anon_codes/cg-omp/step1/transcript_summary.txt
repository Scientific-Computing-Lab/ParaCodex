- Documented the Strategy C plan (arrays, per-iteration function, transfer budget, and checks) ahead of implementation so the CUDA-style workflow is explicit before touching the code (`data_plan.md:3`, `data_plan.md:26`).
- Added `<omp.h>`, persistent device pointers, helper prototypes, and a device-managed `f1` that runs every loop through `#pragma omp target teams loop` to keep CSR/vectors on the GPU; `omp_target_alloc`/`omp_target_memcpy`/`omp_target_free` helpers now own the lifecycle of the working arrays (`cg.c:15`, `cg.c:26`, `cg.c:102`, `cg.c:559`, `cg.c:661`).
- Warmup and benchmark phases now call `f1` with device pointers, compute dot-products as device reductions, and scale `v8` on the GPU so only scalars touch the host; this keeps all vector math resident on the accelerator without extra transfers (`cg.c:197`, `cg.c:218`, `cg.c:250`).

**Testing**
- `make clean`
- `timeout 300 env OMP_TARGET_OFFLOAD=MANDATORY make CC=nvc++ CLASS=S run > gpu_output.txt 2>&1`
- `grep -E "Verification|SUCCESSFUL|FAILED" gpu_output.txt` → `VERIFICATION SUCCESSFUL`
- `diff baseline_output.txt gpu_output.txt` → only warning line-number shifts plus longer init/benchmark time and Mop/s changes, no incorrect results

**Next Steps**
1. Run the heavier Class B/C builds/runs (with the same `OMP_TARGET_OFFLOAD=MANDATORY` guard) and capture an `nsys` profile to understand GPU kernel performance now that the data lives on-device.
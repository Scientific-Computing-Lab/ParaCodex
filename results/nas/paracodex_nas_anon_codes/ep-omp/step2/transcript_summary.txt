Cached the hot sample loop’s bin count and histogram entries so the offloaded kernel stops rereading `v8`/`local_hist` on every iteration, and captured the profiling/summary story in `optimization_plan.md`.

- **Code** `ep.c:122` now aliases `v8` to `bin_count` and caches each histogram slot before the atomic update inside the `target teams loop`, which keeps register pressure lower in the hot path and helped drop the CLASS=S host runtime from 0.4355s to 0.4257s (≈1.024× faster).
- **Plan** The full analysis, bottleneck checklist, and final performance summary (baseline vs. final runtimes, speedup, applied micro-opts, and key insights) live in `optimization_plan.md:1-102`, including the note that the existing `nvkernel_main_F1L127_2` profile (1.743s, single instance) remains the reference.
- **Testing** `timeout 300 env OMP_TARGET_OFFLOAD=MANDATORY make CC=nvc++ CLASS=S run` (after `make clean`) – CLASS=S verification still reports “SUCCESSFUL”.
- **Next Steps** 1. Re-run the `nsys` profile to confirm whether the kernel-level time drops now that the loops cache local state. 2. If further gain is needed, consider merging the per-bin accumulations into a small shared/local buffer to reduce the remaining atomic traffic.
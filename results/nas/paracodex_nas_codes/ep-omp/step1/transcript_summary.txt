Reworked the timed region so every random-sample iteration runs as one `target teams loop` with `randlc_ep` and RNG globals declared on-device, removing the block-based scratch arrays and replacing the histogram with a per-thread local array that merges via atomics (see `data/src/ep-omp/ep.c:82-215`).

- **Parallel flow:** The host now seeds the RNG once, zeroes `q`, and enters a `target data map(tofrom: q[0:bins], sx, sy)` block; inside we iterate over `NN` samples with per-thread RNG exponentiation and two random draws per pair, atomic histogram merges, and reduction updates to `sx`/`sy` (`data/src/ep-omp/ep.c:129-214`). `randlc_ep` and the constants it uses live in a `#pragma omp declare target` block so the kernel can run entirely on-device without extra copies.
- **Data plan:** Documented array usage, device strategy, and per-thread histogram plan in `data/src/ep-omp/data_plan.md` before implementing the code changes.
- **Tests:** 
  1. `make clean` in `data/src/ep-omp`.
  2. `timeout 300 env OMP_TARGET_OFFLOAD=MANDATORY make CC=nvc++ CLASS=S run > gpu_output.txt 2>&1` (GPU run).
  3. `grep -E "Verification|SUCCESSFUL|FAILED" gpu_output.txt` (result: `SUCCESSFUL`).
  4. `diff baseline_output.txt gpu_output.txt` (only compiler-warning line-number shifts and shortened runtime; no verification data differences, as expected).
- **Diff note:** The `diff` output only reports warning line-number changes and the faster runtime (`Time in seconds`/`Mop/s`), so correctness is preserved.

Next steps you might consider:
1. Run the same flow for larger classes (B/C) to ensure the GPU mapping scales.
2. Capture an `nsys` profile under `OMP_TARGET_OFFLOAD=MANDATORY` to verify kernel occupancy and whether further tuning (e.g., asynchronous copies or shared-memory hist reductions) would help.
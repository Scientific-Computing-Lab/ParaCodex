**Summary**
- Wrapped the post-`makea` initialization and the timed benchmark in a persistent `#pragma omp target data map(to: a, colidx, rowstr) map(alloc: x,z,p,q,r)` block so the working vectors stay on the device while the norm/rescale loops and the `x` reset before the benchmark run execute through `#pragma omp target teams loop` reductions instead of host loops (`serial_omp_nas_workdir/data/src/cg-omp/cg.c:181`).
- Reworked `conj_grad` so every SpMV, dot, update, and final norm runs on the device via `#pragma omp target teams loop` (with reductions inside the loops) to avoid redundant transfers and keep the sparse CSR/Krylov work entirely on the accelerator (`serial_omp_nas_workdir/data/src/cg-omp/cg.c:338`).
- Recorded the data-management rationale in `serial_omp_nas_workdir/data/src/cg-omp/data_plan.md` and left the requested backup at `serial_omp_nas_workdir/data/src/cg-omp/cg.c.bak` so there is clear documentation of the arrays/strategy that guided this rewrite.

**Testing**
- `timeout 300 env OMP_TARGET_OFFLOAD=MANDATORY make CC=nvc++ CLASS=S run > serial_omp_nas_workdir/data/src/cg-omp/baseline_output.txt 2>&1` (baseline capture required by the workflow).
- `timeout 300 env OMP_TARGET_OFFLOAD=MANDATORY make CC=nvc++ CLASS=S run > serial_omp_nas_workdir/data/src/cg-omp/gpu_output.txt 2>&1` (launch on the modified code; `grep -E "Verification|SUCCESSFUL|FAILED" serial_omp_nas_workdir/data/src/cg-omp/gpu_output.txt` prints `VERIFICATION SUCCESSFUL`).
- `diff serial_omp_nas_workdir/data/src/cg-omp/baseline_output.txt serial_omp_nas_workdir/data/src/cg-omp/gpu_output.txt` shows only warning line-number shifts, implicit map warnings, and the expected timing/MFLOPS differences from the GPU runâ€”`VERIFICATION` and `zeta` lines remain identical.

Next steps: if you need broader validation, rerun the GPU path on Class B/C inputs or collect an `nsys` profile now that the loops stay resident on the accelerator.
- Precomputed row-level metadata so each batch’s ragged span is flattened once (`main.cpp:94-166`). `row_write_base` captures every row’s starting index and `row_dense_base` holds the matching dense vector offset, eliminating per-thread offset math and letting us launch work proportional to the actual rows touched.
- Retuned the work estimator to `row_work = total_rows * ncols` and rewrote both GPU kernels to iterate over `(row_token, col)` pairs (`main.cpp:145-190`). The collapse(2) loop plus metadata ensures every thread touches contiguous cache lines, removing the high-latency strided loop the profiler flagged. k2 mirrors k1 for validation but now exercises the same row-wise traversal for a meaningful cross-check.
- Updated the persistent `target data` region to keep the new metadata resident on the device and freed the host buffers once they’re no longer needed (`main.cpp:131-220`). This avoids remapping `offset` that the kernels no longer read and keeps device memory traffic minimal.
- Tests: `make -f Makefile.nvc clean` → `make -f Makefile.nvc`.

Next steps: 1) Run `FORCE_OMP_GPU=1 OMP_TARGET_OFFLOAD=MANDATORY nsys profile …` to confirm the primary kernel (now `nvkernel_main_F1L153_4`) shows higher SOL and improved memory bandwidth; 2) If further tuning is needed, sweep `block_size` beyond 1024 to see if wider thread teams help this GPU’s 24 SMs.
**Concurrency Tuning**
- Added device-wide scheduling constants plus `compute_num_teams_hint` so the runtime can size `num_teams` based on the live iteration space while capping at 4K teams and 256 threads/team, matching the RTX 4060 Laptop GPU’s 24 SM configuration (`main.cpp:7-28`).  
- Replaced the nested `teams`+`parallel` pragmas with a combined `target teams distribute parallel for collapse(2)` region, guarded by a lightweight bounds check to create a rectangular iteration space without touching the rotation math; this lets the GPU see the full `(layer, col)` space and apply the tuned `num_teams`/`thread_limit` hints (`main.cpp:34-64`).  
- Mirrored the same concurrency strategy in the reference path so both kernels pay the same data movement cost and can be profiled fairly on the device (`main.cpp:72-102`).

**Profiling**
- Commands run (in order): `make -f Makefile.nvc clean`, `make -f Makefile.nvc`, `FORCE_OMP_GPU=1 OMP_TARGET_OFFLOAD=MANDATORY nsys profile --stats=true --trace=cuda,osrt --force-overwrite=true -o nsys_profile make -f Makefile.nvc run`, plus `nsys stats --force-export=true --report cuda_gpu_kern_sum --format csv nsys_profile.nsys-rep`.  
- nsys kernel summary (25 launches each): `rotate_matrix_parallel` avg 20.247 µs, `rotate_matrix_serial` avg 20.315 µs, down from ~25.7 µs before; total GPU kernel time now ≈1.014 ms for the run, and the application reports `PASS` with matching FNV checksums.

**Next Steps**
1. Dive into Nsight Compute for occupancy/SASS metrics to confirm the 256-thread teams keep register pressure in check and to see if additional unrolling would help.
2. Explore shared-memory staging per layer to reduce global transactions once concurrency is fully utilized.
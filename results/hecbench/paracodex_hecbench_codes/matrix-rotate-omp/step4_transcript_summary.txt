**Updates**
- In `data/src/matrix-rotate-omp/main.cpp:31-127` the per-layer rotation work now iterates only over the active edge columns (`col = first .. last-1`) so every GPU work-item does useful work, eliminating the divergent guard that previously stalled most threads in each warp.
- Precompute `first_row`, `last_row`, and per-iteration `mirror_row`/`col_row` offsets so each rotation touches four cache lines using a single multiply per row instead of recomputing `row * n` on every swap; this lowers instruction count and keeps accesses to the top/bottom edges contiguous, which matters on the RTX 4060 Laptop GPU’s 24 SMs with limited L1 bandwidth.

**Profiling**
- Commands (in order): `make -f Makefile.nvc clean && make -f Makefile.nvc`, `make -f Makefile.nvc clean`, `FORCE_OMP_GPU=1 OMP_TARGET_OFFLOAD=MANDATORY nsys profile --stats=true --trace=cuda,osrt --force-overwrite=true -o nsys_profile make -f Makefile.nvc run`, and `nsys stats --report cuda_gpu_kern_sum nsys_profile.nsys-rep` (the optional `cuda_memory_op_sum` report isn’t available in this Nsight build).
- Run output (`./main 500 25`) still reports matching FNV checksums and `PASS`, with an average kernel time of 6.1e-5 s per repeat.
- Nsight Systems now shows each GPU kernel at ~1.28 µs (total 31.9 µs over 25 launches) with the work split evenly between the serial and parallel variants:  
  `nvkernel__Z22rotate_matrix_parallelPfii_F1L42_2` – 31,906 ns total (25 instances);  
  `nvkernel__Z20rotate_matrix_serialPfii_F1L93_6` – 31,875 ns total (25 instances).
- The drastic drop from the prior ~20 µs averages confirms that trimming the iteration space removed thousands of empty, memory-latency-bound iterations per launch, improving SOL utilization; remaining time is evenly split between the two kernels, indicating both are now similarly efficient.

**Next steps**
1. Re-run `nsys stats --report gpu__l2_tex_write_sectors` (or Nsight Compute) if you want detailed L1/L2 bandwidth confirmation.
2. Sweep larger `n` to ensure the new bounds logic scales and to look for any renewed memory bottlenecks.
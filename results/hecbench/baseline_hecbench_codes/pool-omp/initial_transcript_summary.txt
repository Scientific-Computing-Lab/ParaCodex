**Implementation**
- `data/src/pool-omp/main.cpp:12-38` marks the pooling functors and small helper min/max routines with `omp declare target`, making them callable from device code without duplicating logic.
- `data/src/pool-omp/main.cpp:43-148` rewrites `KernelPool2DGrad` as an OpenMP `target teams distribute parallel for` kernel, using a 256-thread team size to align with warp multiples and passing device pointers via `is_device_ptr` so all pooling work executes on the GPU without repeated mappings.
- `data/src/pool-omp/main.cpp:157-276` builds the host driver: retains the serial setup, seeds data, wraps the repeated launches in a persistent `target data` region (`map(to: input, output, output_grad)`, `map(from: input_grad)`), times only the compute loop, and validates against the CPU reference.

**Build**
- `make -f Makefile.nvc clean && make -f Makefile.nvc` succeeded.

**Notes**
- Runtime test in this sandbox exits early because no OpenMP target device is visible (“No OpenMP target devices available.”).

**Next steps**
1. Run `./main 32 30 128 128 24 24 20` on a GPU-enabled node to confirm the PASS result and capture realistic timings.
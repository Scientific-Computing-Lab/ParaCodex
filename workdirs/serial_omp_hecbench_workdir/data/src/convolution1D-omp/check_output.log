nvc++  -std=c++14 -Wall -I/root/codex_baseline/cuda_omp_workdir/gate_sdk -O3 -Minfo -mp=gpu -gpu=cc89 -c main.cpp -o main.o
gate_record_output(char const*, double const*, unsigned long):
          52, Loop not vectorized: may not be beneficial for target
gate_record_output(char const*, float const*, unsigned long):
          43, Generated vector simd code for the loop containing reductions
          44, FMA (fused multiply-add) instruction(s) generated
main:
    400, Loop not vectorized/parallelized: potential early exits
void conv1D<double>(int, int, int):
    331, FMA (fused multiply-add) instruction(s) generated
    350, Loop not fused: function call before adjacent loop
         Generated vector simd code for the loop
    355, Loop not vectorized/parallelized: contains call
         315, Recognized memory zero idiom
         331, Loop not fused: function call before adjacent loop
              Loop not vectorized/parallelized: potential early exits
              Generated vector simd code for the loop containing reductions
              Loop not vectorized: may not be beneficial for target
         315, Recognized memory zero idiom
         331, Loop not fused: function call before adjacent loop
              Loop not vectorized/parallelized: potential early exits
              Generated vector simd code for the loop containing reductions
              Loop not vectorized: may not be beneficial for target
         315, Recognized memory zero idiom
         331, Loop not fused: function call before adjacent loop
              Loop not vectorized/parallelized: potential early exits
              Generated vector simd code for the loop containing reductions
              Loop not vectorized: may not be beneficial for target
void conv1D<float>(int, int, int):
    331, FMA (fused multiply-add) instruction(s) generated
    350, Loop not fused: function call before adjacent loop
         Generated vector simd code for the loop
    355, Loop not vectorized/parallelized: contains call
         315, Recognized memory zero idiom
         331, Loop not fused: function call before adjacent loop
              Loop not vectorized/parallelized: potential early exits
              Generated vector simd code for the loop containing reductions
         315, Recognized memory zero idiom
         331, Loop not fused: function call before adjacent loop
              Loop not vectorized/parallelized: potential early exits
              Generated vector simd code for the loop containing reductions
         315, Recognized memory zero idiom
         331, Loop not fused: function call before adjacent loop
              Loop not vectorized/parallelized: potential early exits
              Generated vector simd code for the loop containing reductions
void conv1D<short>(int, int, int):
    350, Loop not fused: function call before adjacent loop
         Generated vector simd code for the loop
    355, Loop not vectorized/parallelized: contains call
         315, Recognized memory zero idiom
         331, Loop not fused: function call before adjacent loop
              Loop not vectorized/parallelized: potential early exits
              Generated vector simd code for the loop containing reductions
              Loop not vectorized: recurrence
              Loop unrolled 2 times
         315, Recognized memory zero idiom
         331, Loop not fused: function call before adjacent loop
              Loop not vectorized/parallelized: potential early exits
              Generated vector simd code for the loop containing reductions
              Loop not vectorized: recurrence
              Loop unrolled 2 times
         315, Recognized memory zero idiom
         331, Loop not fused: function call before adjacent loop
              Loop not vectorized/parallelized: potential early exits
              Generated vector simd code for the loop containing reductions
              Loop not vectorized: recurrence
              Loop unrolled 2 times
void conv1d_gpu<double>(double const*, double const*, double*, int, int, int, bool):
     95, Loop not fused: no successor loop
          67, Generated vector simd code for the loop containing reductions
          69, FMA (fused multiply-add) instruction(s) generated
    104, #omp target teams distribute parallel for num_teams((input_width+255)/256) thread_limit(256)
        104, Generating "nvkernel__Z10conv1d_gpuIdEvPKT_S2_PS0_iiib_F1L104_2" GPU kernel
        109, Loop parallelized across teams and threads(128), schedule(static)
    104, Generating map(tofrom:in[:input_width],out[:input_width],mask[:mask_width]) 
         Loop not vectorized/parallelized: contains call
    109, Loop not vectorized/parallelized: not countable
    112, Generated vector simd code for the loop containing reductions
    115, FMA (fused multiply-add) instruction(s) generated
    120, #omp target teams distribute parallel for num_teams((input_width+255)/256) thread_limit(256)
        103, Generating map(to:in[:input_width]) 
             Generating map(from:out[:input_width]) 
             Generating map(to:mask[:mask_width]) 
        109, Loop parallelized across teams and threads, schedule(static)
    120, Generating map(tofrom:in[:input_width],out[:input_width],mask[:mask_width]) 
void benchmark_kernel<void (*)(double const*, double const*, double*, int, int, int, bool), double>(char const*, void (*)(double const*, double const*, double*, int, int, int, bool), double const*, double const*, double*, int, int, int):
         999, Recognized memory zero idiom
         288, Loop not vectorized/parallelized: potential early exits
         291, Generated vector simd code for the loop containing reductions
         292, FMA (fused multiply-add) instruction(s) generated
         302, Loop not fused: function call before adjacent loop
              Loop not vectorized: may not be beneficial for target
void reference<double>(double const*, double const*, double const*, int, int, char const*):
    288, Loop not vectorized/parallelized: potential early exits
    291, Generated vector simd code for the loop containing reductions
    293, FMA (fused multiply-add) instruction(s) generated
          22, Loop not fused: function call before adjacent loop
              Loop not vectorized: may not be beneficial for target
void conv1d_serial_host<double>(double const*, double const*, double*, int, int):
     67, Generated vector simd code for the loop containing reductions
     70, FMA (fused multiply-add) instruction(s) generated
void conv1d_tiled_gpu<double>(double const*, double const*, double*, int, int, int, bool):
    144, Loop not fused: no successor loop
          67, Generated vector simd code for the loop containing reductions
          69, FMA (fused multiply-add) instruction(s) generated
    153, Loop not vectorized/parallelized: contains call
    158, #omp target teams num_teams((input_width+255)/256) thread_limit(256)
        158, Generating "nvkernel__Z16conv1d_tiled_gpuIdEvPKT_S2_PS0_iiib_F1L158_9" GPU kernel
        165, #omp parallel
          175, Barrier
        166, Team private (tile,block_start) located in CUDA shared memory
    158, Generating map(tofrom:mask[:mask_width],in[:input_width],out[:input_width]) 
    167, Loop not vectorized: data dependency
    177, Loop not vectorized/parallelized: potential early exits
    181, Generated vector simd code for the loop containing reductions
    182, FMA (fused multiply-add) instruction(s) generated
void conv1d_tiled_caching_gpu<double>(double const*, double const*, double*, int, int, int, bool):
    212, Loop not fused: no successor loop
          67, Generated vector simd code for the loop containing reductions
          69, FMA (fused multiply-add) instruction(s) generated
    221, Loop not vectorized/parallelized: contains call
    226, #omp target teams num_teams((input_width+255)/256) thread_limit(256)
        226, Generating "nvkernel__Z24conv1d_tiled_caching_gpuIdEvPKT_S2_PS0_iiib_F1L226_17" GPU kernel
        236, #omp parallel
          250, Barrier
        237, Team private (mask_tile,block_start,tile,next_tile_start) located in CUDA shared memory
    226, Generating map(tofrom:mask[:mask_width],in[:input_width],out[:input_width]) 
    238, Loop not vectorized: data dependency
         Loop unrolled 4 times
         Loop not vectorized: data dependency
         Loop unrolled 4 times
    252, Loop not vectorized/parallelized: potential early exits
    262, FMA (fused multiply-add) instruction(s) generated
    265, FMA (fused multiply-add) instruction(s) generated
void conv1d_gpu<float>(float const*, float const*, float*, int, int, int, bool):
     95, Loop not fused: no successor loop
          67, Generated vector simd code for the loop containing reductions
          69, FMA (fused multiply-add) instruction(s) generated
    104, #omp target teams distribute parallel for num_teams((input_width+255)/256) thread_limit(256)
        104, Generating "nvkernel__Z10conv1d_gpuIfEvPKT_S2_PS0_iiib_F1L104_25" GPU kernel
        109, Loop parallelized across teams and threads(128), schedule(static)
    104, Generating map(tofrom:in[:input_width],out[:input_width],mask[:mask_width]) 
         Loop not vectorized/parallelized: contains call
    109, Loop not vectorized/parallelized: not countable
    112, Generated vector simd code for the loop containing reductions
    115, FMA (fused multiply-add) instruction(s) generated
    120, #omp target teams distribute parallel for num_teams((input_width+255)/256) thread_limit(256)
        103, Generating map(to:in[:input_width]) 
             Generating map(from:out[:input_width]) 
             Generating map(to:mask[:mask_width]) 
        109, Loop parallelized across teams and threads, schedule(static)
    120, Generating map(tofrom:in[:input_width],out[:input_width],mask[:mask_width]) 
void benchmark_kernel<void (*)(float const*, float const*, float*, int, int, int, bool), float>(char const*, void (*)(float const*, float const*, float*, int, int, int, bool), float const*, float const*, float*, int, int, int):
         999, Recognized memory zero idiom
         288, Loop not vectorized/parallelized: potential early exits
         291, Generated vector simd code for the loop containing reductions
         292, FMA (fused multiply-add) instruction(s) generated
         302, Loop not fused: function call before adjacent loop
              Generated vector simd code for the loop containing reductions
              FMA (fused multiply-add) instruction(s) generated
void reference<float>(float const*, float const*, float const*, int, int, char const*):
     26, FMA (fused multiply-add) instruction(s) generated
    288, Loop not vectorized/parallelized: potential early exits
    291, Generated vector simd code for the loop containing reductions
    293, FMA (fused multiply-add) instruction(s) generated
          26, Loop not fused: function call before adjacent loop
              Generated vector simd code for the loop containing reductions
void conv1d_serial_host<float>(float const*, float const*, float*, int, int):
     67, Generated vector simd code for the loop containing reductions
     70, FMA (fused multiply-add) instruction(s) generated
void conv1d_tiled_gpu<float>(float const*, float const*, float*, int, int, int, bool):
    144, Loop not fused: no successor loop
          67, Generated vector simd code for the loop containing reductions
          69, FMA (fused multiply-add) instruction(s) generated
    153, Loop not vectorized/parallelized: contains call
    158, #omp target teams num_teams((input_width+255)/256) thread_limit(256)
        158, Generating "nvkernel__Z16conv1d_tiled_gpuIfEvPKT_S2_PS0_iiib_F1L158_32" GPU kernel
        165, #omp parallel
          175, Barrier
        166, Team private (tile,block_start) located in CUDA shared memory
    158, Generating map(tofrom:mask[:mask_width],in[:input_width],out[:input_width]) 
    167, Loop not vectorized: data dependency
    177, Loop not vectorized/parallelized: potential early exits
    181, Generated vector simd code for the loop containing reductions
    182, FMA (fused multiply-add) instruction(s) generated
void conv1d_tiled_caching_gpu<float>(float const*, float const*, float*, int, int, int, bool):
    212, Loop not fused: no successor loop
          67, Generated vector simd code for the loop containing reductions
          69, FMA (fused multiply-add) instruction(s) generated
    221, Loop not vectorized/parallelized: contains call
    226, #omp target teams num_teams((input_width+255)/256) thread_limit(256)
        226, Generating "nvkernel__Z24conv1d_tiled_caching_gpuIfEvPKT_S2_PS0_iiib_F1L226_40" GPU kernel
        236, #omp parallel
          250, Barrier
        237, Team private (mask_tile,block_start,tile,next_tile_start) located in CUDA shared memory
    226, Generating map(tofrom:mask[:mask_width],in[:input_width],out[:input_width]) 
    238, Loop not vectorized: data dependency
         Loop unrolled 4 times
         Loop not vectorized: data dependency
         Loop unrolled 4 times
    252, Loop not vectorized/parallelized: potential early exits
    262, FMA (fused multiply-add) instruction(s) generated
    265, FMA (fused multiply-add) instruction(s) generated
void conv1d_gpu<short>(short const*, short const*, short*, int, int, int, bool):
     95, Loop not fused: no successor loop
          67, Generated vector simd code for the loop containing reductions
    104, #omp target teams distribute parallel for num_teams((input_width+255)/256) thread_limit(256)
        104, Generating "nvkernel__Z10conv1d_gpuIsEvPKT_S2_PS0_iiib_F1L104_48" GPU kernel
        109, Loop parallelized across teams and threads(128), schedule(static)
    104, Generating map(tofrom:in[:input_width],out[:input_width],mask[:mask_width]) 
         Loop not vectorized/parallelized: contains call
    109, Loop not vectorized/parallelized: not countable
    112, Generated vector simd code for the loop containing reductions
    120, #omp target teams distribute parallel for num_teams((input_width+255)/256) thread_limit(256)
        103, Generating map(to:in[:input_width]) 
             Generating map(from:out[:input_width]) 
             Generating map(to:mask[:mask_width]) 
        109, Loop parallelized across teams and threads, schedule(static)
    120, Generating map(tofrom:in[:input_width],out[:input_width],mask[:mask_width]) 
void benchmark_kernel<void (*)(short const*, short const*, short*, int, int, int, bool), short>(char const*, void (*)(short const*, short const*, short*, int, int, int, bool), short const*, short const*, short*, int, int, int):
         999, Recognized memory zero idiom
         288, Loop not vectorized/parallelized: potential early exits
         291, Generated vector simd code for the loop containing reductions
         302, Loop not fused: function call before adjacent loop
              Loop not vectorized: recurrence
              Loop unrolled 2 times
void reference<short>(short const*, short const*, short const*, int, int, char const*):
    288, Loop not vectorized/parallelized: potential early exits
    291, Generated vector simd code for the loop containing reductions
          18, Loop not fused: function call before adjacent loop
              Loop not vectorized: recurrence
              Loop unrolled 2 times
void gate_record_output<short>(char const*, short const*, unsigned long):
          35, Loop not vectorized: recurrence
              Loop unrolled 2 times
void conv1d_serial_host<short>(short const*, short const*, short*, int, int):
     67, Generated vector simd code for the loop containing reductions
void conv1d_tiled_gpu<short>(short const*, short const*, short*, int, int, int, bool):
    144, Loop not fused: no successor loop
          67, Generated vector simd code for the loop containing reductions
    153, Loop not vectorized/parallelized: contains call
    158, #omp target teams num_teams((input_width+255)/256) thread_limit(256)
        158, Generating "nvkernel__Z16conv1d_tiled_gpuIsEvPKT_S2_PS0_iiib_F1L158_55" GPU kernel
        165, #omp parallel
          175, Barrier
        166, Team private (tile,block_start) located in CUDA shared memory
    158, Generating map(tofrom:mask[:mask_width],in[:input_width],out[:input_width]) 
    167, Loop not vectorized: data dependency
    177, Loop not vectorized/parallelized: potential early exits
    181, Generated vector simd code for the loop containing reductions
void conv1d_tiled_caching_gpu<short>(short const*, short const*, short*, int, int, int, bool):
    212, Loop not fused: no successor loop
          67, Generated vector simd code for the loop containing reductions
    221, Loop not vectorized/parallelized: contains call
    226, #omp target teams num_teams((input_width+255)/256) thread_limit(256)
        226, Generating "nvkernel__Z24conv1d_tiled_caching_gpuIsEvPKT_S2_PS0_iiib_F1L226_63" GPU kernel
        236, #omp parallel
          250, Barrier
        237, Team private (mask_tile,block_start,tile,next_tile_start) located in CUDA shared memory
    226, Generating map(tofrom:mask[:mask_width],in[:input_width],out[:input_width]) 
    238, Loop not vectorized: data dependency
         Loop unrolled 4 times
         Loop not vectorized: data dependency
         Loop unrolled 4 times
    252, Loop not vectorized/parallelized: potential early exits
std::chrono::duration<long, std::ratio<1l, 1000000000l>>::_S_gcd(long, long):
      5, include "chrono"
         472, Loop not vectorized/parallelized: not countable
void std::fill<double*, double>(double*, double*, double const&):
         969, Recognized memory set idiom
void std::__fill_a<double*, double>(double*, double*, double const&):
         923, Recognized memory set idiom
__gnu_cxx::__enable_if<std::__is_scalar<double>::__value, void>::__type std::__fill_a1<double*, double>(double*, double*, double const&):
      8, include "algorithm"
          10, include "algorithm"
               61, include "stl_algobase.h"
                   923, Recognized memory set idiom
void std::fill<float*, float>(float*, float*, float const&):
         969, Recognized memory set idiom
void std::__fill_a<float*, float>(float*, float*, float const&):
         923, Recognized memory set idiom
__gnu_cxx::__enable_if<std::__is_scalar<float>::__value, void>::__type std::__fill_a1<float*, float>(float*, float*, float const&):
      8, include "algorithm"
          10, include "algorithm"
               61, include "stl_algobase.h"
                   923, Recognized memory set idiom
void std::fill<short*, short>(short*, short*, short const&):
         969, Recognized memory set idiom
void std::__fill_a<short*, short>(short*, short*, short const&):
         923, Recognized memory set idiom
__gnu_cxx::__enable_if<std::__is_scalar<short>::__value, void>::__type std::__fill_a1<short*, short>(short*, short*, short const&):
      8, include "algorithm"
          10, include "algorithm"
               61, include "stl_algobase.h"
                   923, Recognized memory set idiom
_INTERNAL_8_main_cpp_main::gate_fnv1a64_bytes(void const*, unsigned long):
     10, include "gate.h"
          15, Loop not vectorized: recurrence
              Loop unrolled 2 times
_INTERNAL_8_main_cpp_main::GATE_CHECKSUM_BYTES(char const*, void const*, unsigned long):
          15, Loop not vectorized: recurrence
              Loop unrolled 2 times
_INTERNAL_8_main_cpp_main::GATE_STATS_F32(char const*, float const*, unsigned long):
     10, include "gate.h"
          43, Generated vector simd code for the loop containing reductions
          44, FMA (fused multiply-add) instruction(s) generated
_INTERNAL_8_main_cpp_main::GATE_STATS_F64(char const*, double const*, unsigned long):
     10, include "gate.h"
          52, Loop not vectorized: may not be beneficial for target
nvc++  -std=c++14 -Wall -I/root/codex_baseline/cuda_omp_workdir/gate_sdk -O3 -Minfo -mp=gpu -gpu=cc89 main.o -o main 
make -C /root/codex_baseline/cuda_omp_workdir/golden_labels/src/convolution1D-serial -f Makefile.nvc clean
make[1]: Entering directory '/root/codex_baseline/cuda_omp_workdir/golden_labels/src/convolution1D-serial'
rm -rf main main.o
make[1]: Leaving directory '/root/codex_baseline/cuda_omp_workdir/golden_labels/src/convolution1D-serial'
make -C /root/codex_baseline/cuda_omp_workdir/golden_labels/src/convolution1D-serial -f Makefile.nvc 	    CC="nvc++" OPTIMIZE="yes" DEBUG="no" DEVICE="gpu" SM="cc89" 	    CFLAGS=" -std=c++14 -Wall -I/root/codex_baseline/cuda_omp_workdir/gate_sdk -O3 -Minfo -mp=gpu -gpu=cc89 -I/root/codex_baseline/cuda_omp_workdir/gate_sdk"
make[1]: Entering directory '/root/codex_baseline/cuda_omp_workdir/golden_labels/src/convolution1D-serial'
nvc++ -std=c++14 -Wall -I/root/codex_baseline/cuda_omp_workdir/gate_sdk -O3 -Minfo -mp=gpu -gpu=cc89 -I/root/codex_baseline/cuda_omp_workdir/gate_sdk -c main.cpp -o main.o
gate_record_output(char const*, double const*, unsigned long):
          52, Loop not vectorized: may not be beneficial for target
gate_record_output(char const*, float const*, unsigned long):
          43, Generated vector simd code for the loop containing reductions
          44, FMA (fused multiply-add) instruction(s) generated
main:
    265, Loop not vectorized/parallelized: potential early exits
void conv1D<double>(int, int, int):
     61, FMA (fused multiply-add) instruction(s) generated
    102, FMA (fused multiply-add) instruction(s) generated
    133, FMA (fused multiply-add) instruction(s) generated
    140, FMA (fused multiply-add) instruction(s) generated
    162, FMA (fused multiply-add) instruction(s) generated
    188, Loop not fused: function call before adjacent loop
         Generated vector simd code for the loop
    191, Loop not vectorized/parallelized: contains call
    199, Loop not fused: function call before adjacent loop
          60, Generated vector simd code for the loop containing reductions
         158, Loop not vectorized/parallelized: potential early exits
         161, Generated vector simd code for the loop containing reductions
         172, Loop not fused: function call before adjacent loop
              Loop not vectorized: may not be beneficial for target
          82, Loop not fused: different loop trip count
              Generated vector simd code for the loop
          88, Loop not fused: complex flow graph
              Generated vector simd code for the loop
          94, Generated vector simd code for the loop
         100, Loop not vectorized/parallelized: potential early exits
         102, Generated vector simd code for the loop containing reductions
              Loop unrolled 2 times
         216, Loop not vectorized/parallelized: too deeply nested
         158, Loop not vectorized/parallelized: potential early exits
         161, Generated vector simd code for the loop containing reductions
         172, Loop not fused: function call before adjacent loop
              Loop not vectorized: may not be beneficial for target
    233, Loop not vectorized/parallelized: contains call
         158, Loop not vectorized/parallelized: potential early exits
         161, Generated vector simd code for the loop containing reductions
         172, Loop not fused: function call before adjacent loop
              Loop not vectorized: may not be beneficial for target
void conv1D<float>(int, int, int):
     61, FMA (fused multiply-add) instruction(s) generated
    102, FMA (fused multiply-add) instruction(s) generated
    133, FMA (fused multiply-add) instruction(s) generated
    140, FMA (fused multiply-add) instruction(s) generated
    162, FMA (fused multiply-add) instruction(s) generated
    172, FMA (fused multiply-add) instruction(s) generated
    188, Loop not fused: function call before adjacent loop
         Generated vector simd code for the loop
    191, Loop not vectorized/parallelized: contains call
    199, Loop not fused: function call before adjacent loop
          60, Generated vector simd code for the loop containing reductions
         158, Loop not vectorized/parallelized: potential early exits
         161, Generated vector simd code for the loop containing reductions
         172, Loop not fused: function call before adjacent loop
              Generated vector simd code for the loop containing reductions
          82, Loop not fused: different loop trip count
              Generated vector simd code for the loop
          88, Loop not fused: complex flow graph
              Generated vector simd code for the loop
          94, Generated vector simd code for the loop
         100, Loop not vectorized/parallelized: potential early exits
         102, Generated vector simd code for the loop containing reductions
              Loop unrolled 4 times
         216, Loop not vectorized/parallelized: too deeply nested
         158, Loop not vectorized/parallelized: potential early exits
         161, Generated vector simd code for the loop containing reductions
         172, Loop not fused: function call before adjacent loop
              Generated vector simd code for the loop containing reductions
    233, Loop not vectorized/parallelized: contains call
         158, Loop not vectorized/parallelized: potential early exits
         161, Generated vector simd code for the loop containing reductions
         172, Loop not fused: function call before adjacent loop
              Generated vector simd code for the loop containing reductions
void conv1D<short>(int, int, int):
    188, Loop not fused: function call before adjacent loop
         Generated vector simd code for the loop
    191, Loop not vectorized/parallelized: contains call
    199, Loop not fused: function call before adjacent loop
          60, Generated vector simd code for the loop containing reductions
         158, Loop not vectorized/parallelized: potential early exits
         161, Generated vector simd code for the loop containing reductions
         172, Loop not fused: function call before adjacent loop
              Loop not vectorized: recurrence
              Loop unrolled 2 times
          82, Loop not fused: different loop trip count
              Generated vector simd code for the loop
          88, Loop not fused: complex flow graph
              Generated vector simd code for the loop
          94, Generated vector simd code for the loop
         100, Loop not vectorized/parallelized: potential early exits
         102, Generated vector simd code for the loop containing reductions
         216, Loop not vectorized/parallelized: too deeply nested
         158, Loop not vectorized/parallelized: potential early exits
         161, Generated vector simd code for the loop containing reductions
         172, Loop not fused: function call before adjacent loop
              Loop not vectorized: recurrence
              Loop unrolled 2 times
    233, Loop not vectorized/parallelized: contains call
         158, Loop not vectorized/parallelized: potential early exits
         161, Generated vector simd code for the loop containing reductions
         172, Loop not fused: function call before adjacent loop
              Loop not vectorized: recurrence
              Loop unrolled 2 times
void conv1d<double>(double const*, double const*, double*, int, int):
     60, Generated vector simd code for the loop containing reductions
     62, FMA (fused multiply-add) instruction(s) generated
void reference<double>(double const*, double const*, double const*, int, int, char const*):
    158, Loop not vectorized/parallelized: potential early exits
    161, Generated vector simd code for the loop containing reductions
    163, FMA (fused multiply-add) instruction(s) generated
          23, Loop not fused: function call before adjacent loop
              Loop not vectorized: may not be beneficial for target
void conv1d_tiled<double>(double const*, double const*, double*, int, int):
     82, Loop not fused: different loop trip count
         Generated vector simd code for the loop
     88, Loop not fused: complex flow graph
         Generated vector simd code for the loop
     94, Generated vector simd code for the loop
    100, Loop not vectorized/parallelized: potential early exits
    102, Generated vector simd code for the loop containing reductions
         Loop unrolled 2 times
         FMA (fused multiply-add) instruction(s) generated
    103, FMA (fused multiply-add) instruction(s) generated
void conv1d_tiled_caching<double>(double const*, double const*, double*, int, int):
    138, FMA (fused multiply-add) instruction(s) generated
    140, FMA (fused multiply-add) instruction(s) generated
void conv1d<float>(float const*, float const*, float*, int, int):
     60, Generated vector simd code for the loop containing reductions
     62, FMA (fused multiply-add) instruction(s) generated
void reference<float>(float const*, float const*, float const*, int, int, char const*):
     27, FMA (fused multiply-add) instruction(s) generated
    158, Loop not vectorized/parallelized: potential early exits
    161, Generated vector simd code for the loop containing reductions
    163, FMA (fused multiply-add) instruction(s) generated
          27, Loop not fused: function call before adjacent loop
              Generated vector simd code for the loop containing reductions
void conv1d_tiled<float>(float const*, float const*, float*, int, int):
     82, Loop not fused: different loop trip count
         Generated vector simd code for the loop
     88, Loop not fused: complex flow graph
         Generated vector simd code for the loop
     94, Generated vector simd code for the loop
    100, Loop not vectorized/parallelized: potential early exits
    102, Generated vector simd code for the loop containing reductions
         Loop unrolled 4 times
         FMA (fused multiply-add) instruction(s) generated
    103, FMA (fused multiply-add) instruction(s) generated
void conv1d_tiled_caching<float>(float const*, float const*, float*, int, int):
    138, FMA (fused multiply-add) instruction(s) generated
    140, FMA (fused multiply-add) instruction(s) generated
void conv1d<short>(short const*, short const*, short*, int, int):
     60, Generated vector simd code for the loop containing reductions
void reference<short>(short const*, short const*, short const*, int, int, char const*):
    158, Loop not vectorized/parallelized: potential early exits
    161, Generated vector simd code for the loop containing reductions
          19, Loop not fused: function call before adjacent loop
              Loop not vectorized: recurrence
              Loop unrolled 2 times
void gate_record_output<short>(char const*, short const*, unsigned long):
          35, Loop not vectorized: recurrence
              Loop unrolled 2 times
void conv1d_tiled<short>(short const*, short const*, short*, int, int):
     82, Loop not fused: different loop trip count
         Generated vector simd code for the loop
     88, Loop not fused: complex flow graph
         Generated vector simd code for the loop
     94, Generated vector simd code for the loop
    100, Loop not vectorized/parallelized: potential early exits
    102, Generated vector simd code for the loop containing reductions
std::chrono::duration<long, std::ratio<1l, 1000000000l>>::_S_gcd(long, long):
      8, include "chrono"
         472, Loop not vectorized/parallelized: not countable
_INTERNAL_8_main_cpp_main::gate_fnv1a64_bytes(void const*, unsigned long):
     11, include "gate.h"
          15, Loop not vectorized: recurrence
              Loop unrolled 2 times
_INTERNAL_8_main_cpp_main::GATE_CHECKSUM_BYTES(char const*, void const*, unsigned long):
          15, Loop not vectorized: recurrence
              Loop unrolled 2 times
_INTERNAL_8_main_cpp_main::GATE_STATS_F32(char const*, float const*, unsigned long):
     11, include "gate.h"
          43, Generated vector simd code for the loop containing reductions
          44, FMA (fused multiply-add) instruction(s) generated
_INTERNAL_8_main_cpp_main::GATE_STATS_F64(char const*, double const*, unsigned long):
     11, include "gate.h"
          52, Loop not vectorized: may not be beneficial for target
nvc++ -std=c++14 -Wall -I/root/codex_baseline/cuda_omp_workdir/gate_sdk -O3 -Minfo -mp=gpu -gpu=cc89 -I/root/codex_baseline/cuda_omp_workdir/gate_sdk main.o -o main 
make[1]: Leaving directory '/root/codex_baseline/cuda_omp_workdir/golden_labels/src/convolution1D-serial'
OMP_TARGET_OFFLOAD=MANDATORY 	python3 /root/codex_baseline/cuda_omp_workdir/gate_sdk/scripts/gate_harness.py /root/codex_baseline/cuda_omp_workdir/golden_labels/src/convolution1D-serial/main ./main 100000 1000
[FAIL][no_gate_output] Neither reference nor candidate produced any GATE macros output
This indicates that neither program contains GATE_CHECKSUM_* or GATE_STATS_* macros
---- REF LOG ----

---------------------
Mask width: 3
1D convolution (FP64)
Average kernel execution time of conv1d kernel: 157.510956 (us)
PASS
GATE:STAT name=conv1d kernel::FP64 dtype=f64 n=100096 min=5 max=755 mean=382.82290001598465 L1=38319041 L2=127738.03728334016
Average kernel execution time of conv1d-tiled kernel: 298.971741 (us)
PASS
GATE:STAT name=conv1d-tiled kernel::FP64 dtype=f64 n=100096 min=5 max=755 mean=382.82290001598465 L1=38319041 L2=127738.03728334016
Average kernel execution time of conv1d-tiled-caching kernel: 0.223919 (us)
PASS
GATE:STAT name=conv1d-tiled-caching kernel::FP64 dtype=f64 n=100096 min=5 max=755 mean=382.82290001598465 L1=38319041 L2=127738.03728334016
1D convolution (FP32)
Average kernel execution time of conv1d kernel: 193.924927 (us)
PASS
GATE:STAT name=conv1d kernel::FP32 dtype=f32 n=100096 min=5 max=755 mean=382.8229 L1=38319041 L2=127738.037
Average kernel execution time of conv1d-tiled kernel: 273.080536 (us)
PASS
GATE:STAT name=conv1d-tiled kernel::FP32 dtype=f32 n=100096 min=5 max=755 mean=382.8229 L1=38319041 L2=127738.037
Average kernel execution time of conv1d-tiled-caching kernel: 0.023181 (us)
PASS
GATE:STAT name=conv1d-tiled-caching kernel::FP32 dtype=f32 n=100096 min=5 max=755 mean=382.8229 L1=38319041 L2=127738.037
1D convolution (INT16)
Average kernel execution time of conv1d kernel: 258.550537 (us)
PASS
GATE:SUM name=conv1d kernel::INT16 dtype=bytes algo=fnv1a64 value=65ffd96468e55811 nbytes=200192
Average kernel execution time of conv1d-tiled kernel: 220.411804 (us)
PASS
GATE:SUM name=conv1d-tiled kernel::INT16 dtype=bytes algo=fnv1a64 value=65ffd96468e55811 nbytes=200192
Average kernel execution time of conv1d-tiled-caching kernel: 0.017863 (us)
PASS
GATE:SUM name=conv1d-tiled-caching kernel::INT16 dtype=bytes algo=fnv1a64 value=65ffd96468e55811 nbytes=200192

---------------------
Mask width: 5
1D convolution (FP64)
Average kernel execution time of conv1d kernel: 284.647156 (us)
PASS
GATE:STAT name=conv1d kernel::FP64 dtype=f64 n=100096 min=55 max=1206 mean=638.03489649936061 L1=63864741 L2=208538.19905475352
Average kernel execution time of conv1d-tiled kernel: 290.431488 (us)
PASS
GATE:STAT name=conv1d-tiled kernel::FP64 dtype=f64 n=100096 min=55 max=1206 mean=638.03489649936061 L1=63864741 L2=208538.19905475352
Average kernel execution time of conv1d-tiled-caching kernel: 0.021824 (us)
PASS
GATE:STAT name=conv1d-tiled-caching kernel::FP64 dtype=f64 n=100096 min=55 max=1206 mean=638.03489649936061 L1=63864741 L2=208538.19905475352
1D convolution (FP32)
Average kernel execution time of conv1d kernel: 310.157837 (us)
PASS
GATE:STAT name=conv1d kernel::FP32 dtype=f32 n=100096 min=55 max=1206 mean=638.034896 L1=63864741 L2=208538.199
Average kernel execution time of conv1d-tiled kernel: 345.499573 (us)
PASS
GATE:STAT name=conv1d-tiled kernel::FP32 dtype=f32 n=100096 min=55 max=1206 mean=638.034896 L1=63864741 L2=208538.199
Average kernel execution time of conv1d-tiled-caching kernel: 0.018737 (us)
PASS
GATE:STAT name=conv1d-tiled-caching kernel::FP32 dtype=f32 n=100096 min=55 max=1206 mean=638.034896 L1=63864741 L2=208538.199
1D convolution (INT16)
Average kernel execution time of conv1d kernel: 408.737488 (us)
PASS
GATE:SUM name=conv1d kernel::INT16 dtype=bytes algo=fnv1a64 value=58088b9457dab6ba nbytes=200192
Average kernel execution time of conv1d-tiled kernel: 303.391052 (us)
PASS
GATE:SUM name=conv1d-tiled kernel::INT16 dtype=bytes algo=fnv1a64 value=58088b9457dab6ba nbytes=200192
Average kernel execution time of conv1d-tiled-caching kernel: 0.018422 (us)
PASS
GATE:SUM name=conv1d-tiled-caching kernel::INT16 dtype=bytes algo=fnv1a64 value=58088b9457dab6ba nbytes=200192

---------------------
Mask width: 7
1D convolution (FP64)
Average kernel execution time of conv1d kernel: 412.218048 (us)
PASS
GATE:STAT name=conv1d kernel::FP64 dtype=f64 n=100096 min=159 max=1660 mean=893.24426550511509 L1=89410178 L2=289303.47306591395
Average kernel execution time of conv1d-tiled kernel: 307.224701 (us)
PASS
GATE:STAT name=conv1d-tiled kernel::FP64 dtype=f64 n=100096 min=159 max=1660 mean=893.24426550511509 L1=89410178 L2=289303.47306591395
Average kernel execution time of conv1d-tiled-caching kernel: 0.019777 (us)
PASS
GATE:STAT name=conv1d-tiled-caching kernel::FP64 dtype=f64 n=100096 min=159 max=1660 mean=893.24426550511509 L1=89410178 L2=289303.47306591395
1D convolution (FP32)
Average kernel execution time of conv1d kernel: 405.084717 (us)
PASS
GATE:STAT name=conv1d kernel::FP32 dtype=f32 n=100096 min=159 max=1660 mean=893.244266 L1=89410178 L2=289303.473
Average kernel execution time of conv1d-tiled kernel: 447.956635 (us)
PASS
GATE:STAT name=conv1d-tiled kernel::FP32 dtype=f32 n=100096 min=159 max=1660 mean=893.244266 L1=89410178 L2=289303.473
Average kernel execution time of conv1d-tiled-caching kernel: 0.026569 (us)
PASS
GATE:STAT name=conv1d-tiled-caching kernel::FP32 dtype=f32 n=100096 min=159 max=1660 mean=893.244266 L1=89410178 L2=289303.473
1D convolution (INT16)
Average kernel execution time of conv1d kernel: 579.217957 (us)
PASS
GATE:SUM name=conv1d kernel::INT16 dtype=bytes algo=fnv1a64 value=fd3dd7dd8c65a745 nbytes=200192
Average kernel execution time of conv1d-tiled kernel: 386.074371 (us)
PASS
GATE:SUM name=conv1d-tiled kernel::INT16 dtype=bytes algo=fnv1a64 value=fd3dd7dd8c65a745 nbytes=200192
Average kernel execution time of conv1d-tiled-caching kernel: 0.019163 (us)
PASS
GATE:SUM name=conv1d-tiled-caching kernel::INT16 dtype=bytes algo=fnv1a64 value=fd3dd7dd8c65a745 nbytes=200192

---------------------
Mask width: 9
1D convolution (FP64)
Average kernel execution time of conv1d kernel: 373.119568 (us)
PASS
GATE:STAT name=conv1d kernel::FP64 dtype=f64 n=100096 min=341 max=2017 mean=1148.4519061700767 L1=114955442 L2=370058.01310064886
Average kernel execution time of conv1d-tiled kernel: 241.229614 (us)
PASS
GATE:STAT name=conv1d-tiled kernel::FP64 dtype=f64 n=100096 min=341 max=2017 mean=1148.4519061700767 L1=114955442 L2=370058.01310064886
Average kernel execution time of conv1d-tiled-caching kernel: 0.020418 (us)
PASS
GATE:STAT name=conv1d-tiled-caching kernel::FP64 dtype=f64 n=100096 min=341 max=2017 mean=1148.4519061700767 L1=114955442 L2=370058.01310064886
1D convolution (FP32)
Average kernel execution time of conv1d kernel: 313.236542 (us)
PASS
GATE:STAT name=conv1d kernel::FP32 dtype=f32 n=100096 min=341 max=2017 mean=1148.45191 L1=114955442 L2=370058.013
Average kernel execution time of conv1d-tiled kernel: 227.980606 (us)
PASS
GATE:STAT name=conv1d-tiled kernel::FP32 dtype=f32 n=100096 min=341 max=2017 mean=1148.45191 L1=114955442 L2=370058.013
Average kernel execution time of conv1d-tiled-caching kernel: 0.026053 (us)
PASS
GATE:STAT name=conv1d-tiled-caching kernel::FP32 dtype=f32 n=100096 min=341 max=2017 mean=1148.45191 L1=114955442 L2=370058.013
1D convolution (INT16)
Average kernel execution time of conv1d kernel: 532.723572 (us)
PASS
GATE:SUM name=conv1d kernel::INT16 dtype=bytes algo=fnv1a64 value=5b26f7e40e0feb46 nbytes=200192
Average kernel execution time of conv1d-tiled kernel: 248.987640 (us)
PASS
GATE:SUM name=conv1d-tiled kernel::INT16 dtype=bytes algo=fnv1a64 value=5b26f7e40e0feb46 nbytes=200192
Average kernel execution time of conv1d-tiled-caching kernel: 0.021009 (us)
PASS
GATE:SUM name=conv1d-tiled-caching kernel::INT16 dtype=bytes algo=fnv1a64 value=5b26f7e40e0feb46 nbytes=200192
---- CAND LOG ----

---------------------
Mask width: 3
1D convolution (FP64)
Average kernel execution time of conv1d kernel: 176.871017 (us)
PASS
GATE:STAT name=conv1d kernel::FP64 dtype=f64 n=100096 min=5 max=755 mean=382.82290001598465 L1=38319041 L2=127738.03728334016
Average kernel execution time of conv1d-tiled kernel: 166.020462 (us)
PASS
GATE:STAT name=conv1d-tiled kernel::FP64 dtype=f64 n=100096 min=5 max=755 mean=382.82290001598465 L1=38319041 L2=127738.03728334016
Average kernel execution time of conv1d-tiled-caching kernel: 164.758514 (us)
PASS
GATE:STAT name=conv1d-tiled-caching kernel::FP64 dtype=f64 n=100096 min=5 max=755 mean=382.82290001598465 L1=38319041 L2=127738.03728334016
1D convolution (FP32)
Average kernel execution time of conv1d kernel: 176.182709 (us)
PASS
GATE:STAT name=conv1d kernel::FP32 dtype=f32 n=100096 min=5 max=755 mean=382.8229 L1=38319041 L2=127738.037
Average kernel execution time of conv1d-tiled kernel: 174.054031 (us)
PASS
GATE:STAT name=conv1d-tiled kernel::FP32 dtype=f32 n=100096 min=5 max=755 mean=382.8229 L1=38319041 L2=127738.037
Average kernel execution time of conv1d-tiled-caching kernel: 176.711823 (us)
PASS
GATE:STAT name=conv1d-tiled-caching kernel::FP32 dtype=f32 n=100096 min=5 max=755 mean=382.8229 L1=38319041 L2=127738.037
1D convolution (INT16)
Average kernel execution time of conv1d kernel: 188.886887 (us)
PASS
GATE:SUM name=conv1d kernel::INT16 dtype=bytes algo=fnv1a64 value=65ffd96468e55811 nbytes=200192
Average kernel execution time of conv1d-tiled kernel: 186.620102 (us)
PASS
GATE:SUM name=conv1d-tiled kernel::INT16 dtype=bytes algo=fnv1a64 value=65ffd96468e55811 nbytes=200192
Average kernel execution time of conv1d-tiled-caching kernel: 187.119858 (us)
PASS
GATE:SUM name=conv1d-tiled-caching kernel::INT16 dtype=bytes algo=fnv1a64 value=65ffd96468e55811 nbytes=200192

---------------------
Mask width: 5
1D convolution (FP64)
Average kernel execution time of conv1d kernel: 267.162231 (us)
PASS
GATE:STAT name=conv1d kernel::FP64 dtype=f64 n=100096 min=55 max=1206 mean=638.03489649936061 L1=63864741 L2=208538.19905475352
Average kernel execution time of conv1d-tiled kernel: 263.905304 (us)
PASS
GATE:STAT name=conv1d-tiled kernel::FP64 dtype=f64 n=100096 min=55 max=1206 mean=638.03489649936061 L1=63864741 L2=208538.19905475352
Average kernel execution time of conv1d-tiled-caching kernel: 269.349976 (us)
PASS
GATE:STAT name=conv1d-tiled-caching kernel::FP64 dtype=f64 n=100096 min=55 max=1206 mean=638.03489649936061 L1=63864741 L2=208538.19905475352
1D convolution (FP32)
Average kernel execution time of conv1d kernel: 288.046906 (us)
PASS
GATE:STAT name=conv1d kernel::FP32 dtype=f32 n=100096 min=55 max=1206 mean=638.034896 L1=63864741 L2=208538.199
Average kernel execution time of conv1d-tiled kernel: 287.187256 (us)
PASS
GATE:STAT name=conv1d-tiled kernel::FP32 dtype=f32 n=100096 min=55 max=1206 mean=638.034896 L1=63864741 L2=208538.199
Average kernel execution time of conv1d-tiled-caching kernel: 286.024994 (us)
PASS
GATE:STAT name=conv1d-tiled-caching kernel::FP32 dtype=f32 n=100096 min=55 max=1206 mean=638.034896 L1=63864741 L2=208538.199
1D convolution (INT16)
Average kernel execution time of conv1d kernel: 296.693970 (us)
PASS
GATE:SUM name=conv1d kernel::INT16 dtype=bytes algo=fnv1a64 value=58088b9457dab6ba nbytes=200192
Average kernel execution time of conv1d-tiled kernel: 293.991364 (us)
PASS
GATE:SUM name=conv1d-tiled kernel::INT16 dtype=bytes algo=fnv1a64 value=58088b9457dab6ba nbytes=200192
Average kernel execution time of conv1d-tiled-caching kernel: 310.799927 (us)
PASS
GATE:SUM name=conv1d-tiled-caching kernel::INT16 dtype=bytes algo=fnv1a64 value=58088b9457dab6ba nbytes=200192

---------------------
Mask width: 7
1D convolution (FP64)
Average kernel execution time of conv1d kernel: 408.450043 (us)
PASS
GATE:STAT name=conv1d kernel::FP64 dtype=f64 n=100096 min=159 max=1660 mean=893.24426550511509 L1=89410178 L2=289303.47306591395
Average kernel execution time of conv1d-tiled kernel: 403.484100 (us)
PASS
GATE:STAT name=conv1d-tiled kernel::FP64 dtype=f64 n=100096 min=159 max=1660 mean=893.24426550511509 L1=89410178 L2=289303.47306591395
Average kernel execution time of conv1d-tiled-caching kernel: 405.371765 (us)
PASS
GATE:STAT name=conv1d-tiled-caching kernel::FP64 dtype=f64 n=100096 min=159 max=1660 mean=893.24426550511509 L1=89410178 L2=289303.47306591395
1D convolution (FP32)
Average kernel execution time of conv1d kernel: 400.230988 (us)
PASS
GATE:STAT name=conv1d kernel::FP32 dtype=f32 n=100096 min=159 max=1660 mean=893.244266 L1=89410178 L2=289303.473
Average kernel execution time of conv1d-tiled kernel: 395.361389 (us)
PASS
GATE:STAT name=conv1d-tiled kernel::FP32 dtype=f32 n=100096 min=159 max=1660 mean=893.244266 L1=89410178 L2=289303.473
Average kernel execution time of conv1d-tiled-caching kernel: 397.984222 (us)
PASS
GATE:STAT name=conv1d-tiled-caching kernel::FP32 dtype=f32 n=100096 min=159 max=1660 mean=893.244266 L1=89410178 L2=289303.473
1D convolution (INT16)
Average kernel execution time of conv1d kernel: 412.717072 (us)
PASS
GATE:SUM name=conv1d kernel::INT16 dtype=bytes algo=fnv1a64 value=fd3dd7dd8c65a745 nbytes=200192
Average kernel execution time of conv1d-tiled kernel: 416.227600 (us)
PASS
GATE:SUM name=conv1d-tiled kernel::INT16 dtype=bytes algo=fnv1a64 value=fd3dd7dd8c65a745 nbytes=200192
Average kernel execution time of conv1d-tiled-caching kernel: 411.168213 (us)
PASS
GATE:SUM name=conv1d-tiled-caching kernel::INT16 dtype=bytes algo=fnv1a64 value=fd3dd7dd8c65a745 nbytes=200192

---------------------
Mask width: 9
1D convolution (FP64)
Average kernel execution time of conv1d kernel: 358.395081 (us)
PASS
GATE:STAT name=conv1d kernel::FP64 dtype=f64 n=100096 min=341 max=2017 mean=1148.4519061700767 L1=114955442 L2=370058.01310064886
Average kernel execution time of conv1d-tiled kernel: 362.620605 (us)
PASS
GATE:STAT name=conv1d-tiled kernel::FP64 dtype=f64 n=100096 min=341 max=2017 mean=1148.4519061700767 L1=114955442 L2=370058.01310064886
Average kernel execution time of conv1d-tiled-caching kernel: 370.029510 (us)
PASS
GATE:STAT name=conv1d-tiled-caching kernel::FP64 dtype=f64 n=100096 min=341 max=2017 mean=1148.4519061700767 L1=114955442 L2=370058.01310064886
1D convolution (FP32)
Average kernel execution time of conv1d kernel: 286.890869 (us)
PASS
GATE:STAT name=conv1d kernel::FP32 dtype=f32 n=100096 min=341 max=2017 mean=1148.45191 L1=114955442 L2=370058.013
Average kernel execution time of conv1d-tiled kernel: 297.253479 (us)
PASS
GATE:STAT name=conv1d-tiled kernel::FP32 dtype=f32 n=100096 min=341 max=2017 mean=1148.45191 L1=114955442 L2=370058.013
Average kernel execution time of conv1d-tiled-caching kernel: 285.965576 (us)
PASS
GATE:STAT name=conv1d-tiled-caching kernel::FP32 dtype=f32 n=100096 min=341 max=2017 mean=1148.45191 L1=114955442 L2=370058.013
1D convolution (INT16)
Average kernel execution time of conv1d kernel: 550.300598 (us)
PASS
GATE:SUM name=conv1d kernel::INT16 dtype=bytes algo=fnv1a64 value=5b26f7e40e0feb46 nbytes=200192
Average kernel execution time of conv1d-tiled kernel: 547.411499 (us)
PASS
GATE:SUM name=conv1d-tiled kernel::INT16 dtype=bytes algo=fnv1a64 value=5b26f7e40e0feb46 nbytes=200192
Average kernel execution time of conv1d-tiled-caching kernel: 540.655457 (us)
PASS
GATE:SUM name=conv1d-tiled-caching kernel::INT16 dtype=bytes algo=fnv1a64 value=5b26f7e40e0feb46 nbytes=200192
make: *** [Makefile.nvc:81: check-correctness] Error 2

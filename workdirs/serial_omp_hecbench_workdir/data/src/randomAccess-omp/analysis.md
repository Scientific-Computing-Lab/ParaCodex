### Offload Candidate Analysis for main.cpp

**Primary Candidate:**
* **Function/Loop:** Random update kernel in `main`, lines 95-100.
* **Justification:** Profiling shows this double-nested loop consumes >90% of the runtime because it performs `NUPDATE = 4 * TableSize` (≈134M for the current 2^25 table) 64-bit XOR updates against the main table. Each iteration only depends on its thread-local RNG state `ran[j]`, so we can distribute the `(j,i)` pairs across many GPU threads. The access pattern is random but still maps well to the RTX 4060 Laptop GPU (per `system_info.txt`) because the table lives in global memory and each update is a single XOR—ideal for a throughput-oriented kernel with atomic XORs to manage collisions.

**Secondary Candidate:**
* **Function/Loop:** Table initialization sweep in `main`, lines 88-91.
* **Justification:** This loop writes `Table[i] = i` for every element in the 2^25-entry array—over 256 MB of contiguous data. The work is purely memory bandwidth bound and perfectly data-parallel, so launching a GPU kernel that assigns one element per thread lets us saturate the GPU’s ~256-bit memory controllers instead of streaming the data from the CPU.

**Tertiary Candidate:**
* **Function/Loop:** Error count reduction in `main`, lines 115-118.
* **Justification:** The pass scans the entire table (≈33M entries) comparing each slot to its index and increments an error counter. The comparisons are independent, so the loop can be offloaded with a simple parallel reduction on the GPU; using warp-level reductions can hide the latency of the irregular cache hits generated by the preceding random updates.
